2020-01-22 15:18:59	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:18:59	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:18:59	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:18:59	scrapy.extensions.telnet	INFO	Telnet Password: c3fb078efca0c049
2020-01-22 15:18:59	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:19:00	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:19:00	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:19:00	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:19:00	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:19:00	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:19:00	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190116&endtime=20190117&sort=time> (referer: None)
2020-01-22 15:19:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190117&endtime=20190118&sort=time> (referer: None)
2020-01-22 15:19:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190118&endtime=20190119&sort=time> (referer: None)
2020-01-22 15:19:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190119&endtime=20190120&sort=time> (referer: None)
2020-01-22 15:19:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190120&endtime=20190121&sort=time> (referer: None)
2020-01-22 15:19:05	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190121&endtime=20190122&sort=time> (referer: None)
2020-01-22 15:19:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190122&endtime=20190123&sort=time> (referer: None)
2020-01-22 15:19:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190123&endtime=20190124&sort=time> (referer: None)
2020-01-22 15:19:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190124&endtime=20190125&sort=time> (referer: None)
2020-01-22 15:19:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190125&endtime=20190126&sort=time> (referer: None)
2020-01-22 15:19:11	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190126&endtime=20190127&sort=time> (referer: None)
2020-01-22 15:19:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190127&endtime=20190128&sort=time> (referer: None)
2020-01-22 15:19:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190128&endtime=20190129&sort=time> (referer: None)
2020-01-22 15:19:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190129&endtime=20190130&sort=time> (referer: None)
2020-01-22 15:19:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190130&endtime=20190131&sort=time> (referer: None)
2020-01-22 15:19:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190131&endtime=20190201&sort=time> (referer: None)
2020-01-22 15:19:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190201&endtime=20190202&sort=time> (referer: None)
2020-01-22 15:19:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190202&endtime=20190203&sort=time> (referer: None)
2020-01-22 15:19:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190203&endtime=20190204&sort=time> (referer: None)
2020-01-22 15:19:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190204&endtime=20190205&sort=time> (referer: None)
2020-01-22 15:19:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190205&endtime=20190206&sort=time> (referer: None)
2020-01-22 15:19:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190206&endtime=20190207&sort=time> (referer: None)
2020-01-22 15:19:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190207&endtime=20190208&sort=time> (referer: None)
2020-01-22 15:19:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190208&endtime=20190209&sort=time> (referer: None)
2020-01-22 15:19:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190209&endtime=20190210&sort=time> (referer: None)
2020-01-22 15:19:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190210&endtime=20190211&sort=time> (referer: None)
2020-01-22 15:19:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190211&endtime=20190212&sort=time> (referer: None)
2020-01-22 15:19:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190212&endtime=20190213&sort=time> (referer: None)
2020-01-22 15:19:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190213&endtime=20190214&sort=time> (referer: None)
2020-01-22 15:19:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190214&endtime=20190215&sort=time> (referer: None)
2020-01-22 15:19:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190215&endtime=20190216&sort=time> (referer: None)
2020-01-22 15:19:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190216&endtime=20190217&sort=time> (referer: None)
2020-01-22 15:19:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190217&endtime=20190218&sort=time> (referer: None)
2020-01-22 15:19:39	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190218&endtime=20190219&sort=time> (referer: None)
2020-01-22 15:19:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190219&endtime=20190220&sort=time> (referer: None)
2020-01-22 15:19:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190220&endtime=20190221&sort=time> (referer: None)
2020-01-22 15:19:42	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190221&endtime=20190222&sort=time> (referer: None)
2020-01-22 15:19:44	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190222&endtime=20190223&sort=time> (referer: None)
2020-01-22 15:19:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190223&endtime=20190224&sort=time> (referer: None)
2020-01-22 15:19:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190224&endtime=20190225&sort=time> (referer: None)
2020-01-22 15:19:47	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190225&endtime=20190226&sort=time> (referer: None)
2020-01-22 15:19:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190226&endtime=20190227&sort=time> (referer: None)
2020-01-22 15:19:50	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190227&endtime=20190228&sort=time> (referer: None)
2020-01-22 15:19:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190228&endtime=20190301&sort=time> (referer: None)
2020-01-22 15:19:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190301&endtime=20190302&sort=time> (referer: None)
2020-01-22 15:19:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190302&endtime=20190303&sort=time> (referer: None)
2020-01-22 15:19:54	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190303&endtime=20190304&sort=time> (referer: None)
2020-01-22 15:19:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190304&endtime=20190305&sort=time> (referer: None)
2020-01-22 15:19:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:19:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190305&endtime=20190306&sort=time> (referer: None)
2020-01-22 15:19:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:00	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190306&endtime=20190307&sort=time> (referer: None)
2020-01-22 15:20:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:00	scrapy.extensions.logstats	INFO	Crawled 50 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:20:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190307&endtime=20190308&sort=time> (referer: None)
2020-01-22 15:20:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190308&endtime=20190309&sort=time> (referer: None)
2020-01-22 15:20:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:04	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190309&endtime=20190310&sort=time> (referer: None)
2020-01-22 15:20:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:04	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190309&endtime=20190310&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:05	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190310&endtime=20190311&sort=time> (referer: None)
2020-01-22 15:20:05	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:05	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190310&endtime=20190311&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:06	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190311&endtime=20190312&sort=time> (referer: None)
2020-01-22 15:20:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:06	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190311&endtime=20190312&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:07	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190312&endtime=20190313&sort=time> (referer: None)
2020-01-22 15:20:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:07	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190312&endtime=20190313&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:07	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190313&endtime=20190314&sort=time> (referer: None)
2020-01-22 15:20:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:07	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190313&endtime=20190314&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:09	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190314&endtime=20190315&sort=time> (referer: None)
2020-01-22 15:20:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:09	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190314&endtime=20190315&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:10	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190315&endtime=20190316&sort=time> (referer: None)
2020-01-22 15:20:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:10	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190315&endtime=20190316&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:11	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190316&endtime=20190317&sort=time> (referer: None)
2020-01-22 15:20:11	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:12	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190316&endtime=20190317&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:13	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190317&endtime=20190318&sort=time> (referer: None)
2020-01-22 15:20:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:13	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190317&endtime=20190318&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:14	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190318&endtime=20190319&sort=time> (referer: None)
2020-01-22 15:20:14	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:14	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190318&endtime=20190319&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:15	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190319&endtime=20190320&sort=time> (referer: None)
2020-01-22 15:20:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:15	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190319&endtime=20190320&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:17	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190320&endtime=20190321&sort=time> (referer: None)
2020-01-22 15:20:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:17	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190320&endtime=20190321&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:18	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190321&endtime=20190322&sort=time> (referer: None)
2020-01-22 15:20:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:18	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190321&endtime=20190322&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:19	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190322&endtime=20190323&sort=time> (referer: None)
2020-01-22 15:20:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:19	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190322&endtime=20190323&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:20	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190323&endtime=20190324&sort=time> (referer: None)
2020-01-22 15:20:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:20	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190323&endtime=20190324&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:21	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190324&endtime=20190325&sort=time> (referer: None)
2020-01-22 15:20:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:21	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190324&endtime=20190325&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:22	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190325&endtime=20190326&sort=time> (referer: None)
2020-01-22 15:20:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:22	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190325&endtime=20190326&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:23	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190326&endtime=20190327&sort=time> (referer: None)
2020-01-22 15:20:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:23	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190326&endtime=20190327&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:24	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190327&endtime=20190328&sort=time> (referer: None)
2020-01-22 15:20:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:24	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190327&endtime=20190328&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:25	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190328&endtime=20190329&sort=time> (referer: None)
2020-01-22 15:20:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:26	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190328&endtime=20190329&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:26	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190329&endtime=20190330&sort=time> (referer: None)
2020-01-22 15:20:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:27	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190329&endtime=20190330&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:28	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190330&endtime=20190331&sort=time> (referer: None)
2020-01-22 15:20:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:28	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190330&endtime=20190331&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:29	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190331&endtime=20190401&sort=time> (referer: None)
2020-01-22 15:20:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:30	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190331&endtime=20190401&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:31	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190401&endtime=20190402&sort=time> (referer: None)
2020-01-22 15:20:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:31	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190401&endtime=20190402&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:32	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190402&endtime=20190403&sort=time> (referer: None)
2020-01-22 15:20:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:32	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190402&endtime=20190403&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:33	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190403&endtime=20190404&sort=time> (referer: None)
2020-01-22 15:20:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:33	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190403&endtime=20190404&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:34	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190404&endtime=20190405&sort=time> (referer: None)
2020-01-22 15:20:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:34	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190404&endtime=20190405&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:36	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190405&endtime=20190406&sort=time> (referer: None)
2020-01-22 15:20:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:20:36	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:20:36	scrapy.core.engine	INFO	Closing spider (shutdown)
2020-01-22 15:20:36	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190405&endtime=20190406&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:37	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190406&endtime=20190407&sort=time> (referer: None)
2020-01-22 15:20:37	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190406&endtime=20190407&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:38	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190407&endtime=20190408&sort=time> (referer: None)
2020-01-22 15:20:38	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190407&endtime=20190408&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:39	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190408&endtime=20190409&sort=time> (referer: None)
2020-01-22 15:20:39	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190408&endtime=20190409&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:40	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190409&endtime=20190410&sort=time> (referer: None)
2020-01-22 15:20:41	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190409&endtime=20190410&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:42	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190410&endtime=20190411&sort=time> (referer: None)
2020-01-22 15:20:42	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190410&endtime=20190411&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:43	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190411&endtime=20190412&sort=time> (referer: None)
2020-01-22 15:20:43	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190411&endtime=20190412&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:44	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190412&endtime=20190413&sort=time> (referer: None)
2020-01-22 15:20:45	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190412&endtime=20190413&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:46	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190413&endtime=20190414&sort=time> (referer: None)
2020-01-22 15:20:46	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190413&endtime=20190414&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:47	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190414&endtime=20190415&sort=time> (referer: None)
2020-01-22 15:20:47	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190414&endtime=20190415&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:20:48	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190415&endtime=20190416&sort=time> (referer: None)
2020-01-22 15:20:48	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20190415&endtime=20190416&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:21:17	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:21:17	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:21:17	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:21:17	scrapy.extensions.telnet	INFO	Telnet Password: 83be6ae0445caa79
2020-01-22 15:21:17	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:21:18	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:21:18	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:21:18	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:21:18	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:21:18	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:21:18	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:21:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:21:19	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:21:19	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:21:19	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 15:21:19	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 818,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 140,
 'downloader/response_count': 1,
 'downloader/response_status_count/418': 1,
 'elapsed_time_seconds': 0.648204,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 6, 21, 19, 178418),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/418': 1,
 'log_count/DEBUG': 2,
 'log_count/INFO': 11,
 'memusage/max': 108916736,
 'memusage/startup': 108916736,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 1, 22, 6, 21, 18, 530214)}
2020-01-22 15:21:19	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 15:22:31	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:22:31	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:22:31	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:22:31	scrapy.extensions.telnet	INFO	Telnet Password: f5825413d8b3b005
2020-01-22 15:22:32	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:22:32	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:22:32	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:22:32	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:22:32	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:22:32	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:22:32	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:22:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:22:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:22:33	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:22:33	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:22:33	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200121&endtime=20200122&sort=time> (referer: None)
2020-01-22 15:22:34	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200121&endtime=20200122&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:22:34	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 15:22:34	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 1636,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 280,
 'downloader/response_count': 2,
 'downloader/response_status_count/418': 2,
 'elapsed_time_seconds': 1.356349,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 6, 22, 34, 23344),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/418': 2,
 'log_count/DEBUG': 4,
 'log_count/INFO': 12,
 'memusage/max': 108912640,
 'memusage/startup': 108904448,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 1, 22, 6, 22, 32, 666995)}
2020-01-22 15:22:34	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 15:22:57	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:22:57	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:22:58	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:22:58	scrapy.extensions.telnet	INFO	Telnet Password: 05ae9d45502e14a4
2020-01-22 15:22:58	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:22:58	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:22:58	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:22:58	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:22:58	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:22:58	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:22:58	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:22:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:22:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:22:59	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:22:59	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:23:00	scrapy.core.engine	DEBUG	Crawled (418) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200121&endtime=20200122&sort=time> (referer: None)
2020-01-22 15:23:00	scrapy.spidermiddlewares.httperror	INFO	Ignoring response <418 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200121&endtime=20200122&sort=time>: HTTP status code is not handled or not allowed
2020-01-22 15:23:00	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 15:23:00	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 1636,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 280,
 'downloader/response_count': 2,
 'downloader/response_status_count/418': 2,
 'elapsed_time_seconds': 1.717926,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 6, 23, 0, 494644),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/418': 2,
 'log_count/DEBUG': 4,
 'log_count/INFO': 12,
 'memusage/max': 108871680,
 'memusage/startup': 108871680,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 1, 22, 6, 22, 58, 776718)}
2020-01-22 15:23:00	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 15:27:59	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:27:59	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:27:59	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:27:59	scrapy.extensions.telnet	INFO	Telnet Password: dfb6d9057c8f7545
2020-01-22 15:27:59	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:27:59	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:27:59	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:27:59	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:27:59	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:27:59	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:27:59	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:27:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:28:00	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:30:29	scrapy.extensions.logstats	INFO	Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:30:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:31:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:31:04',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:31:04	scrapy.extensions.logstats	INFO	Crawled 1 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2020-01-22 15:31:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:31:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:44:18	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:46:58	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:46:58	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:46:58	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:46:58	scrapy.extensions.telnet	INFO	Telnet Password: 80792556cfb4c945
2020-01-22 15:46:58	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:46:59	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:46:59	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:46:59	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:46:59	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:46:59	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:46:59	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:46:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:46:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:47:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:47:17	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:47:17',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:47:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:47:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:48:40	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:49:39	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:49:39	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:49:39	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:49:39	scrapy.extensions.telnet	INFO	Telnet Password: 7f95f85b24daab21
2020-01-22 15:49:39	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:49:40	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:49:40	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:49:40	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:49:40	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:49:40	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:49:40	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:49:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:49:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:49:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:49:41',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:49:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:49:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:49:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:50:15	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:51:31	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:51:32	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:51:32	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:51:32	scrapy.extensions.telnet	INFO	Telnet Password: 5756f73a0b21afc9
2020-01-22 15:51:32	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:51:32	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:51:32	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:51:32	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:51:32	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:51:32	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:51:32	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:51:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:51:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:51:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:51:34',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:51:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:51:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:51:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:52:27	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:54:05	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:54:05	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:54:05	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:54:05	scrapy.extensions.telnet	INFO	Telnet Password: 53e0320e2afae585
2020-01-22 15:54:06	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:54:06	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:54:06	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:54:06	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:54:06	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:54:06	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:54:06	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:54:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:54:07	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:54:07',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:54:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:54:30	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:54:44	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:54:44	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:54:44	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:54:44	scrapy.extensions.telnet	INFO	Telnet Password: 13c6af3ed2683f82
2020-01-22 15:54:44	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:54:45	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:54:45	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:54:45	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:54:45	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:54:45	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:54:45	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:54:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:54:46	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:54:46',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:54:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:54:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:55:18	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:58:54	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:58:54	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:58:54	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:58:54	scrapy.extensions.telnet	INFO	Telnet Password: 88295146432487db
2020-01-22 15:58:54	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:58:55	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:58:55	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:58:55	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:58:55	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:58:55	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:58:55	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:58:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:58:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:58:56	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:58:56',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:58:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:58:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:58:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 15:59:38	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 15:59:47	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 15:59:47	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 15:59:47	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 15:59:47	scrapy.extensions.telnet	INFO	Telnet Password: 57c009705f0cd065
2020-01-22 15:59:47	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 15:59:48	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 15:59:48	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 15:59:48	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 15:59:48	scrapy.core.engine	INFO	Spider opened
2020-01-22 15:59:48	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 15:59:48	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 15:59:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:59:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 15:59:49	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 15:59:49',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 15:59:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:59:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 15:59:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:00:13	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:00:49	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:00:49	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:00:49	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:00:49	scrapy.extensions.telnet	INFO	Telnet Password: e9b6de6c1b5e46cd
2020-01-22 16:00:49	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:00:50	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:00:50	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:00:50	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:00:50	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:00:50	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:00:50	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:00:50	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:00:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:00:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:00:51',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:00:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:00:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:00:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:01:14	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:02:34	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:02:34	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:02:34	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:02:34	scrapy.extensions.telnet	INFO	Telnet Password: f6c2f95a38ccbf2a
2020-01-22 16:02:34	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:02:35	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:02:35	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:02:35	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:02:35	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:02:35	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:02:35	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:02:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:02:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:02:36	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:02:36',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:02:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:02:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:02:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:03:19	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:04:02	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:04:02	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:04:02	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:04:02	scrapy.extensions.telnet	INFO	Telnet Password: b767a8080682a634
2020-01-22 16:04:02	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:04:02	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:04:02	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:04:02	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:04:02	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:04:02	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:04:02	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:04:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:04:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:04:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:04:03',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:04:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:04:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:04:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E5%87%BA%E9%97%A8%E5%85%A8%E5%AE%B6%E9%83%BD%E5%B8%A6%E4%B8%8A%E4%BA%86%E5%8F%A3%E7%BD%A9&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:06:01	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:07:07	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:07:07	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:07:07	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:07:07	scrapy.extensions.telnet	INFO	Telnet Password: a51727416f43d17d
2020-01-22 16:07:07	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:07:07	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:07:07	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:07:07	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:07:07	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:07:07	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:07:07	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:07:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:07:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time> (referer: None)
2020-01-22 16:07:08	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time>
{'crawled_at': '2020-01-22 16:07:08',
 'created_at': '2020-01-18 20:53',
 'favorite_count': 3,
 'id_str': '3964232262_Iq5NlAoqi',
 'image_url': 'http://wx2.sinaimg.cn/wap180/ec496246ly1gb10c08s47j20u20jytdl.jpg',
 'place': True,
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 9',
 'text': '#信阳生活#【#武汉新增4例新型冠状病毒肺炎病例#】武汉市卫健委18日关于新型冠状病毒感染的肺炎情况通报：1月16日0—24时，治愈出院3例，无新增死亡病例。经专家组综合研判，我市新增4例新型冠状病毒感染的肺炎病例，目前，新增病例已安排转院救治，所有病例病情稳定，无危重症。截至目前，我市累计报告新型冠状病毒感染的肺炎病例45例，已治愈出院15例，在治重症5例，死亡2例，其余患者病情稳定，均在接受隔离治疗。（人民日报）',
 'user': '3964232262',
 'username': '爱信阳',
 'weibo_url': 'https://weibo.com/3964232262/Iq5NlAoqi'}
2020-01-22 16:07:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:07:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:07:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3964232262/Iq5NlAoqi> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time)
2020-01-22 16:17:30	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:18:16	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:18:16	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:18:16	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:18:17	scrapy.extensions.telnet	INFO	Telnet Password: 50b5fee075569b1f
2020-01-22 16:18:17	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:18:17	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:18:17	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:18:17	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:18:17	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:18:17	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:18:17	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:18:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:18:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:18:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:18:18',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:18:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:18:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:18:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:20:21	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:21:02	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:21:02	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:21:02	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:21:02	scrapy.extensions.telnet	INFO	Telnet Password: 264d3c0dbb5da28a
2020-01-22 16:21:02	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:21:03	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:21:03	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:21:03	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:21:03	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:21:03	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:21:03	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:21:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:21:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time> (referer: None)
2020-01-22 16:21:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time>
{'crawled_at': '2020-01-22 16:21:04',
 'created_at': '2020-01-18 20:53',
 'favorite_count': 3,
 'id_str': '3964232262_Iq5NlAoqi',
 'image_url': 'http://wx2.sinaimg.cn/wap180/ec496246ly1gb10c08s47j20u20jytdl.jpg',
 'place': True,
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 9',
 'text': '#信阳生活#【#武汉新增4例新型冠状病毒肺炎病例#】武汉市卫健委18日关于新型冠状病毒感染的肺炎情况通报：1月16日0—24时，治愈出院3例，无新增死亡病例。经专家组综合研判，我市新增4例新型冠状病毒感染的肺炎病例，目前，新增病例已安排转院救治，所有病例病情稳定，无危重症。截至目前，我市累计报告新型冠状病毒感染的肺炎病例45例，已治愈出院15例，在治重症5例，死亡2例，其余患者病情稳定，均在接受隔离治疗。（人民日报）',
 'user': '3964232262',
 'username': '爱信阳',
 'weibo_url': 'https://weibo.com/3964232262/Iq5NlAoqi'}
2020-01-22 16:21:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:21:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:21:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3964232262/Iq5NlAoqi> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200117&endtime=20200118&sort=time)
2020-01-22 16:22:34	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:23:35	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:23:35	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:23:35	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:23:35	scrapy.extensions.telnet	INFO	Telnet Password: 3257ae3a7a8932c9
2020-01-22 16:23:35	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:23:35	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:23:35	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:23:35	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:23:35	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:23:35	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:23:35	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:23:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 37,
 'id_str': '2550809142_Iqzi9yUAF',
 'place': True,
 'reply_count': 2,
 'retweet_count': 5,
 'source': 'HUAWEI Mate 9',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！#钟南山肯定新型冠状病毒肺炎人传人#http://t.cn/A6v1G0dH',
 'user': '2550809142',
 'username': '今日潮汕在线',
 'weibo_url': 'https://weibo.com/2550809142/Iqzi9yUAF'}
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:50',
 'favorite_count': 504,
 'id_str': '1497087080_Iqzey9pO3',
 'reply_count': 37,
 'retweet_count': 90,
 'source': '微博 weibo.com',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！小央视频的秒拍视频',
 'user': '1497087080',
 'username': '羊城晚报',
 'weibo_url': 'https://weibo.com/1497087080/Iqzey9pO3'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:42',
 'favorite_count': 17,
 'id_str': '1106738707_Iqzbtz2oc',
 'reply_count': 0,
 'retweet_count': 2,
 'source': 'Redmi K20 Pro 真旗舰',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。我有国士，天下无双小央视频的秒拍视频',
 'user': '1106738707',
 'username': '3号男嘉宾_',
 'weibo_url': 'https://weibo.com/1106738707/Iqzbtz2oc'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:36',
 'favorite_count': 41,
 'id_str': '2717998533_Iqz8Yo5JT',
 'reply_count': 1,
 'retweet_count': 13,
 'source': '窗 - 魅族 PRO 7',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！#钟南山肯定新型冠状病毒肺炎人传人#http://t.cn/A6v1G0dH',
 'user': '2717998533',
 'username': '平安丰都',
 'weibo_url': 'https://weibo.com/2717998533/Iqz8Yo5JT'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:26',
 'favorite_count': 51,
 'id_str': '2176235777_Iqz54FRVk',
 'reply_count': 0,
 'retweet_count': 13,
 'source': 'iPhone客户端',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！#钟南山肯定新型冠状病毒肺炎人传人#http://t.cn/A6v1G0dH',
 'user': '2176235777',
 'username': '广东政法',
 'weibo_url': 'https://weibo.com/2176235777/Iqz54FRVk'}
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 23:09',
 'favorite_count': 2,
 'id_str': '1435514195_IqyXUhH0s',
 'image_url': 'http://wx1.sinaimg.cn/wap180/55903553gy1gb4l434nv0j20iw09tmy9.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '百度App',
 'text': '《面对疫情，84岁钟南山“挂帅出征”，这两张照片让人肃然起敬》2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山。http://t.cn/A6vdCW0X',
 'user': '1435514195',
 'username': '浔阳街头',
 'weibo_url': 'https://weibo.com/1435514195/IqyXUhH0s'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 22:45',
 'favorite_count': 21,
 'id_str': '1986281173_IqyOf0TTk',
 'reply_count': 3,
 'retweet_count': 4,
 'source': '身体健康的Android',
 'text': '#校园微分享#【为他点赞！面对疫情，#84岁钟南山挂帅出征#！】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。小央视频的秒拍视频',
 'user': '1986281173',
 'username': '广州校园',
 'weibo_url': 'https://weibo.com/1986281173/IqyOf0TTk'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 21:43',
 'favorite_count': 21,
 'id_str': '5194932844_Iqyp34x22',
 'reply_count': 0,
 'retweet_count': 3,
 'source': 'HUAWEI Mate 20 X',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。@小央视频小央视频的秒拍视频',
 'user': '5194932844',
 'username': '云南理论网',
 'weibo_url': 'https://weibo.com/5194932844/Iqyp34x22'}
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 21:27',
 'favorite_count': 68,
 'id_str': '1848870007_IqyiEfflh',
 'image_url': 'http://wx1.sinaimg.cn/wap180/6e338477ly1gb4i4bz5ffj20gt0fcjtu.jpg',
 'reply_count': 1,
 'retweet_count': 9,
 'text': '84岁的钟南山院士在日常繁忙工作之余，每周都要抽出三四天进行锻炼，每一次的时间都会保持在40分钟到50分钟。所以看起来像50岁的。2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山再次挂帅出征去了武汉。为他点赞！英雄！',
 'user': '1848870007',
 'username': '日语老师李晓东',
 'weibo_url': 'https://weibo.com/1848870007/IqyiEfflh'}
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:23:37',
 'created_at': '2020-01-21 21:22',
 'favorite_count': 3,
 'id_str': '6451394969_Iqygu5fmk',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '疾速双摄 魅蓝 Note6',
 'text': '#钟南山#在2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山。现在，2020年，钟南山院士84岁了，他再次挂帅出征去了武汉。这个春节，他会在“突发事件”的第一线向这位老人致敬！',
 'user': '6451394969',
 'username': '南南的生发水',
 'weibo_url': 'https://weibo.com/6451394969/Iqygu5fmk'}
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:23:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2550809142/Iqzi9yUAF> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=2003%E5%B9%B4%EF%BC%8C%E4%B8%80%E5%9C%BA%E7%AA%81%E5%A6%82%E5%85%B6%E6%9D%A5%E7%9A%84%E2%80%9C%E9%9D%9E%E5%85%B8%E2%80%9D%E7%96%AB%E6%83%85%E4%BB%A4%E4%B8%96%E4%BA%BA%E9%97%BB%E4%B9%8B%E8%89%B2%E5%8F%98&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:24:33	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:26:23	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:26:23	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:26:24	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:26:24	scrapy.extensions.telnet	INFO	Telnet Password: 9ea23fa136e84743
2020-01-22 16:26:24	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:26:24	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:26:24	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:26:24	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:26:24	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:26:24	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:26:24	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:26:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:25	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '7062111388_IqzizgN2T',
 'image_url': 'http://wx3.sinaimg.cn/wap180/62bfd143ly1gb4lqfyq3zj20u01dn10w.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqz7oChNQ?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 20',
 'text': '北京新增的五例新性肺炎，五位近期都去过武汉，有两位只去了一天就已经感染。我不由得想，武汉到底已经严重成什么样？真的只有官方报道的两百多例吗？',
 'user': '7062111388',
 'username': '妮妮还是可爱',
 'weibo_url': 'https://weibo.com/7062111388/IqzizgN2T'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '6920592819_Iqzizfqcp',
 'image_url': 'http://wx3.sinaimg.cn/wap180/62bfd143ly1gb4lqfyq3zj20u01dn10w.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqz7oChNQ?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '前后2000万 OPPO R11s',
 'text': '北京新增的五例新性肺炎，五位近期都去过武汉，有两位只去了一天就已经感染。我不由得想，武汉到底已经严重成什么样？真的只有官方报道的两百多例吗？',
 'user': '6920592819',
 'username': '生日愿望是要快乐',
 'weibo_url': 'https://weibo.com/6920592819/Iqzizfqcp'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 388,
 'id_str': '1794555830_IqziyF1Eu',
 'reply_count': 82,
 'retweet_count': 74,
 'source': 'iPhone客户端',
 'text': '朋友圈有些武汉的朋友觉得这次肺炎被称为“武汉肺炎”非常不舒服，感觉受到了针对，甚至有些人觉得在春运这个关头，这对九省通衢的武汉是不是有“阴谋论”，在这里我想说两句。关于“武汉肺炎”这个名称：SARS也就是我们熟知的“非典”，最开始其实就叫“广州肺炎”，只不过03年互联网不像现在这么发达，没有流传开，这个只是常规的“地点+事件”的起名方式。之所以称之为“武汉肺炎”我个人觉得有两点：一是目前只确定了是新型冠状病毒，没有给这个肺炎一个确切的名字，例如“非典”（非典型肺炎）全称就是“严重急性呼吸综合征（简称SARS）”，在这之前采用常规的起名方式先定义这次肺炎；二是其实冬季很多人都会有呼吸道感染引发肺炎，这个时候用“武汉肺炎”是为了区别于普通肺炎，普通肺炎是没有新型冠状病毒的。所以真的不是针对武汉，这跟非典最开始叫“广州肺炎”、中东呼吸综合征是一样的起名方式，让大家有更直观的了解。关于春运关头的阴谋论：这个真的是时间凑巧，赶在了这样一个时间节点，当初“非典”最早的病例也是在年前发现的，因为当时的医疗条件、疾控体系的不完善等因素，导致了经过春运之后大范围的爆发，所以大家印象中好像非典是暑假的事情，实际上那个时候已经是非常后期了，目前这次的新型冠状病毒疫情还处于比较前期，刚好在春运这个时间点。最后，希望各位能够正视这次疫情，不传谣，不信谣，没有必要恐慌，但也不要掉以轻心，勤洗手、戴口罩、不去人多的地方凑热闹，按照疾控中心发布的预防指南做好预防工作，相信政府也相信我们的医护人员，如果出现症状，也不必恐慌，就近就诊，如实说明病情。保护好自己就是对自己对家人最好的保护。#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '1794555830',
 'username': '谦大江',
 'weibo_url': 'https://weibo.com/1794555830/IqziyF1Eu'}
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1989779131_IqziyowXb',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 20 Pro',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '1989779131',
 'username': '杨影枫',
 'weibo_url': 'https://weibo.com/1989779131/IqziyowXb'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5538732325_Iqziy5JSu',
 'image_url': 'http://wx1.sinaimg.cn/wap180/0062PXilgy1gb4mkyaddyj30k00hj3yu.jpg',
 'reply_count': 2,
 'retweet_count': 0,
 'source': 'jjjjjackyiPhone客户端',
 'text': '#四川确诊首例新型肺炎#我爸今天回来说身边有人接触过刚从武汉回来的人，我现在慌得要死',
 'user': '5538732325',
 'username': 'QiAnn7',
 'weibo_url': 'https://weibo.com/5538732325/Iqziy5JSu'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '3860256970_Iqzix9rcI',
 'origin_weibo': 'https://weibo.cn/comment/IqyXc0hgW?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P20',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！（央视新闻）#黄冈新增12例新型肺炎##武汉新型肺炎患者救治由政府买单#http://t.cn/A6vdVkn7',
 'user': '3860256970',
 'username': '丫牙915',
 'weibo_url': 'https://weibo.com/3860256970/Iqzix9rcI'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '3025162335_IqziwAHue',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P20',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '3025162335',
 'username': 'aboutQ-',
 'weibo_url': 'https://weibo.com/3025162335/IqziwAHue'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 3,
 'id_str': '5044511176_Iqziwzka4',
 'reply_count': 0,
 'retweet_count': 1,
 'text': '【#昆明确诊首例新型肺炎病例#】患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。(人民日报)',
 'user': '5044511176',
 'username': '中国搜索',
 'weibo_url': 'https://weibo.com/5044511176/Iqziwzka4'}
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 3,
 'id_str': '2094844082_IqziwxKhS',
 'place': '湖北省·恩施土家族苗族自治州',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '全中国都在讨论新型肺炎而我在湖北准备过年离武汉好远但是也害怕的买了口罩去外面饭店吃饭选择了吃素菜然后抓紧来到了乡下过完年扫个墓就赶紧回我大广东！',
 'user': '2094844082',
 'username': '我就是狗粮吃多了',
 'weibo_url': 'https://weibo.com/2094844082/IqziwxKhS'}
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:26:26',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1807664190_IqziwxKfP',
 'image_url': 'http://wx1.sinaimg.cn/wap180/a716fd45ly1gb4mg1u6z3j20ob0obk0y.jpg',
 'origin_weibo': 'https://weibo.cn/comment/IqzgHrEV4?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 20',
 'text': '【#山东确诊1例新型肺炎病例#】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。',
 'user': '1807664190',
 'username': '飞砂风中转2001',
 'weibo_url': 'https://weibo.com/1807664190/IqziwxKfP'}
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1794555830/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6920592819/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/7062111388/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5044511176/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3025162335/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3860256970/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5538732325/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1989779131/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1807664190/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2094844082/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89%20%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '3230317920_Iqziwkb9E',
 'image_url': 'http://wx3.sinaimg.cn/wap180/c08abd60ly1gb4mkxwyg3j20sg0izmxl.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 10 Pro',
 'text': '【喝板蓝根和熏醋可以预防武汉肺炎？不可以！】武汉肺炎发生以来，囤板蓝根、熏醋的声音越来越多，甚至一度渲染成为预防的“黄金组合”，那么它们真能预防武汉肺炎吗？和平里医院呼吸科主任医师张骅称：板蓝根适用于治疗风热感冒、病毒性感冒等热性疾病的治疗，有一定的抗病毒效果，但是对冠状病毒是不可能有效的。熏醋，所含醋酸本身浓度就很低，根本达不到消毒的效果。不信谣不传谣！via健康中国',
 'user': '3230317920',
 'username': '陇南日报',
 'weibo_url': 'https://weibo.com/3230317920/Iqziwkb9E'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 1,
 'id_str': '6043703345_IqziwhcfS',
 'image_url': 'http://wx3.sinaimg.cn/wap180/62bfd143ly1gb4lqfyq3zj20u01dn10w.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqz7oChNQ?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 3,
 'text': '北京新增的五例新性肺炎，五位近期都去过武汉，有两位只去了一天就已经感染。我不由得想，武汉到底已经严重成什么样？真的只有官方报道的两百多例吗？',
 'user': '6043703345',
 'username': '收到请回富',
 'weibo_url': 'https://weibo.com/6043703345/IqziwhcfS'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '3989509305_Iqziwg6W6',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 10',
 'text': '『正滚动播报“武汉新型肺炎”全国疫情实时动态_新浪直播间』正滚动播报“武汉新型肺炎”全国疫情实时动态',
 'user': '3989509305',
 'username': '婷婷走走nanna',
 'weibo_url': 'https://weibo.com/3989509305/Iqziwg6W6'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5533637161_IqzivqOvc',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone 8',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '5533637161',
 'username': '-isluluna',
 'weibo_url': 'https://weibo.com/5533637161/IqzivqOvc'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1748828707_IqzivnPKS',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 3,
 'source': '微博 weibo.com',
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '1748828707',
 'username': '_織田七海',
 'weibo_url': 'https://weibo.com/1748828707/IqzivnPKS'}
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 2,
 'id_str': '2515943601_Iqziv7Yr2',
 'image_url': 'http://wx2.sinaimg.cn/wap180/95f640b1ly1gb4mkisvf5j20u017qqfp.jpg',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'HUAWEI P30',
 'text': '【#重庆确诊5例新型肺炎#病例：均有武汉工作史或居住史】重庆卫健委网站消息，今晚，国家卫健委确认重庆市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为44岁女性，巫山县人，15日自武汉返回巫山县后，因发热、乏力等症状，于当日在巫山县一发热门诊就诊后即被收治入院隔离治疗。另外，经重庆市疾控中心实验室检测，市诊断专家组评估确认新型冠状病毒感染的肺炎确诊病例4例。截至今晚18时，重庆累计报告新型冠状病毒感染的肺炎确诊病例5例，其中：巫山县2例、万州区2例、长寿区1例。所有病例均有武汉工作史或居住史。目前5名患者在定点医疗机构接受诊治，病情稳定。对72名密切接触者实施医学观察，目前无发热等异常情况。据央视新闻',
 'user': '2515943601',
 'username': '都市热报',
 'weibo_url': 'https://weibo.com/2515943601/Iqziv7Yr2'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 2,
 'id_str': '5798006881_Iqziv989u',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '华为手机',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#中国加油！武汉加油！我们永远在一起！每个人都要平平安安呐！！！',
 'user': '5798006881',
 'username': '_从心白白',
 'weibo_url': 'https://weibo.com/5798006881/Iqziv989u'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '6037497446_IqziuxpIZ',
 'reply_count': 1,
 'retweet_count': 0,
 'source': '路上捡的iPhone客户端',
 'text': '超级流感严重还是武汉肺炎严重。。。。医学小白求问',
 'user': '6037497446',
 'username': 'kpovess',
 'weibo_url': 'https://weibo.com/6037497446/IqziuxpIZ'}
2020-01-22 16:26:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2>
{'crawled_at': '2020-01-22 16:26:38',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1405484094_IqzitE41c',
 'image_url': 'http://wx1.sinaimg.cn/wap180/006ySZxAgy1gb4k65npqzj31fb0u0tfw.jpg',
 'origin_weibo': 'https://weibo.cn/comment/IqyKLAS8u?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '【武汉一患者感染14名医护人员，可认定为超级传播者】在1月21日16时广东省政府新闻办举办的新闻发布会上，钟南山透露，“在武汉就出现了一个病人影响了14个医护人员的案例，这个并没有出现在传染病医院，而是出现在不是收传染病人的地方——神经科。所以我们要关注所有的医护人员（的防疫问题）。”北京大学一位专家指出，这位感染多位医务人员的患者可以被认定为超级传播者。在感染人数判断上，如果感染人数超过三个，就可以考虑在超级传播者的范围内；如果感染人数超过十个，就应该是比较确切的超级传播者。（中国新闻周刊）',
 'user': '1405484094',
 'username': '盛叶美树',
 'weibo_url': 'https://weibo.com/1405484094/IqzitE41c'}
2020-01-22 16:26:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1794555830> (referer: https://weibo.cn/1794555830/info)
2020-01-22 16:26:39	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:39	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1794555830>
{'authentication': '旅游博主 头条文章作者',
 'birthday': '水瓶座',
 'brief_introduction': '喜马拉雅FM旅行节目《行走的背包》主播 大江  微信公众号：大江星球（dajiangplante）',
 'city': '静安区',
 'crawled_at': '2020-01-22 16:26:39',
 'fans_num': 20413,
 'follows_num': 1036,
 'gender': '男',
 'id': '1794555830',
 'labels': '行走的背包,旅行,心情',
 'name': '谦大江',
 'province': '上海',
 'sentiment': '暗恋中',
 'tweets_num': 635,
 'vip_level': '4级'}
2020-01-22 16:26:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6920592819> (referer: https://weibo.cn/6920592819/info)
2020-01-22 16:26:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6920592819>
{'birthday': '愿望是要快乐',
 'brief_introduction': '看到我叫我去学习',
 'crawled_at': '2020-01-22 16:26:40',
 'fans_num': 96,
 'follows_num': 409,
 'gender': '女',
 'id': '6920592819',
 'name': '生日愿望是要快乐',
 'province': '广东',
 'tweets_num': 3081,
 'vip_level': '3级'}
2020-01-22 16:26:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/7062111388> (referer: https://weibo.cn/7062111388/info)
2020-01-22 16:26:42	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:42	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/7062111388>
{'brief_introduction': '想爱，想死，这是他的两个愿望',
 'crawled_at': '2020-01-22 16:26:42',
 'fans_num': 31,
 'follows_num': 654,
 'gender': '女',
 'id': '7062111388',
 'name': '妮妮还是可爱',
 'province': '贵州',
 'tweets_num': 2264,
 'vip_level': '未开通'}
2020-01-22 16:26:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5044511176> (referer: https://weibo.cn/5044511176/info)
2020-01-22 16:26:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:43	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5044511176>
{'authentication': '中国搜索(chinaso.com)官方微博',
 'birthday': '2014-01-01',
 'brief_introduction': '中国搜索（简称“国搜”，www.chinaso.com）是由中央七大新闻单位——人民日报、新华社、中央电视台、光明日报、经济日报、中国日报、中国新闻社联手打造的国家级互联网高新企业，强大的跨媒体、融媒体、新媒体传播载体，权威的互联网百科、数据、资料库，丰富多彩的互联网+创新应用平台。',
 'crawled_at': '2020-01-22 16:26:43',
 'fans_num': 2382191,
 'follows_num': 1187,
 'gender': '男',
 'id': '5044511176',
 'labels': '中国搜索',
 'name': '中国搜索',
 'province': '北京',
 'tweets_num': 28025,
 'vip_level': '5级'}
2020-01-22 16:26:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3025162335> (referer: https://weibo.cn/3025162335/info)
2020-01-22 16:26:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3025162335>
{'brief_introduction': '认真生活！',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:26:45',
 'fans_num': 148,
 'follows_num': 474,
 'gender': '男',
 'id': '3025162335',
 'name': 'aboutQ-',
 'province': '广东',
 'tweets_num': 561,
 'vip_level': '未开通'}
2020-01-22 16:26:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3860256970> (referer: https://weibo.cn/3860256970/info)
2020-01-22 16:26:46	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3860256970>
{'birthday': '1989-06-13',
 'brief_introduction': '人生就是一场修行。不乱于心，方能始终。',
 'city': '福州',
 'crawled_at': '2020-01-22 16:26:46',
 'fans_num': 74,
 'follows_num': 441,
 'gender': '女',
 'id': '3860256970',
 'labels': '搞笑幽默,福州生活,职场招聘',
 'name': '丫牙915',
 'province': '福建',
 'tweets_num': 713,
 'vip_level': '未开通'}
2020-01-22 16:26:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5538732325> (referer: https://weibo.cn/5538732325/info)
2020-01-22 16:26:47	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5538732325>
{'authentication': '王嘉尔超话粉丝大咖',
 'birthday': '1998-09-20',
 'city': '德阳',
 'crawled_at': '2020-01-22 16:26:47',
 'fans_num': 100,
 'follows_num': 81,
 'gender': '女',
 'id': '5538732325',
 'name': 'QiAnn7',
 'province': '四川',
 'tweets_num': 215,
 'vip_level': '4级'}
2020-01-22 16:26:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1989779131> (referer: https://weibo.cn/1989779131/info)
2020-01-22 16:26:47	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1989779131>
{'birthday': '1990-09-01',
 'brief_introduction': '萧瑟秋风今又是',
 'city': '泉州',
 'crawled_at': '2020-01-22 16:26:47',
 'fans_num': 435,
 'follows_num': 366,
 'gender': '男',
 'id': '1989779131',
 'labels': 'IT数码,广播剧,文字控',
 'name': '杨影枫',
 'province': '福建',
 'tweets_num': 3210,
 'vip_level': '5级'}
2020-01-22 16:26:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1807664190> (referer: https://weibo.cn/1807664190/info)
2020-01-22 16:26:49	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1807664190>
{'birthday': '1983-01-08',
 'brief_introduction': '练一身炒股本领，拼一轮牛熊传奇，赢一个无悔人生',
 'crawled_at': '2020-01-22 16:26:49',
 'fans_num': 767,
 'follows_num': 2187,
 'gender': '男',
 'id': '1807664190',
 'labels': '听歌,美食,旅行',
 'name': '飞砂风中转2001',
 'province': '山东',
 'tweets_num': 3524,
 'vip_level': '未开通'}
2020-01-22 16:26:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2094844082> (referer: https://weibo.cn/2094844082/info)
2020-01-22 16:26:50	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2094844082>
{'birthday': '双子座',
 'brief_introduction': '微博认证：脾气暴躁易怒表演艺术家',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:26:50',
 'fans_num': 1194,
 'follows_num': 117,
 'gender': '女',
 'id': '2094844082',
 'labels': '健身爱好者,唱歌,双子座',
 'name': '我就是狗粮吃多了',
 'province': '广东',
 'sex_orientation': '异性恋',
 'tweets_num': 165,
 'vip_level': '6级'}
2020-01-22 16:26:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1748828707/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5533637161/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3989509305/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6043703345/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3230317920/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1405484094/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:26:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6037497446/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:26:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:00	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5798006881/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:27:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2515943601/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:27:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=2)
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1221228832_IqzitB9uI',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀畅玩8C',
 'text': '#武汉新型肺炎患者救治由政府买单#个sars一样吗？如何落实？',
 'user': '1221228832',
 'username': '斯巴-达克斯',
 'weibo_url': 'https://weibo.com/1221228832/IqzitB9uI'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5506416622_IqzitjtEN',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '三星android智能手机',
 'text': '我分享了文章武汉肺炎康复患者一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深...',
 'user': '5506416622',
 'username': '来自天空中的风',
 'weibo_url': 'https://weibo.com/5506416622/IqzitjtEN'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '2254575713_Iqzit1ScM',
 'origin_weibo': 'https://weibo.cn/comment/IqyScgVMq?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#新型冠状病毒肺炎最新情况#【转发了解！#武汉新型肺炎潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！#北京新增5例新型肺炎病例#央视新闻的微博视频',
 'user': '2254575713',
 'username': 'FanFan_范范_',
 'weibo_url': 'https://weibo.com/2254575713/Iqzit1ScM'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 19,
 'id_str': '2706574710_Iqzit1PPR',
 'image_url': 'http://wx1.sinaimg.cn/wap180/a1530d76ly1gb4mkbtobnj20rs18g7c8.jpg',
 'reply_count': 0,
 'retweet_count': 1,
 'text': '#四川确诊首例新型肺炎#刚才刷视频有记者暗访发现武汉还有些商家卖野味，真的是良心何在，钱真的比命更重要吗？不知道有没有刷到那个视频的',
 'user': '2706574710',
 'username': '只会拍照',
 'weibo_url': 'https://weibo.com/2706574710/Iqzit1PPR'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 3,
 'id_str': '6019664190_IqzisboF4',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'OnePlus 7 Pro',
 'text': '#北京新增5例新型肺炎病例#去武汉呆了一天就感染了突然有点怕，希望大家都健健康康的',
 'user': '6019664190',
 'username': '跟哥闭馆日去故宫',
 'weibo_url': 'https://weibo.com/6019664190/IqzisboF4'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 37,
 'id_str': '2030717731_Iqzisa3HU',
 'reply_count': 11,
 'retweet_count': 7,
 'text': '#国内确诊291例新型冠状病毒肺炎病例#武汉首例重症新型肺炎出院患者发声，详细讲述了被隔离治疗的经过。一手video的秒拍视频',
 'user': '2030717731',
 'username': '武汉路边社',
 'weibo_url': 'https://weibo.com/2030717731/Iqzisa3HU'}
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1923459965_Iqziri4Yn',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '不想上班的iPhone客户端',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '1923459965',
 'username': '岛主黄老邪是一棵健康的盆栽',
 'weibo_url': 'https://weibo.com/1923459965/Iqziri4Yn'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1725486022_Iqzir1uk9',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '1725486022',
 'username': '尔康他外甥',
 'weibo_url': 'https://weibo.com/1725486022/Iqzir1uk9'}
2020-01-22 16:27:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3>
{'crawled_at': '2020-01-22 16:27:02',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 2,
 'id_str': '1150584951_IqziqpNCs',
 'image_url': 'http://wx1.sinaimg.cn/wap180/44948877ly1gb4mj1fezrj205c040t9g.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '华为畅享10 Plus',
 'text': '本次不明原因的病毒性肺炎病例的病原体初步判定为新型冠状病毒问题一：武汉不明原因的病毒性肺炎疫情病原学鉴定有什么进展？徐建国表示，截至2020年1月7日21时，实验室检出一种新型冠状病毒，获得该病毒的全基因组序列，经核酸检测方法共检出新型冠状病毒阳性结果15例，从1例阳性病人样本中分离出该病毒，电镜下呈现典型的冠状病毒形态。专家组认为，本次不明原因的病毒性肺炎病例的病原体初步判定为新型冠状病毒。问题二：本次病原学鉴定是如何组织开展的?组织实验室采用基因组测...http://t.cn/A6vd82Ay',
 'user': '1150584951',
 'username': '小月弯弯微博',
 'weibo_url': 'https://weibo.com/1150584951/IqziqpNCs'}
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1748828707> (referer: https://weibo.cn/1748828707/info)
2020-01-22 16:27:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1748828707>
{'brief_introduction': '(／・ω・)／博爱党，不定时刷屏＼(・ω・＼)',
 'city': '徐汇区',
 'crawled_at': '2020-01-22 16:27:04',
 'fans_num': 112,
 'follows_num': 554,
 'gender': '女',
 'id': '1748828707',
 'name': '_織田七海',
 'province': '上海',
 'tweets_num': 3126,
 'vip_level': '5级'}
2020-01-22 16:27:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5533637161> (referer: https://weibo.cn/5533637161/info)
2020-01-22 16:27:05	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:05	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5533637161>
{'brief_introduction': '看什么看',
 'crawled_at': '2020-01-22 16:27:05',
 'fans_num': 229,
 'follows_num': 539,
 'gender': '女',
 'id': '5533637161',
 'name': '-isluluna',
 'province': '其他',
 'tweets_num': 82,
 'vip_level': '3级'}
2020-01-22 16:27:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3989509305> (referer: https://weibo.cn/3989509305/info)
2020-01-22 16:27:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:06	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3989509305>
{'birthday': '1983-04-26',
 'brief_introduction': '微信：weiting492556315，南娜回归自然的生活！',
 'city': '昌吉',
 'crawled_at': '2020-01-22 16:27:06',
 'fans_num': 181,
 'follows_num': 744,
 'gender': '女',
 'id': '3989509305',
 'name': '婷婷走走nanna',
 'province': '新疆',
 'tweets_num': 497,
 'vip_level': '未开通'}
2020-01-22 16:27:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6043703345> (referer: https://weibo.cn/6043703345/info)
2020-01-22 16:27:07	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6043703345>
{'authentication': '一只清单超话主持人',
 'birthday': '双鱼座',
 'brief_introduction': '钱国人民富起来了！',
 'crawled_at': '2020-01-22 16:27:07',
 'fans_num': 9889,
 'follows_num': 326,
 'gender': '女',
 'id': '6043703345',
 'name': '收到请回富',
 'province': '北京',
 'tweets_num': 16318,
 'vip_level': '5级'}
2020-01-22 16:27:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3230317920> (referer: https://weibo.cn/3230317920/info)
2020-01-22 16:27:08	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3230317920>
{'authentication': '《陇南日报》官方微博',
 'birthday': '0001-00-00',
 'brief_introduction': '一个核心价值体系凝聚的高地一个主流媒体舆论传播的平台一个观点互动网民交流的家园  '
                       '我们是陇南日报官方微博，让我们见证、记录陇南发展！新闻热线：0939-8211211 '
                       '广告经营：0939-8213340',
 'crawled_at': '2020-01-22 16:27:08',
 'fans_num': 321724,
 'follows_num': 1556,
 'gender': '男',
 'id': '3230317920',
 'labels': '新闻传播',
 'name': '陇南日报',
 'province': '甘肃',
 'tweets_num': 38615,
 'vip_level': '未开通'}
2020-01-22 16:27:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1405484094> (referer: https://weibo.cn/1405484094/info)
2020-01-22 16:27:10	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1405484094>
{'birthday': '双子座',
 'brief_introduction': '会当凌绝顶，坐看云起时。',
 'crawled_at': '2020-01-22 16:27:10',
 'fans_num': 606,
 'follows_num': 3085,
 'gender': '女',
 'id': '1405484094',
 'name': '盛叶美树',
 'province': '其他',
 'tweets_num': 1776,
 'vip_level': '6级'}
2020-01-22 16:27:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6037497446> (referer: https://weibo.cn/6037497446/info)
2020-01-22 16:27:11	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6037497446>
{'birthday': '1995-01-13',
 'brief_introduction': '一个无趣的人',
 'crawled_at': '2020-01-22 16:27:11',
 'fans_num': 526,
 'follows_num': 930,
 'gender': '男',
 'id': '6037497446',
 'name': 'kpovess',
 'province': '陕西',
 'tweets_num': 1047,
 'vip_level': '4级'}
2020-01-22 16:27:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5798006881> (referer: https://weibo.cn/5798006881/info)
2020-01-22 16:27:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5798006881>
{'crawled_at': '2020-01-22 16:27:13',
 'fans_num': 46,
 'follows_num': 357,
 'gender': '女',
 'id': '5798006881',
 'name': '_从心白白',
 'province': '云南',
 'tweets_num': 201,
 'vip_level': '未开通'}
2020-01-22 16:27:14	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2515943601> (referer: https://weibo.cn/2515943601/info)
2020-01-22 16:27:14	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2515943601>
{'authentication': '《都市热报》官方微博',
 'birthday': '2011-11-23',
 'brief_introduction': '都市热报微博一网打尽网络热门话题，随时随地与你分享新鲜事！',
 'city': '渝中区',
 'crawled_at': '2020-01-22 16:27:14',
 'fans_num': 1062502,
 'follows_num': 260,
 'gender': '男',
 'id': '2515943601',
 'name': '都市热报',
 'province': '重庆',
 'tweets_num': 17379,
 'vip_level': '4级'}
2020-01-22 16:27:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6019664190/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2706574710/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5506416622/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2254575713/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1221228832/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1725486022/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1923459965/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:24	scrapy.extensions.logstats	INFO	Crawled 48 pages (at 48 pages/min), scraped 47 items (at 47 items/min)
2020-01-22 16:27:25	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1150584951/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2030717731/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=3)
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 12,
 'id_str': '1659336417_IqziqpNb7',
 'image_url': 'http://wx4.sinaimg.cn/wap180/62e776e1gy1gb4mkn3tumj20o71ci7be.jpg',
 'place': True,
 'reply_count': 0,
 'retweet_count': 3,
 'source': '禅韵书画Android',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#【云南#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。（央视记者王溪）',
 'user': '1659336417',
 'username': '禅韵书画',
 'weibo_url': 'https://weibo.com/1659336417/IqziqpNb7'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 4,
 'id_str': '1691032500_Iqziohtxr',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '2019年12月21日，也就是上个月，我参加了全国研究生统考。那天下着大雨，我没带伞，出了考场在武大门口的报亭躲雨，当时想着失落也不过如此。元旦三天，我在广东，看着微博爆出武汉发现新型肺炎病毒，当时并没有太在意，虽然03年非典我并没有什么印象，但是心里相信17年后国家不会再爆发当年那种疫情。现在，我退了所有出行的票，决定在家呆着不出门度过整个春运。生命面前，都是小事。就像说道说道而已。',
 'user': '1691032500',
 'username': 'Yovchiyaya',
 'weibo_url': 'https://weibo.com/1691032500/Iqziohtxr'}
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5819036117_IqzilFlWY',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀8X Max',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '5819036117',
 'username': '牛油果拌饭亚',
 'weibo_url': 'https://weibo.com/5819036117/IqzilFlWY'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 1,
 'id_str': '2729433175_IqzilEbEn',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#在武汉上班或要出去旅游的，能别往外跑了，求你们了行不',
 'user': '2729433175',
 'username': 'SUPER可爱超级洋',
 'weibo_url': 'https://weibo.com/2729433175/IqzilEbEn'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 9,
 'id_str': '3041787370_IqzilEaqT',
 'reply_count': 2,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#真的心塞，当年非典年少不懂事，现在每天跟着新闻着急，看着武汉沦陷心在滴血.....',
 'user': '3041787370',
 'username': '会跑路的小香瓜',
 'weibo_url': 'https://weibo.com/3041787370/IqzilEaqT'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 24,
 'id_str': '5329116942_IqzilCtdZ',
 'image_url': 'http://wx4.sinaimg.cn/wap180/005OEqL4ly1gb4mkfhs17j30ob0obdiy.jpg',
 'reply_count': 9,
 'retweet_count': 11,
 'text': '【#山东确诊1例新型肺炎病例#】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。',
 'user': '5329116942',
 'username': '济南生活',
 'weibo_url': 'https://weibo.com/5329116942/IqzilCtdZ'}
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5580873139_IqzilmubX',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Ykk小尾巴Android',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '5580873139',
 'username': 'WR微微一笑很倾城',
 'weibo_url': 'https://weibo.com/5580873139/IqzilmubX'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1841274207_Iqzil3DH5',
 'origin_weibo': 'https://weibo.cn/comment/IqyFWxLU9?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 30',
 'text': '【钟南山：肺炎疫情在武汉局部暴发建议原则上不进不出】国家卫健委高级别专家组组长钟南山20日对记者表示，新型冠状病毒感染的肺炎疫情目前在武汉局部暴发，近期防控要点仍应针对武汉地区，建议原则上不去武汉、不出武汉。新华视点的秒拍视频',
 'user': '1841274207',
 'username': '小花7777777',
 'weibo_url': 'https://weibo.com/1841274207/Iqzil3DH5'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 309,
 'id_str': '7281473317_Iqzikrs5A',
 'reply_count': 27,
 'retweet_count': 15,
 'source': 'HUAWEI P20 Pro',
 'text': '武汉肺炎还给港台年轻人上了一堂祖国的地理课',
 'user': '7281473317',
 'username': '编辑下山',
 'weibo_url': 'https://weibo.com/7281473317/Iqzikrs5A'}
2020-01-22 16:27:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4>
{'crawled_at': '2020-01-22 16:27:27',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 1,
 'id_str': '1959451603_IqzijAWEa',
 'image_url': 'http://wx2.sinaimg.cn/wap180/74cadbd3gy1gb4mkeu5j5j20m80cqq3k.jpg',
 'reply_count': 0,
 'retweet_count': 1,
 'source': 'iPhone客户端',
 'text': '【#昆明确诊首例新型肺炎病例#】患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。@人民日报',
 'user': '1959451603',
 'username': '成都日报锦观',
 'weibo_url': 'https://weibo.com/1959451603/IqzijAWEa'}
2020-01-22 16:27:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6019664190> (referer: https://weibo.cn/6019664190/info)
2020-01-22 16:27:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6019664190>
{'birthday': '1996-11-05',
 'brief_introduction': '你们好酸',
 'city': '东城区',
 'crawled_at': '2020-01-22 16:27:29',
 'fans_num': 116,
 'follows_num': 491,
 'gender': '男',
 'id': '6019664190',
 'labels': '考研',
 'name': '跟哥闭馆日去故宫',
 'province': '北京',
 'tweets_num': 423,
 'vip_level': '未开通'}
2020-01-22 16:27:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2706574710> (referer: https://weibo.cn/2706574710/info)
2020-01-22 16:27:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:30	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2706574710>
{'authentication': '时尚博主 视频自媒体 微博签约自媒体',
 'birthday': '天蝎座',
 'crawled_at': '2020-01-22 16:27:30',
 'fans_num': 229235,
 'follows_num': 114,
 'gender': '女',
 'id': '2706574710',
 'labels': '语录,历史讲坛,A股',
 'name': '只会拍照',
 'province': '北京',
 'tweets_num': 522,
 'vip_level': '6级'}
2020-01-22 16:27:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5506416622> (referer: https://weibo.cn/5506416622/info)
2020-01-22 16:27:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:31	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5506416622>
{'birthday': '1973-04-14',
 'city': '湘西土家族苗族自治州',
 'crawled_at': '2020-01-22 16:27:31',
 'fans_num': 458,
 'follows_num': 628,
 'gender': '男',
 'id': '5506416622',
 'labels': 'IT科技,美女,八卦杂谈',
 'name': '来自天空中的风',
 'province': '湖南',
 'tweets_num': 750,
 'vip_level': '未开通'}
2020-01-22 16:27:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2254575713> (referer: https://weibo.cn/2254575713/info)
2020-01-22 16:27:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:32	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2254575713>
{'birthday': '0001-00-00',
 'city': '邢台',
 'crawled_at': '2020-01-22 16:27:32',
 'fans_num': 83,
 'follows_num': 177,
 'gender': '女',
 'id': '2254575713',
 'name': 'FanFan_范范_',
 'province': '河北',
 'tweets_num': 1127,
 'vip_level': '未开通'}
2020-01-22 16:27:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1221228832> (referer: https://weibo.cn/1221228832/info)
2020-01-22 16:27:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:27:33	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1221228832>
{'birthday': '0001-00-00',
 'brief_introduction': '冬天里的启明星！',
 'city': '石家庄',
 'crawled_at': '2020-01-22 16:27:33',
 'fans_num': 3242,
 'follows_num': 5309,
 'gender': '男',
 'id': '1221228832',
 'labels': '时尚,旅行,旅游',
 'name': '斯巴-达克斯',
 'province': '河北',
 'tweets_num': 7128,
 'vip_level': '未开通'}
2020-01-22 16:27:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1725486022> (referer: https://weibo.cn/1725486022/info)
2020-01-22 16:27:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1725486022>
{'birthday': '水瓶座',
 'crawled_at': '2020-01-22 16:27:34',
 'fans_num': 872,
 'follows_num': 1443,
 'gender': '女',
 'id': '1725486022',
 'name': '尔康他外甥',
 'province': '其他',
 'tweets_num': 6674,
 'vip_level': '未开通'}
2020-01-22 16:27:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1923459965> (referer: https://weibo.cn/1923459965/info)
2020-01-22 16:27:35	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1923459965>
{'birthday': '1994-02-25',
 'brief_introduction': '草木有本心 何求美人折',
 'city': '杭州',
 'crawled_at': '2020-01-22 16:27:35',
 'fans_num': 1273,
 'follows_num': 812,
 'gender': '女',
 'id': '1923459965',
 'labels': '社畜',
 'name': '岛主黄老邪是一棵健康的盆栽',
 'province': '浙江',
 'tweets_num': 5295,
 'vip_level': '6级'}
2020-01-22 16:27:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1150584951> (referer: https://weibo.cn/1150584951/info)
2020-01-22 16:27:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1150584951>
{'birthday': '0001-00-00',
 'brief_introduction': '我的图书馆',
 'city': '南开区',
 'crawled_at': '2020-01-22 16:27:37',
 'fans_num': 76,
 'follows_num': 42,
 'gender': '男',
 'id': '1150584951',
 'labels': '旅游,军事,IT数码',
 'name': '小月弯弯微博',
 'province': '天津',
 'tweets_num': 2750,
 'vip_level': '4级'}
2020-01-22 16:27:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2030717731> (referer: https://weibo.cn/2030717731/info)
2020-01-22 16:27:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2030717731>
{'authentication': '本地资讯博主（武汉）',
 'birthday': '01-01',
 'brief_introduction': '关于武汉的七里八里。你值得关注！微信号 wuhanlbs 投稿请@武汉路边社。合作请加QQ745336',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:27:38',
 'fans_num': 605219,
 'follows_num': 1780,
 'gender': '男',
 'id': '2030717731',
 'labels': '武汉去哪儿？,武汉身边事,武汉生活',
 'name': '武汉路边社',
 'province': '湖北',
 'sentiment': '求交往',
 'sex_orientation': '异性恋',
 'tweets_num': 27578,
 'vip_level': '7级'}
2020-01-22 16:27:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1659336417/IqziqpNb7> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/1659336417/IqziqpNb7>
{'crawled_at': '2020-01-22 16:29:20',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 12,
 'id_str': '1659336417_IqziqpNb7',
 'image_url': 'http://wx4.sinaimg.cn/wap180/62e776e1gy1gb4mkn3tumj20o71ci7be.jpg',
 'place': '昆明',
 'reply_count': 0,
 'retweet_count': 3,
 'source': '禅韵书画Android',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#【云南#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。（央视记者王溪）',
 'user': '1659336417',
 'username': '禅韵书画',
 'weibo_url': 'https://weibo.com/1659336417/IqziqpNb7'}
2020-01-22 16:29:20	scrapy.extensions.logstats	INFO	Crawled 61 pages (at 13 pages/min), scraped 67 items (at 20 items/min)
2020-01-22 16:29:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1659336417/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3041787370/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2729433175/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5819036117/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:24	scrapy.extensions.logstats	INFO	Crawled 65 pages (at 4 pages/min), scraped 67 items (at 0 items/min)
2020-01-22 16:29:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1691032500/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/7281473317/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1959451603/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1841274207/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5580873139/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5329116942/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=4)
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 180,
 'id_str': '1686546714_IqzijAT8x',
 'image_url': 'http://wx1.sinaimg.cn/wap180/6486a91aly1gb4mkb3ns3j21pc1pcgt5.jpg',
 'reply_count': 43,
 'retweet_count': 37,
 'text': '【#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。（央视新闻）',
 'user': '1686546714',
 'username': '环球网',
 'weibo_url': 'https://weibo.com/1686546714/IqzijAT8x'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 1,
 'id_str': '3519421583_Iqzijy6o1',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '#昆明确诊首例新型肺炎#微博每刷新一次就看到一个新的地区出现一例新型肺炎的新闻武汉加油啊',
 'user': '3519421583',
 'username': '再见萤火虫-FZ',
 'weibo_url': 'https://weibo.com/3519421583/Iqzijy6o1'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1249157091_Iqzij2Kn5',
 'reply_count': 2,
 'retweet_count': 1,
 'source': 'iPhone X',
 'text': '那8个普通群众怀疑武汉肺炎需依法配合调查，专家才有权力向媒体表态“可控”，是控了个啥呢？现在说啥都没查清楚呢，还需要时间，需要时间没问题，你没查清楚咋就能说“可控”你控啥呢？这是对人民群众负责任的专家吗？',
 'user': '1249157091',
 'username': '咸淡猪手',
 'weibo_url': 'https://weibo.com/1249157091/Iqzij2Kn5'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5971931070_IqzihdFXo',
 'origin_weibo': 'https://weibo.cn/comment/IqyScgVMq?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '#新型冠状病毒肺炎最新情况#【转发了解！#武汉新型肺炎潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！#北京新增5例新型肺炎病例#央视新闻的微博视频',
 'user': '5971931070',
 'username': '山栀子0923',
 'weibo_url': 'https://weibo.com/5971931070/IqzihdFXo'}
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1597301333_IqzigD82h',
 'origin_weibo': 'https://weibo.cn/comment/IqyVDBV7L?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '心理学上关于人的非理性思维，一个说烂了的例子是，明明每单位里程的交通事故死亡率，飞机远低于汽车，人们却认为飞机出行更不安全，原因在于飞机失事的新闻影像报道留给人的印象太生动鲜活。类似地，去年春节流感疫情远超过往几年，仅1月全国感染人数就高达608511人，死亡143人，相当于2018年全年流感死亡人数（144人），但印象中去年春节流感从未成为过热议话题。相比之下，目前的情况根据已有的有限证据和国内外专家的背书，并不认为会甚于2003年的非典，但大家所表现出的关切程度远甚于过往任何一次已知或未知病毒的传播，究其原因大概是当年非典的惨痛教训令人印象太深刻。那说到非典，全国患病人数4698人，死亡284人，令人悲痛万分，可是，它却并非2003年上半年死亡人数和病死率最高的传染病，最高的是什么，是狂犬病，发病人数545人，死亡490人，此后几年死亡人数甚至逐年攀升。同样是数百条同胞生命的逝去，我们可曾为后者感到悲痛呢？我们可曾为此后狂犬病死亡人数的持续增加的态势发出过呼喊呢？再说到非典时期因为前期瞒报掩饰而造成疫情最严重的北京，患病人数2434人，死亡147人，再比上北京市常住人口1500万的基数（考虑到患者中实际上包含外地游客，这个基数应该上调），自己去算概率。作为一个春节需要出行的人，在仔细评估过上述情况和数据并了解了有关部门采取的公共预防措施之后我做了出行的决定，我认为这是一个理性的决策，我也做好了承担相应风险的心理准备。我实在不能理解那种全市出现一个疑似病例就呼吁大家不要出门的吃瓜群众，更不能理解那种要求全国公共交通都停止运行的极端声音。全国每年机动车交通事故死亡十几万人，情况比一般的传染病严重上百倍，那是不是早该立法禁止开车干脆把公路都改成步行街呢？人命当然是宝贵的，可任何的小到个体决策大到公共政策，最终都需要在人命与别的因素之间做出权衡。一个人怕死永远地足不出户大概在这个时代活一辈子是没有问题的，但如果所有人都足不出户这个社会就崩溃了谁也别想活。怕死是人的本能，在此基础之上的适度恐慌也是人之常情，但是群体层面上呈现出过度的非理性，是我在任何议题中都不乐见的现象，我从不认为群体的过度非理性能在整体上有利于社会（也就是所有人）的福祉。【本文故意不分段。】',
 'user': '1597301333',
 'username': 'MadaoIkari',
 'weibo_url': 'https://weibo.com/1597301333/IqzigD82h'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '3771702070_IqzigAmZn',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#已经放弃了去武汉过年的计划体质差的人伤不起',
 'user': '3771702070',
 'username': '小戴小戴时亨运泰',
 'weibo_url': 'https://weibo.com/3771702070/IqzigAmZn'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '2101415084_Iqzig3Mnl',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '新浪科技',
 'text': '“武汉肺炎”疫情三问“武汉肺炎”疫情三问',
 'user': '2101415084',
 'username': '靠谱不得',
 'weibo_url': 'https://weibo.com/2101415084/Iqzig3Mnl'}
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5238845563_Iqziftitu',
 'origin_weibo': 'https://weibo.cn/comment/Iqyfwl5qK?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'vivo AI智慧拍照X21',
 'text': '脱下穿了5小时的防护服，他们汗流浃背！抗击新型冠状病毒肺炎，人民英雄一直努力！他们来自武汉大学人民医院他们为生命多开了一扇窗白衣战士意志坚，搏击病魔勇向前！向所有辛苦抗争的医务人员致敬！（图片来源：武汉大学人民医院）#武汉加油##武汉制定诊疗方案#http://t.cn/A6vdz9tD',
 'user': '5238845563',
 'username': '啊清日常',
 'weibo_url': 'https://weibo.com/5238845563/Iqziftitu'}
2020-01-22 16:29:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5>
{'crawled_at': '2020-01-22 16:29:34',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 6,
 'id_str': '3314503443_IqzifarMx',
 'reply_count': 2,
 'retweet_count': 0,
 'source': '微博 weibo.com',
 'text': '淘宝官方已向淘宝天猫平台上所有销售口罩的商家发出通知，绝不允许涨价销售，官方启动专项补贴。从黑龙江省牡丹江市卫生健康委获悉，今天，黑龙江牡丹江市第二医院呼吸科收治一位去武汉探亲返回的69岁男性危重肺炎患者，初步判定新型冠状病毒感染可疑病人，按诊断程序，需进一步确诊。',
 'user': '3314503443',
 'username': '金行长',
 'weibo_url': 'https://weibo.com/3314503443/IqzifarMx'}
2020-01-22 16:29:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1659336417> (referer: https://weibo.cn/1659336417/info)
2020-01-22 16:29:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:35	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1659336417>
{'authentication': '知名书法博主 头条文章作者 微博签约自媒体',
 'birthday': '金牛座',
 'brief_introduction': '禅韵书画是集书画研究、书画作品创作、销售、书画（国画，书法教学）教育为一体的文化研习机构。',
 'crawled_at': '2020-01-22 16:29:35',
 'fans_num': 261883,
 'follows_num': 843,
 'gender': '男',
 'id': '1659336417',
 'labels': '书画,普洱茶人,诗人摄影师',
 'name': '禅韵书画',
 'province': '云南',
 'tweets_num': 2745,
 'vip_level': '6级'}
2020-01-22 16:29:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3041787370> (referer: https://weibo.cn/3041787370/info)
2020-01-22 16:29:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:36	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3041787370>
{'birthday': '1994-02-21',
 'brief_introduction': 'Distant pastures are always greener',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:29:36',
 'fans_num': 231,
 'follows_num': 196,
 'gender': '女',
 'id': '3041787370',
 'labels': '爱笑,吸血鬼,双鱼座',
 'name': '会跑路的小香瓜',
 'province': '湖北',
 'tweets_num': 169,
 'vip_level': '未开通'}
2020-01-22 16:29:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2729433175> (referer: https://weibo.cn/2729433175/info)
2020-01-22 16:29:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2729433175>
{'birthday': '1996-01-21',
 'brief_introduction': '养龟爱好者 欢迎交流🐢',
 'city': '广州',
 'crawled_at': '2020-01-22 16:29:38',
 'fans_num': 332,
 'follows_num': 465,
 'gender': '女',
 'id': '2729433175',
 'labels': '摄影,乐观,时尚',
 'name': 'SUPER可爱超级洋',
 'province': '广东',
 'tweets_num': 525,
 'vip_level': '未开通'}
2020-01-22 16:29:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5819036117> (referer: https://weibo.cn/5819036117/info)
2020-01-22 16:29:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5819036117>
{'birthday': '2000-01-04',
 'brief_introduction': 'sunshine my love',
 'crawled_at': '2020-01-22 16:29:38',
 'fans_num': 237,
 'follows_num': 353,
 'gender': '女',
 'id': '5819036117',
 'name': '牛油果拌饭亚',
 'province': '山西',
 'tweets_num': 540,
 'vip_level': '1级'}
2020-01-22 16:29:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1691032500> (referer: https://weibo.cn/1691032500/info)
2020-01-22 16:29:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1691032500>
{'birthday': '白羊座',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:29:40',
 'fans_num': 307,
 'follows_num': 381,
 'gender': '女',
 'id': '1691032500',
 'labels': '读书,吃,历史',
 'name': 'Yovchiyaya',
 'province': '湖北',
 'tweets_num': 60,
 'vip_level': '未开通'}
2020-01-22 16:29:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/7281473317> (referer: https://weibo.cn/7281473317/info)
2020-01-22 16:29:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/7281473317>
{'birthday': '1989-12-01',
 'crawled_at': '2020-01-22 16:29:41',
 'fans_num': 82559,
 'follows_num': 50,
 'gender': '男',
 'id': '7281473317',
 'name': '编辑下山',
 'province': '上海',
 'tweets_num': 1153,
 'vip_level': '3级'}
2020-01-22 16:29:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1959451603> (referer: https://weibo.cn/1959451603/info)
2020-01-22 16:29:42	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1959451603>
{'authentication': '《成都日报》官方微博',
 'birthday': '01-01',
 'brief_introduction': '《成都日报》是成都市委机关报，也是成都最具影响力的大型综合日报之一。“权威、深度、责任”是我们的办报理念。欢迎拨打本报新闻热线：028-962211。',
 'crawled_at': '2020-01-22 16:29:42',
 'fans_num': 4444051,
 'follows_num': 450,
 'gender': '女',
 'id': '1959451603',
 'name': '成都日报锦观',
 'province': '四川',
 'tweets_num': 63624,
 'vip_level': '未开通'}
2020-01-22 16:29:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1841274207> (referer: https://weibo.cn/1841274207/info)
2020-01-22 16:29:43	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1841274207>
{'birthday': '巨蟹座',
 'crawled_at': '2020-01-22 16:29:43',
 'fans_num': 5,
 'follows_num': 58,
 'gender': '女',
 'id': '1841274207',
 'name': '小花7777777',
 'province': '辽宁',
 'tweets_num': 12585,
 'vip_level': '未开通'}
2020-01-22 16:29:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5580873139> (referer: https://weibo.cn/5580873139/info)
2020-01-22 16:29:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5580873139>
{'birthday': '1996-01-04',
 'brief_introduction': '不要求别的，就是让自己开心，活的没心没肺的。',
 'crawled_at': '2020-01-22 16:29:45',
 'fans_num': 171,
 'follows_num': 830,
 'gender': '女',
 'id': '5580873139',
 'name': 'WR微微一笑很倾城',
 'province': '广西',
 'tweets_num': 3709,
 'vip_level': '5级'}
2020-01-22 16:29:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5329116942> (referer: https://weibo.cn/5329116942/info)
2020-01-22 16:29:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5329116942>
{'authentication': '知名本地博主 本地资讯博主（济南） 城市生活家 微博故事原创作者 资讯视频自媒体',
 'birthday': '1985-04-17',
 'brief_introduction': '@济南生活 关注济南身边事',
 'crawled_at': '2020-01-22 16:29:45',
 'fans_num': 705374,
 'follows_num': 504,
 'gender': '女',
 'id': '5329116942',
 'labels': '济南吃货,吃喝玩乐在济南,济南旅游',
 'name': '济南生活',
 'province': '山东',
 'tweets_num': 17388,
 'vip_level': '6级'}
2020-01-22 16:29:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1249157091/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:47	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3519421583/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1686546714/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3771702070/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:50	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1597301333/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5971931070/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3314503443/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5238845563/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2101415084/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=5)
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '1326403317_Iqzieh3A0',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Android',
 'text': '『正滚动播报“武汉新型肺炎”全国疫情实时动态_新浪直播间』正滚动播报“武汉新型肺炎”全国疫情实时动态',
 'user': '1326403317',
 'username': '千载不相逢_',
 'weibo_url': 'https://weibo.com/1326403317/Iqzieh3A0'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 3,
 'id_str': '5687063107_IqzicvyAk',
 'image_url': 'http://wx1.sinaimg.cn/wap180/006cSkUjly1gb4mk4ad49j30jv0ept9r.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 30',
 'text': '#韩国出现一新型冠状病毒肺炎确诊病例#韩国确诊一例新型冠状病毒肺炎患者，为来自武汉的女性。该名女性19日从武汉出发，搭乘南方航空CZ6079次航班入境韩国。据统计，与之接触者共有44名，其中29名乘客、5名乘务员、10名机场相关人员。29名乘客分别是确诊患者同排和前后各3排，共7排座位上的乘客。接触者中有9人从韩国离境。',
 'user': '5687063107',
 'username': '饭爱豆_日韩娱乐',
 'weibo_url': 'https://weibo.com/5687063107/IqzicvyAk'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 1,
 'id_str': '1959451603_IqzicdKPk',
 'image_url': 'http://wx1.sinaimg.cn/wap180/74cadbd3gy1gb4mk32dttj20m80cqq3k.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '【#山东确诊1例新型肺炎病例#】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。@人民日报',
 'user': '1959451603',
 'username': '成都日报锦观',
 'weibo_url': 'https://weibo.com/1959451603/IqzicdKPk'}
2020-01-22 16:29:57	scrapy.dupefilters	DEBUG	Filtered duplicate request: <GET https://weibo.cn/1959451603/info> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:59',
 'favorite_count': 0,
 'id_str': '5589506717_IqzibDitU',
 'reply_count': 2,
 'retweet_count': 0,
 'source': 'iPhone 8 Plus',
 'text': '刚接到飞猪电话客服飞武汉的机票可选非自愿退票：肺炎我靠白天已经选自愿退了还能改吗？@飞猪@飞猪客服扣了我两百块',
 'user': '5589506717',
 'username': '187CM的黄鲸鱼饼',
 'weibo_url': 'https://weibo.com/5589506717/IqzibDitU'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '1681480141_Iqziar48C',
 'image_url': 'http://wx2.sinaimg.cn/wap180/a716fd45ly1gb4e8rbxb6j20rs11r0wv.jpg',
 'origin_weibo': 'https://weibo.cn/comment/IqxpN8dWx?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '坚果手机 Pro',
 'text': '【今天，转发#武汉新型肺炎防治倡议#！】让我们一起努力，早日打赢这场看不见硝烟的战争！#武汉加油#！',
 'user': '1681480141',
 'username': '布瓜浪漫窝',
 'weibo_url': 'https://weibo.com/1681480141/Iqziar48C'}
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 37,
 'id_str': '2550809142_Iqzi9yUAF',
 'place': True,
 'reply_count': 2,
 'retweet_count': 5,
 'source': 'HUAWEI Mate 9',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！#钟南山肯定新型冠状病毒肺炎人传人#http://t.cn/A6v1G0dH',
 'user': '2550809142',
 'username': '今日潮汕在线',
 'weibo_url': 'https://weibo.com/2550809142/Iqzi9yUAF'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 123,
 'id_str': '2411362032_Iqzi9wyGW',
 'image_url': 'http://wx1.sinaimg.cn/wap180/8fba76f0gy1gb4lxtj8zpj20p00tatct.jpg',
 'place': '信阳',
 'reply_count': 25,
 'retweet_count': 20,
 'text': '及时通报，有效防控，让我们共同努力，早日打赢这场看不见硝烟的战争！#武汉加油#！[加油]#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '2411362032',
 'username': '在信阳',
 'weibo_url': 'https://weibo.com/2411362032/Iqzi9wyGW'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 2,
 'id_str': '5044511176_Iqzi9dpQJ',
 'reply_count': 1,
 'retweet_count': 2,
 'text': '【#山东确诊1例新型肺炎病例#】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。(人民日报)',
 'user': '5044511176',
 'username': '中国搜索',
 'weibo_url': 'https://weibo.com/5044511176/Iqzi9dpQJ'}
2020-01-22 16:29:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6>
{'crawled_at': '2020-01-22 16:29:57',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 2,
 'id_str': '3283037437_Iqzi8lAqt',
 'reply_count': 3,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#北京新增5例新型肺炎病例#出趟差就感染上了，武汉疫情有这么严重吗？这二天没看手机，听他们在说都觉得有点可怕。到底是怎样传播的？什么地方才是最严重的地方呢？',
 'user': '3283037437',
 'username': 'o花开有声o',
 'weibo_url': 'https://weibo.com/3283037437/Iqzi8lAqt'}
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1249157091> (referer: https://weibo.cn/1249157091/info)
2020-01-22 16:29:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:29:59	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1249157091>
{'birthday': '1967-10-07',
 'brief_introduction': '吃货，爱玩。不会笑别跟我对骂，我能文明的把你骂怀孕，无论男女',
 'city': '西安',
 'crawled_at': '2020-01-22 16:29:59',
 'fans_num': 4236,
 'follows_num': 160,
 'gender': '男',
 'id': '1249157091',
 'labels': '文艺,美景美元美死我,美食美酒美女',
 'name': '咸淡猪手',
 'province': '陕西',
 'tweets_num': 34153,
 'vip_level': '6级'}
2020-01-22 16:30:00	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3519421583> (referer: https://weibo.cn/3519421583/info)
2020-01-22 16:30:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:00	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3519421583>
{'authentication': '芸汐传超话小主持人',
 'birthday': '射手座',
 'brief_introduction': '谦虚对事 礼貌待人',
 'city': '广州',
 'crawled_at': '2020-01-22 16:30:00',
 'fans_num': 1839,
 'follows_num': 296,
 'gender': '女',
 'id': '3519421583',
 'name': '再见萤火虫-FZ',
 'province': '广东',
 'tweets_num': 945,
 'vip_level': '4级'}
2020-01-22 16:30:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1686546714> (referer: https://weibo.cn/1686546714/info)
2020-01-22 16:30:01	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1686546714>
{'authentication': '环球网微博',
 'birthday': '0001-00-00',
 'brief_introduction': '环球网【http://www.huanqiu.com】是由《环球时报》社主办的中英文双语网站，每日滚动发送热门国际台海新闻。环球网，世界很精彩！',
 'city': '朝阳区',
 'crawled_at': '2020-01-22 16:30:01',
 'fans_num': 17667921,
 'follows_num': 1363,
 'gender': '女',
 'id': '1686546714',
 'labels': '世界,英国,美国',
 'name': '环球网',
 'province': '北京',
 'tweets_num': 79572,
 'vip_level': '6级'}
2020-01-22 16:30:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3771702070> (referer: https://weibo.cn/3771702070/info)
2020-01-22 16:30:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3771702070>
{'birthday': '1935-08-05',
 'brief_introduction': '祝福你真的可以睡得好',
 'crawled_at': '2020-01-22 16:30:03',
 'fans_num': 176,
 'follows_num': 189,
 'gender': '女',
 'id': '3771702070',
 'name': '小戴小戴时亨运泰',
 'province': '其他',
 'tweets_num': 349,
 'vip_level': '6级'}
2020-01-22 16:30:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1597301333> (referer: https://weibo.cn/1597301333/info)
2020-01-22 16:30:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1597301333>
{'brief_introduction': '枯叶作樱飞入梦 浮云沧海病郎中 每逢执起歌敦盛 劣酒歪诗放月翁',
 'city': '珠海',
 'crawled_at': '2020-01-22 16:30:03',
 'fans_num': 403,
 'follows_num': 296,
 'gender': '男',
 'id': '1597301333',
 'labels': 'stage1st,EXPer',
 'name': 'MadaoIkari',
 'province': '广东',
 'tweets_num': 4290,
 'vip_level': '6级'}
2020-01-22 16:30:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5971931070> (referer: https://weibo.cn/5971931070/info)
2020-01-22 16:30:05	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5971931070>
{'birthday': '1997-06-27',
 'brief_introduction': '如果不喜欢，也请不要伤害！',
 'crawled_at': '2020-01-22 16:30:05',
 'fans_num': 91,
 'follows_num': 218,
 'gender': '女',
 'id': '5971931070',
 'name': '山栀子0923',
 'province': '其他',
 'tweets_num': 337,
 'vip_level': '1级'}
2020-01-22 16:30:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3314503443> (referer: https://weibo.cn/3314503443/info)
2020-01-22 16:30:06	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3314503443>
{'authentication': '知名财经博主 头条文章作者',
 'brief_introduction': '检验理论的唯一标准，在于持续稳定获利！',
 'crawled_at': '2020-01-22 16:30:06',
 'fans_num': 120098,
 'follows_num': 1610,
 'gender': '男',
 'id': '3314503443',
 'labels': '能源投资,股指期货,外汇投资',
 'name': '金行长',
 'province': '北京',
 'tweets_num': 2746,
 'vip_level': '6级'}
2020-01-22 16:30:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5238845563> (referer: https://weibo.cn/5238845563/info)
2020-01-22 16:30:07	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5238845563>
{'birthday': '2002-07-07',
 'brief_introduction': '对今天的自己满意！！！',
 'city': '百色',
 'crawled_at': '2020-01-22 16:30:07',
 'fans_num': 181,
 'follows_num': 706,
 'gender': '女',
 'id': '5238845563',
 'labels': '动漫',
 'name': '啊清日常',
 'province': '广西',
 'tweets_num': 4958,
 'vip_level': '1级'}
2020-01-22 16:30:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2101415084> (referer: https://weibo.cn/2101415084/info)
2020-01-22 16:30:08	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2101415084>
{'birthday': '0001-00-00',
 'brief_introduction': '鸟王争霸：哦，哦，红鸟，哦，哦！',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:30:08',
 'fans_num': 1776,
 'follows_num': 1093,
 'gender': '男',
 'id': '2101415084',
 'labels': '娱乐',
 'name': '靠谱不得',
 'province': '广东',
 'tweets_num': 117479,
 'vip_level': '未开通'}
2020-01-22 16:30:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2550809142/Iqzi9yUAF> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:42	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/2550809142/Iqzi9yUAF>
{'crawled_at': '2020-01-22 16:30:42',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 37,
 'id_str': '2550809142_Iqzi9yUAF',
 'place': '汕头·汕头老城',
 'reply_count': 2,
 'retweet_count': 5,
 'source': 'HUAWEI Mate 9',
 'text': '【面对疫情，#84岁钟南山挂帅出征#！他是谁，三分钟了解一下】2003年，一场突如其来的“非典”疫情令世人闻之色变，“把重病人都送到我这里来”的豪言，让国人记住了一个名字——钟南山，现在2020年，钟南山84岁了，他再次挂帅出征去了武汉。为他点赞！#钟南山肯定新型冠状病毒肺炎人传人#小央视频的秒拍视频',
 'user': '2550809142',
 'username': '今日潮汕在线',
 'weibo_url': 'https://weibo.com/2550809142/Iqzi9yUAF'}
2020-01-22 16:30:42	scrapy.extensions.logstats	INFO	Crawled 102 pages (at 37 pages/min), scraped 105 items (at 38 items/min)
2020-01-22 16:30:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1681480141/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5589506717/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:44	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5687063107/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1326403317/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:47	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3283037437/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2411362032/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2550809142/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=6)
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 10,
 'id_str': '6372764285_Iqzi7rNL6',
 'image_url': 'http://wx4.sinaimg.cn/wap180/006Xht6Jly1gb4mi4pfwej31t00u0tmy.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P30',
 'text': '#国内确诊291例新型冠状病毒肺炎病例##良医#武汉疫情和这个剧情有点巧合了吧',
 'user': '6372764285',
 'username': '蕊哩个蕊蕊蕊',
 'weibo_url': 'https://weibo.com/6372764285/Iqzi7rNL6'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '5856217159_Iqzi7rNCd',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 10',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '5856217159',
 'username': '小小陈童鞋119',
 'weibo_url': 'https://weibo.com/5856217159/Iqzi7rNCd'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 3,
 'id_str': '5539315908_Iqzi7ayyn',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '非典的时候我才3岁，现在肺炎我20岁了。三岁都挺过来了20岁也能挺过来。武汉加油',
 'user': '5539315908',
 'username': '奋斗的小刘同学ing',
 'weibo_url': 'https://weibo.com/5539315908/Iqzi7ayyn'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 5,
 'id_str': '2306520925_Iqzi6haeE',
 'image_url': 'http://wx2.sinaimg.cn/wap180/897ab75dgy1gb4mihdupoj20v91vo7wj.jpg',
 'reply_count': 3,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#黄冈新增12例新型肺炎#武汉人不担心武汉，倒是担心其他地方',
 'user': '2306520925',
 'username': '冰岛的一杯温水',
 'weibo_url': 'https://weibo.com/2306520925/Iqzi6haeE'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 2,
 'id_str': '5258700147_Iqzi61RSg',
 'image_url': 'http://wx2.sinaimg.cn/wap180/005JSY8jly1gb4mjusk4uj30u01nbq8d.jpg',
 'reply_count': 3,
 'retweet_count': 0,
 'source': 'Share微博客户端',
 'text': '1、一个舆情评论，底下的追评，追评的追评，可以构成一个较为完整的态势发展链，或者态势发展树。是不是可以做东西？2、GIS的空间分析最早就是做伦敦瘟疫致灾原因分析的，现在很多外地旅客到了武汉得了肺炎，怎么能拿到旅客经停数据，来进行重要致灾地点锁定与危险性评估分析？3、肺炎舆情这么凶猛，要不要抓点评论做点东西？',
 'user': '5258700147',
 'username': '作小寒喵喵张',
 'weibo_url': 'https://weibo.com/5258700147/Iqzi61RSg'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 151,
 'id_str': '5601972391_Iqzi60Eai',
 'reply_count': 42,
 'retweet_count': 13,
 'source': '360安全浏览器',
 'text': '【青岛市疑似新型冠状病毒感染的肺炎病例被国家卫生健康委确认为确诊病例】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。经省、市疾控部门检测，并经中国疾控中心复核，新型冠状病毒核酸检测结果为阳性。1月21日，经国家卫生健康委疫情防控领导小组下设的诊断组专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。下一步，省、市将指导定点医院加强对患者救治，加强密切接触者医学观察。http://t.cn/A6vdQFx9',
 'user': '5601972391',
 'username': '健康山东',
 'weibo_url': 'https://weibo.com/5601972391/Iqzi60Eai'}
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '3665794267_Iqzi5nRfF',
 'origin_weibo': 'https://weibo.cn/comment/Iqpx4qqDU?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '【中国人，别再乱吃野生动物了！！！】钟南山院士：我们到武汉去看，那个所谓海鲜市场，相当多的并不是海鲜，而是野味，也就是野生动物，病毒有很大可能是从野生动物传染到人。——当年非典的源头，同样疑为野生动物，呼吁国人，管住嘴，别特么再乱吃了！！！#新型冠状病毒肺炎很可能来自野味##钟南山肯定新型冠状病毒肺炎人传人##境内确诊217例新型冠状病毒肺炎病例#http://t.cn/A6vmqD04',
 'user': '3665794267',
 'username': 'heumyun-',
 'weibo_url': 'https://weibo.com/3665794267/Iqzi5nRfF'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 7,
 'id_str': '2781665401_Iqzi3kzh1',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#武汉卫健委发布病毒性肺炎高发注意事项#武汉加油[淚][淚][淚][淚][淚]中国加油[淚]医护人员加油！！！！！！！！！！！！！！！！！大家都可以度过这个难关的！',
 'user': '2781665401',
 'username': '心比猪野',
 'weibo_url': 'https://weibo.com/2781665401/Iqzi3kzh1'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '6291378416_Iqzi1gcv5',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#小陈在说废话#最近几天在微博上看的都是武汉肺炎的最新动态对那些什么娱乐新闻已经完全没有兴趣了隔几个小时刷新一次发现某个地方又多了几例是真的很害怕很恐慌希望能早点有特效药控制疫情希望医生记者执勤警察都能好好的希望中国能挺过去',
 'user': '6291378416',
 'username': '小陈个子不高',
 'weibo_url': 'https://weibo.com/6291378416/Iqzi1gcv5'}
2020-01-22 16:30:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7>
{'crawled_at': '2020-01-22 16:30:51',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 95,
 'id_str': '6143036868_Iqzi1eHJp',
 'reply_count': 3,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#黄冈新增12例新型肺炎#今天上午得知在武汉医院工作的姐姐们都不能回来了，刚刚得知老妈年假也没了，大家都在努力对付疫情啊，一切尽快好起来吧，湖北加油！',
 'user': '6143036868',
 'username': '叫我大萌子就好',
 'weibo_url': 'https://weibo.com/6143036868/Iqzi1eHJp'}
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:51	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1681480141> (referer: https://weibo.cn/1681480141/info)
2020-01-22 16:30:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:52	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1681480141>
{'brief_introduction': '幸福瓜窝窝',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:30:52',
 'fans_num': 226,
 'follows_num': 525,
 'gender': '女',
 'id': '1681480141',
 'name': '布瓜浪漫窝',
 'province': '广东',
 'tweets_num': 1386,
 'vip_level': '未开通'}
2020-01-22 16:30:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5589506717> (referer: https://weibo.cn/5589506717/info)
2020-01-22 16:30:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:30:54	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5589506717>
{'authentication': '黄景瑜超话粉丝大咖',
 'birthday': '0001-00-00',
 'brief_introduction': '黄景瑜忠实迷妹~♥鱼饼这么阔爱！怎么可以次鱼饼！♥~',
 'crawled_at': '2020-01-22 16:30:54',
 'fans_num': 1505,
 'follows_num': 442,
 'gender': '女',
 'id': '5589506717',
 'name': '187CM的黄鲸鱼饼',
 'province': '其他',
 'tweets_num': 21194,
 'vip_level': '6级'}
2020-01-22 16:30:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5687063107> (referer: https://weibo.cn/5687063107/info)
2020-01-22 16:30:55	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5687063107>
{'authentication': '娱乐综艺视频博主',
 'brief_introduction': '正能量追星，陪你饭爱豆！粉丝福利抢先享，爱豆资讯一手抓！粉丝投稿QQ：2435125235  '
                       '宣传合作微信：FanidolBiz饭爱豆合作手机号：17717046223',
 'crawled_at': '2020-01-22 16:30:55',
 'fans_num': 426281,
 'follows_num': 721,
 'gender': '女',
 'id': '5687063107',
 'labels': '名人明星',
 'name': '饭爱豆_日韩娱乐',
 'province': '上海',
 'tweets_num': 7993,
 'vip_level': '6级'}
2020-01-22 16:30:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1326403317> (referer: https://weibo.cn/1326403317/info)
2020-01-22 16:30:55	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1326403317>
{'birthday': '天蝎座',
 'brief_introduction': '世事纷扰，安得静好。',
 'crawled_at': '2020-01-22 16:30:55',
 'fans_num': 83,
 'follows_num': 560,
 'gender': '女',
 'id': '1326403317',
 'labels': '情感生活,读书分享,职场招聘',
 'name': '千载不相逢_',
 'province': '其他',
 'tweets_num': 2059,
 'vip_level': '1级'}
2020-01-22 16:30:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3283037437> (referer: https://weibo.cn/3283037437/info)
2020-01-22 16:30:56	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3283037437>
{'birthday': '0001-00-00',
 'brief_introduction': '笑口常开，好彩自然来！',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:30:56',
 'fans_num': 468,
 'follows_num': 30,
 'gender': '女',
 'id': '3283037437',
 'labels': '宅女,80后,微笑',
 'name': 'o花开有声o',
 'province': '湖北',
 'tweets_num': 6408,
 'vip_level': '3级'}
2020-01-22 16:30:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2411362032> (referer: https://weibo.cn/2411362032/info)
2020-01-22 16:30:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2411362032>
{'authentication': '微博信阳同城大使 城市生活家 美食视频自媒体',
 'birthday': '0000-01-10',
 'brief_introduction': '微博信阳同城大使，欢迎关注。我在信阳，我爱信阳；不在信阳，我念信阳。',
 'city': '信阳',
 'crawled_at': '2020-01-22 16:30:57',
 'fans_num': 642517,
 'follows_num': 1492,
 'gender': '男',
 'id': '2411362032',
 'labels': '新县,信阳师范学院,信阳毛尖',
 'name': '在信阳',
 'province': '河南',
 'tweets_num': 32052,
 'vip_level': '7级'}
2020-01-22 16:30:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2550809142> (referer: https://weibo.cn/2550809142/info)
2020-01-22 16:30:59	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2550809142>
{'authentication': '本地资讯博主（汕头）',
 'birthday': '1982-05-02',
 'brief_introduction': '我是潮汕情报圈中人，我是知情者，只要你关注我，我愿意告诉你事实的真相。',
 'crawled_at': '2020-01-22 16:30:59',
 'fans_num': 138823,
 'follows_num': 1993,
 'gender': '男',
 'id': '2550809142',
 'name': '今日潮汕在线',
 'province': '广东',
 'tweets_num': 31674,
 'vip_level': '2级'}
2020-01-22 16:31:00	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5258700147/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2306520925/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5539315908/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5856217159/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6372764285/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2781665401/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6291378416/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3665794267/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5601972391/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:11	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6143036868/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:12	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=7)
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '3738758345_Iqzi03Hpt',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '3738758345',
 'username': 'ZK丶Lee',
 'weibo_url': 'https://weibo.com/3738758345/Iqzi03Hpt'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 4,
 'id_str': '6033660687_IqzhY0MsS',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '小米8周年旗舰手机',
 'text': '#北京新增5例新型肺炎病例#在武汉呆一天就患上，感觉武汉本地潜在患者可能会有很多啊！',
 'user': '6033660687',
 'username': '无执念_',
 'weibo_url': 'https://weibo.com/6033660687/IqzhY0MsS'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 5,
 'id_str': '2644733664_IqzhUqY6n',
 'image_url': 'http://wx1.sinaimg.cn/wap180/9da36ee0gy1gb4mir8mwrj20yi10y78o.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '2003年我在华师附小抗击非典，2020年我在汤逊湖防控肺炎，一起加油，跟我大武汉同进退',
 'user': '2644733664',
 'username': '爱吃白萝卜的大白兔',
 'weibo_url': 'https://weibo.com/2644733664/IqzhUqY6n'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 87528,
 'id_str': '2803301701_IqzhUd9xt',
 'image_url': 'http://wx3.sinaimg.cn/wap180/a716fd45ly1gb4mjcgjprj20ob0obk0y.jpg',
 'reply_count': 4845,
 'retweet_count': 1983,
 'source': '微博 weibo.com',
 'text': '【#昆明确诊首例新型肺炎病例#】患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。',
 'user': '2803301701',
 'username': '人民日报',
 'weibo_url': 'https://weibo.com/2803301701/IqzhUd9xt'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 2,
 'id_str': '7075452025_IqzhSFF4v',
 'origin_weibo': 'https://weibo.cn/comment/Iqyfwl5qK?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'OPPO智能手机',
 'text': '脱下穿了5小时的防护服，他们汗流浃背！抗击新型冠状病毒肺炎，人民英雄一直努力！他们来自武汉大学人民医院他们为生命多开了一扇窗白衣战士意志坚，搏击病魔勇向前！向所有辛苦抗争的医务人员致敬！（图片来源：武汉大学人民医院）#武汉加油##武汉制定诊疗方案#http://t.cn/A6vdz9tD',
 'user': '7075452025',
 'username': '迟兮87683',
 'weibo_url': 'https://weibo.com/7075452025/IqzhSFF4v'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 52,
 'id_str': '1699540307_IqzhRd0GQ',
 'image_url': 'http://wx1.sinaimg.cn/wap180/654ced53gy1gb4miwut3vj20kr0jadn7.jpg',
 'reply_count': 10,
 'retweet_count': 14,
 'source': '微博 weibo.com',
 'text': '【#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。',
 'user': '1699540307',
 'username': '中国之声',
 'weibo_url': 'https://weibo.com/1699540307/IqzhRd0GQ'}
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 5,
 'id_str': '2201378802_IqzhRcYv9',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'Android',
 'text': '武汉这个疫情，政府一定有责任的，因为很多省份的外来病例都有一个共性，在当地已经明显出现肺炎症状，但是最终还是回到了本地看病。这就表明，第一武汉医院并没有进行有效隔离，其次武汉政府当时根本没有为这些病人准备治疗手段，否则，有了病，谁愿意跑那么远回家看病呢？',
 'user': '2201378802',
 'username': '风儿好喧嚣啊丶',
 'weibo_url': 'https://weibo.com/2201378802/IqzhRcYv9'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '2097034067_IqzhQ1Flq',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀 9X',
 'text': '这位就是最年轻的那位患者了～『一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话』一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话',
 'user': '2097034067',
 'username': '杨柳飘飘58',
 'weibo_url': 'https://weibo.com/2097034067/IqzhQ1Flq'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 6,
 'id_str': '7076905585_IqzhPssDE',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '🍪 Android',
 'text': '#武汉新型肺炎患者救治由政府买单#做得挺好的，政府也在不断进步，全民众志成城，抵抗流感病毒',
 'user': '7076905585',
 'username': 'Citrusgrove',
 'weibo_url': 'https://weibo.com/7076905585/IqzhPssDE'}
2020-01-22 16:31:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8>
{'crawled_at': '2020-01-22 16:31:13',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '2867968760_IqzhPb0cz',
 'origin_weibo': 'https://weibo.cn/comment/IqyD9rCVV?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '阿寄の🍬Android',
 'text': '#武汉疫情防控全面升级#【转发了解！#武汉新型肺炎的潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！央视新闻的微博视频',
 'user': '2867968760',
 'username': '片寄凉太的太妃糖',
 'weibo_url': 'https://weibo.com/2867968760/IqzhPb0cz'}
2020-01-22 16:31:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:14	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5258700147> (referer: https://weibo.cn/5258700147/info)
2020-01-22 16:31:14	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:14	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5258700147>
{'crawled_at': '2020-01-22 16:31:14',
 'fans_num': 238,
 'follows_num': 214,
 'id': '5258700147',
 'tweets_num': 697}
2020-01-22 16:31:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2306520925> (referer: https://weibo.cn/2306520925/info)
2020-01-22 16:31:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:15	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2306520925>
{'birthday': '处女座',
 'brief_introduction': '保持微笑，珍惜身边的人，然后自己幸福活着。',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:31:15',
 'fans_num': 454,
 'follows_num': 358,
 'gender': '女',
 'id': '2306520925',
 'labels': '善良,热爱生活,感性',
 'name': '冰岛的一杯温水',
 'province': '广东',
 'tweets_num': 973,
 'vip_level': '未开通'}
2020-01-22 16:31:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5539315908> (referer: https://weibo.cn/5539315908/info)
2020-01-22 16:31:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:17	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5539315908>
{'birthday': '2000-04-24',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:31:17',
 'fans_num': 45,
 'follows_num': 16,
 'gender': '男',
 'id': '5539315908',
 'name': '奋斗的小刘同学ing',
 'province': '湖北',
 'tweets_num': 3,
 'vip_level': '未开通'}
2020-01-22 16:31:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5856217159> (referer: https://weibo.cn/5856217159/info)
2020-01-22 16:31:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5856217159>
{'birthday': '天蝎座',
 'brief_introduction': '日常吸蛋总😍 阿胖😍 车车😍',
 'city': '广州',
 'crawled_at': '2020-01-22 16:31:18',
 'fans_num': 161,
 'follows_num': 391,
 'gender': '女',
 'id': '5856217159',
 'name': '小小陈童鞋119',
 'province': '广东',
 'tweets_num': 1142,
 'vip_level': '未开通'}
2020-01-22 16:31:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6372764285> (referer: https://weibo.cn/6372764285/info)
2020-01-22 16:31:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:19	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6372764285>
{'crawled_at': '2020-01-22 16:31:19',
 'fans_num': 395,
 'follows_num': 208,
 'id': '6372764285',
 'tweets_num': 11}
2020-01-22 16:31:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2781665401> (referer: https://weibo.cn/2781665401/info)
2020-01-22 16:31:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2781665401>
{'birthday': '天秤座',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:31:20',
 'fans_num': 338,
 'follows_num': 687,
 'gender': '女',
 'id': '2781665401',
 'labels': '名人明星,星座命理,微博奇葩',
 'name': '心比猪野',
 'province': '湖北',
 'tweets_num': 87,
 'vip_level': '未开通'}
2020-01-22 16:31:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6291378416> (referer: https://weibo.cn/6291378416/info)
2020-01-22 16:31:21	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6291378416>
{'brief_introduction': '偶尔话唠 偶尔自闭',
 'crawled_at': '2020-01-22 16:31:21',
 'fans_num': 10,
 'follows_num': 1,
 'gender': '女',
 'id': '6291378416',
 'name': '小陈个子不高',
 'province': '其他',
 'tweets_num': 91,
 'vip_level': '未开通'}
2020-01-22 16:31:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3665794267> (referer: https://weibo.cn/3665794267/info)
2020-01-22 16:31:23	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3665794267>
{'birthday': '2001-04-12',
 'brief_introduction': '一期一会',
 'city': '吉安',
 'crawled_at': '2020-01-22 16:31:23',
 'fans_num': 116,
 'follows_num': 90,
 'gender': '女',
 'id': '3665794267',
 'labels': '白羊座,阳光',
 'name': 'heumyun-',
 'province': '江西',
 'tweets_num': 66,
 'vip_level': '2级'}
2020-01-22 16:31:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5601972391> (referer: https://weibo.cn/5601972391/info)
2020-01-22 16:31:24	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5601972391>
{'authentication': '山东省卫生健康委员会（山东省中医药管理局）官方微博',
 'crawled_at': '2020-01-22 16:31:24',
 'fans_num': 4902,
 'follows_num': 180,
 'gender': '男',
 'id': '5601972391',
 'name': '健康山东',
 'province': '山东',
 'tweets_num': 8923,
 'vip_level': '未开通'}
2020-01-22 16:31:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6143036868> (referer: https://weibo.cn/6143036868/info)
2020-01-22 16:31:24	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6143036868>
{'birthday': '1999-08-17',
 'brief_introduction': '面包片狂热爱好者🍞',
 'crawled_at': '2020-01-22 16:31:24',
 'fans_num': 77,
 'follows_num': 206,
 'gender': '女',
 'id': '6143036868',
 'name': '叫我大萌子就好',
 'province': '北京',
 'tweets_num': 249,
 'vip_level': '2级'}
2020-01-22 16:31:24	scrapy.extensions.logstats	INFO	Crawled 138 pages (at 36 pages/min), scraped 142 items (at 37 items/min)
2020-01-22 16:31:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/7075452025/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2803301701/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2644733664/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6033660687/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3738758345/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/7076905585/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2867968760/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2097034067/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2201378802/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1699540307/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=8)
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 4,
 'id_str': '6279622426_IqzhP9Ie2',
 'reply_count': 9,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '我们被确诊的同事已经有一名出院了虽然专家说尽量不要去人员密集场所，但是过年还是有很多人来银行，我们不能休息，单位又给我们发了一批口罩（这次是医用外科口罩）保洁阿姨每天不停的消毒桌子和地面，发放了体温计，进来的每个人都量体温，每天所有的工作人员也都要量体温上报，再坚持最后2天，我们也要关门回家过年了。今年过年就哪里都不去了，去超市买了很多菜，老老实实待在家里，回老家怕别人嫌弃我们是武汉来的#专家称武汉冠状病毒肺炎总体可治#',
 'user': '6279622426',
 'username': '0臭臭真臭0',
 'weibo_url': 'https://weibo.com/6279622426/IqzhP9Ie2'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 2,
 'id_str': '1848028791_IqzhP9Ham',
 'image_url': 'http://wx2.sinaimg.cn/wap180/6e26ae77ly1gb4mhdaoqyj20zk1bfnbi.jpg',
 'reply_count': 2,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '春节不能回湖北老家过年，只能在北京自拍欢度新春，祝大家新春快乐，武汉肺炎快快散去！',
 'user': '1848028791',
 'username': 'Cathy_A',
 'weibo_url': 'https://weibo.com/1848028791/IqzhP9Ham'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 51,
 'id_str': '2728780847_IqzhO178k',
 'image_url': 'http://wx2.sinaimg.cn/wap180/a2a5e42fly1gb4mikagefj20c40js3zr.jpg',
 'reply_count': 28,
 'retweet_count': 2,
 'source': 'iPhone 11 Pro Max',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#武汉是一座勇于面对困难，不断战胜困难的城市！武汉加油！',
 'user': '2728780847',
 'username': '福州城市建设',
 'weibo_url': 'https://weibo.com/2728780847/IqzhO178k'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 0,
 'id_str': '2948949893_IqzhNEFqT',
 'image_url': 'http://wx2.sinaimg.cn/wap180/afc56785gy3gb4mj2wa64j20qo0zk1ig.jpg',
 'reply_count': 0,
 'retweet_count': 1,
 'source': '绿洲APP',
 'text': '#武汉新型冠状病毒肺炎#冠心病毒肺炎的发生！我们可以建议！加强提高免疫力！注重健康！但很多人事情没发生在你的身上！不断的增加娱乐！这是对生命的不尊重！很无知绿洲',
 'user': '2948949893',
 'username': '谁也不懂得谁',
 'weibo_url': 'https://weibo.com/2948949893/IqzhNEFqT'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:58',
 'favorite_count': 121,
 'id_str': '2703419987_IqzhMeoxM',
 'image_url': 'http://wx4.sinaimg.cn/wap180/a122ea53gy1gb4miy6euwj21900u0q51.jpg',
 'reply_count': 3,
 'retweet_count': 14,
 'source': '团团的华为Android',
 'text': '【感谢守候！】向所有前线医务人员致敬！请你们千万也要为自己做好防护！万众一心、众志成城，一定能够打赢这场疫情防控战！武汉加油！#国内确诊291例新型冠状病毒肺炎病例##武汉新型肺炎患者救治由政府买单#',
 'user': '2703419987',
 'username': '共青团广安市委',
 'weibo_url': 'https://weibo.com/2703419987/IqzhMeoxM'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '2696979161_IqzhJvSwI',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 16,
 'source': '微博 weibo.com',
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '2696979161',
 'username': '蛞蝓搓揉着触角说',
 'weibo_url': 'https://weibo.com/2696979161/IqzhJvSwI'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 30,
 'id_str': '2168732153_IqzhIEGFL',
 'image_url': 'http://wx3.sinaimg.cn/wap180/814439f9gy1gb4mirn9prj22c0340u0x.jpg',
 'reply_count': 26,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '刚刚在酒店办理入住前台看我是武汉的恨不得跟我有多远隔多远#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '2168732153',
 'username': '大菲姐-',
 'weibo_url': 'https://weibo.com/2168732153/IqzhIEGFL'}
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1713465100_IqzhIDDcg',
 'place': '香港',
 'reply_count': 6,
 'retweet_count': 0,
 'source': 'iPad Pro',
 'text': '虽然买好了23号的票回武汉，但其实还是有点犹豫。家里有病危的奶奶，还有肆虐的肺炎。一种中年危机感，提前萦绕心头。',
 'user': '1713465100',
 'username': '范如也',
 'weibo_url': 'https://weibo.com/1713465100/IqzhIDDcg'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '6878548032_IqzhIkUAZ',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iQOO Neo',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#希望还在武汉的同学都能平安🙏',
 'user': '6878548032',
 'username': '乱拳打死小青蛙',
 'weibo_url': 'https://weibo.com/6878548032/IqzhIkUAZ'}
2020-01-22 16:31:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9>
{'crawled_at': '2020-01-22 16:31:37',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 6,
 'id_str': '5228035069_IqzhHtHHU',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#黄冈新增12例新型肺炎##国内确诊291例新型冠状病毒肺炎病例#没事不要去武汉，有急事自己也掂量掂量清楚。同时也希望在武汉的无论是本地人还是外地人还是旅游准备回家的也不要出来。。你自己也不知道有没有感染到病毒。。免得传染给别人。。',
 'user': '5228035069',
 'username': 'M安夏如沫',
 'weibo_url': 'https://weibo.com/5228035069/IqzhHtHHU'}
2020-01-22 16:31:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/7075452025> (referer: https://weibo.cn/7075452025/info)
2020-01-22 16:31:39	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:39	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/7075452025>
{'brief_introduction': '不努力去追寻的事物，全世界都会让你远离；想要却无法鼓足勇气去完成的诗篇，只能在梦里破碎相见.',
 'crawled_at': '2020-01-22 16:31:39',
 'fans_num': 72,
 'follows_num': 336,
 'gender': '女',
 'id': '7075452025',
 'name': '迟兮87683',
 'province': '其他',
 'tweets_num': 754,
 'vip_level': '未开通'}
2020-01-22 16:31:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2803301701> (referer: https://weibo.cn/2803301701/info)
2020-01-22 16:31:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2803301701>
{'authentication': '《人民日报》法人微博',
 'birthday': '1948-06-15',
 'brief_introduction': '人民日报法人微博。参与、沟通、记录时代。',
 'crawled_at': '2020-01-22 16:31:40',
 'fans_num': 103938480,
 'follows_num': 3037,
 'gender': '男',
 'id': '2803301701',
 'labels': '人民日报',
 'name': '人民日报',
 'province': '北京',
 'tweets_num': 109192,
 'vip_level': '6级'}
2020-01-22 16:31:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2644733664> (referer: https://weibo.cn/2644733664/info)
2020-01-22 16:31:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2644733664>
{'birthday': '白羊座',
 'brief_introduction': 'sweet love😊',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:31:41',
 'fans_num': 391,
 'follows_num': 152,
 'gender': '女',
 'id': '2644733664',
 'name': '爱吃白萝卜的大白兔',
 'province': '湖北',
 'tweets_num': 546,
 'vip_level': '未开通'}
2020-01-22 16:31:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6033660687> (referer: https://weibo.cn/6033660687/info)
2020-01-22 16:31:42	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:42	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6033660687>
{'birthday': '1996-10-26',
 'brief_introduction': '江湖且纵马，逐影照寒秋！',
 'crawled_at': '2020-01-22 16:31:42',
 'fans_num': 116,
 'follows_num': 456,
 'gender': '男',
 'id': '6033660687',
 'name': '无执念_',
 'province': '广东',
 'tweets_num': 343,
 'vip_level': '3级'}
2020-01-22 16:31:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3738758345> (referer: https://weibo.cn/3738758345/info)
2020-01-22 16:31:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:44	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3738758345>
{'birthday': '水瓶座',
 'brief_introduction': '越长大，越孤单。',
 'city': '苏州',
 'crawled_at': '2020-01-22 16:31:44',
 'fans_num': 253,
 'follows_num': 178,
 'gender': '男',
 'id': '3738758345',
 'labels': '腹黑,搞笑幽默',
 'name': 'ZK丶Lee',
 'province': '江苏',
 'tweets_num': 9098,
 'vip_level': '3级'}
2020-01-22 16:31:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/7076905585> (referer: https://weibo.cn/7076905585/info)
2020-01-22 16:31:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/7076905585>
{'birthday': '1994-02-18',
 'brief_introduction': 'Letting the universe know what you want / 生活博主',
 'crawled_at': '2020-01-22 16:31:45',
 'fans_num': 157,
 'follows_num': 207,
 'gender': '女',
 'id': '7076905585',
 'name': 'Citrusgrove',
 'province': '海外',
 'tweets_num': 2249,
 'vip_level': '3级'}
2020-01-22 16:31:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2867968760> (referer: https://weibo.cn/2867968760/info)
2020-01-22 16:31:46	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2867968760>
{'birthday': '水瓶座',
 'brief_introduction': '片寄凉太🍬️💛️GD❤️generations💙️',
 'city': '日本',
 'crawled_at': '2020-01-22 16:31:46',
 'fans_num': 202,
 'follows_num': 302,
 'gender': '女',
 'id': '2867968760',
 'labels': '旅游,星座命理,时尚',
 'name': '片寄凉太的太妃糖',
 'province': '海外',
 'tweets_num': 11440,
 'vip_level': '6级'}
2020-01-22 16:31:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2097034067> (referer: https://weibo.cn/2097034067/info)
2020-01-22 16:31:48	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2097034067>
{'birthday': '01-01',
 'brief_introduction': 'Smart people have their mouths in their hearts',
 'city': '昆明',
 'crawled_at': '2020-01-22 16:31:48',
 'fans_num': 403,
 'follows_num': 585,
 'gender': '女',
 'id': '2097034067',
 'labels': '美食、看书、贫嘴',
 'name': '杨柳飘飘58',
 'province': '云南',
 'tweets_num': 5822,
 'vip_level': '1级'}
2020-01-22 16:31:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2201378802> (referer: https://weibo.cn/2201378802/info)
2020-01-22 16:31:49	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2201378802>
{'birthday': '01-01',
 'brief_introduction': '隔壁的薯片半价啦',
 'crawled_at': '2020-01-22 16:31:49',
 'fans_num': 69,
 'follows_num': 90,
 'gender': '女',
 'id': '2201378802',
 'labels': '新闻资讯',
 'name': '风儿好喧嚣啊丶',
 'province': '其他',
 'tweets_num': 121,
 'vip_level': '未开通'}
2020-01-22 16:31:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1699540307> (referer: https://weibo.cn/1699540307/info)
2020-01-22 16:31:50	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1699540307>
{'authentication': '中央广播电视总台广播新闻综合频率',
 'brief_introduction': '网络直播在线收听： china.cnr.cn。中国唯一覆盖全国的24小时新闻直播频率。',
 'crawled_at': '2020-01-22 16:31:50',
 'fans_num': 26124802,
 'follows_num': 1309,
 'gender': '男',
 'id': '1699540307',
 'labels': '做客中央台,直播,最快',
 'name': '中国之声',
 'province': '北京',
 'tweets_num': 116645,
 'vip_level': '6级'}
2020-01-22 16:31:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2696979161/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2703419987/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2728780847/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2948949893/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1848028791/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6279622426/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5228035069/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:31:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6878548032/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:31:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1713465100/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:32:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2168732153/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:32:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=9)
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '5783199737_IqzhHriqD',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'nova4e 3200W立体美颜',
 'text': '中国能行武汉能行我们能行！！！#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '5783199737',
 'username': '夏曦越Koalas',
 'weibo_url': 'https://weibo.com/5783199737/IqzhHriqD'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 11,
 'id_str': '1892327960_IqzhHrieP',
 'image_url': 'http://wx2.sinaimg.cn/wap180/70caa218gy1gb4mitn46tj20rc0fz76m.jpg',
 'reply_count': 3,
 'retweet_count': 2,
 'text': '【#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。（央视新闻）#黄冈新增12例新型肺炎#',
 'user': '1892327960',
 'username': '成都全搜索新闻网',
 'weibo_url': 'https://weibo.com/1892327960/IqzhHrieP'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 4,
 'id_str': '5261436051_IqzhGhEDe',
 'reply_count': 2,
 'retweet_count': 1,
 'source': '三星 Galaxy S7 Edge',
 'text': '#黄冈新增12例新型肺炎#希望湖北顺遂安康希望大家都好好的希望都有一个好年离武汉黄冈非常非常近真的好害怕过年还要去上学今年真的真的很重要希望高三平平安安一直想高考完想报医科大学我也想成为医生不光是为了家人只是希望我能够尽一份绵薄之力武汉加油都要加油啊',
 'user': '5261436051',
 'username': '北南之境',
 'weibo_url': 'https://weibo.com/5261436051/IqzhGhEDe'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1412248752_IqzhFEAxN',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '华为P9手机摄影再突破',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '1412248752',
 'username': '舒墨自然',
 'weibo_url': 'https://weibo.com/1412248752/IqzhFEAxN'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1662638292_IqzhF5iDU',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Samsung Galaxy S8',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '1662638292',
 'username': '悲天人',
 'weibo_url': 'https://weibo.com/1662638292/IqzhF5iDU'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1708119357_IqzhExhGa',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '1708119357',
 'username': '新闻不是新闻',
 'weibo_url': 'https://weibo.com/1708119357/IqzhExhGa'}
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 2,
 'id_str': '6512797703_IqzhEtCs8',
 'reply_count': 6,
 'retweet_count': 6,
 'source': 'HUAWEI Mate 30',
 'text': '转：#武汉肺炎#通过与我们NIH基因库(GenBank)里基因序列的比对，现在基本可以确定武汉发现的新型冠状病毒就是南京军区军事医学研究所和第三军医大学2018年1月联合发布的中华菊头蝠（在舟山捕获）所携带的SARS病毒的同源病毒！两者除了88%的序列相似度之外，其特异标志性的ORF-8基因片段相似度高达94.2%！而且与2003年的非典SARS病毒(源于云南中华菊头蝠)序列也有80%的相似度！所以，此次武汉暴发的新病毒属于SARS样或者类SARS的2b组的Beta冠状病毒！由于南京军区军事医学研究所2018年初时即已明确报导该病毒具有跨种属的传染性(人传人)，所以一定不能掉以轻心！目前统计该病毒感染后重症率为14%，致死率4%。已发现有集聚性(即整个家庭感染)。重点防控地点应为农贸市场，其中野生动物、禽畜等是重要源头之一！各位一线的朋友好自为之！',
 'user': '6512797703',
 'username': '勿语同蒙',
 'weibo_url': 'https://weibo.com/6512797703/IqzhEtCs8'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '3616451957_IqzhDBBWH',
 'origin_weibo': 'https://weibo.cn/comment/IqxGL4CFN?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '【武汉#首例重症新型肺炎出院者发声#：护士姐姐特别好，总给我加油】武汉首例重症新型肺炎出院患者李先生向梨视频详细讲述了被隔离治疗的经过。他说，姐姐冲进隔离室照顾他直到痊愈，“护士姐姐们特别好，总是给我加油打气。”其间，朋友和邻居都来看他。23岁的他，终于治愈出院。#国内确诊291例新型冠状病毒肺炎病例##武汉新型肺炎患者救治由政府买单#http://t.cn/A6vrC5ME',
 'user': '3616451957',
 'username': 'Dehaan_',
 'weibo_url': 'https://weibo.com/3616451957/IqzhDBBWH'}
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '2101415084_IqzhDBBRQ',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '微博 weibo.com',
 'text': '武汉肺炎，需要异于寻常的防控手段武汉肺炎，需要异于寻常的防控手段',
 'user': '2101415084',
 'username': '靠谱不得',
 'weibo_url': 'https://weibo.com/2101415084/IqzhDBBRQ'}
2020-01-22 16:32:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10>
{'crawled_at': '2020-01-22 16:32:03',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '2208285211_IqzhDjWgJ',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#明天下午湖北，路过武汉',
 'user': '2208285211',
 'username': 'T-eemo',
 'weibo_url': 'https://weibo.com/2208285211/IqzhDjWgJ'}
2020-01-22 16:32:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2696979161> (referer: https://weibo.cn/2696979161/info)
2020-01-22 16:32:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2696979161>
{'brief_introduction': '最近开始做毕业论文项目啦，还请大家多多关照！关注我前请先确认你喜欢看男人和男人搞对象，我不对任何造成的精神伤害负责。',
 'city': '美国',
 'crawled_at': '2020-01-22 16:32:04',
 'fans_num': 5836,
 'follows_num': 268,
 'gender': '女',
 'id': '2696979161',
 'labels': '硬塞,汤粥,教授X老万',
 'name': '蛞蝓搓揉着触角说',
 'province': '海外',
 'tweets_num': 20077,
 'vip_level': '6级'}
2020-01-22 16:32:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2703419987> (referer: https://weibo.cn/2703419987/info)
2020-01-22 16:32:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:06	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2703419987>
{'authentication': '共青团广安市委员会官方微博',
 'birthday': '0001-00-00',
 'brief_introduction': '这里是广安共青团，广安青年家园。获取更多青年资讯，欢迎关注微信公众号：共青团广安市委员会（gqtgasw）。青春路上，你我同行！肩负时代责任，汇聚青春力量。共谋青春大事，同谱年轻赞歌。',
 'city': '广安',
 'crawled_at': '2020-01-22 16:32:06',
 'fans_num': 529128,
 'follows_num': 2639,
 'gender': '男',
 'id': '2703419987',
 'labels': '小平故里,伟人故里,广安',
 'name': '共青团广安市委',
 'province': '四川',
 'tweets_num': 41419,
 'vip_level': '6级'}
2020-01-22 16:32:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2728780847> (referer: https://weibo.cn/2728780847/info)
2020-01-22 16:32:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:07	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2728780847>
{'authentication': '本地资讯博主（福州）',
 'birthday': '0001-00-00',
 'brief_introduction': '博主微信详见置顶二维码🔝。',
 'crawled_at': '2020-01-22 16:32:07',
 'fans_num': 171774,
 'follows_num': 1787,
 'gender': '男',
 'id': '2728780847',
 'labels': '福州历史,福州地产,福州建筑',
 'name': '福州城市建设',
 'province': '福建',
 'tweets_num': 19094,
 'vip_level': '6级'}
2020-01-22 16:32:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2948949893> (referer: https://weibo.cn/2948949893/info)
2020-01-22 16:32:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:08	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2948949893>
{'birthday': '1991-06-04',
 'brief_introduction': 'Vx:13432026165孤独难能可贵，不言语的人比较美',
 'city': '广州',
 'crawled_at': '2020-01-22 16:32:08',
 'fans_num': 1326,
 'follows_num': 611,
 'gender': '女',
 'id': '2948949893',
 'labels': '娱乐',
 'name': '谁也不懂得谁',
 'province': '广东',
 'tweets_num': 1963,
 'vip_level': '未开通'}
2020-01-22 16:32:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1848028791> (referer: https://weibo.cn/1848028791/info)
2020-01-22 16:32:09	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1848028791>
{'birthday': '1987-11-21',
 'brief_introduction': '善良的天蝎女',
 'city': '朝阳区',
 'crawled_at': '2020-01-22 16:32:09',
 'fans_num': 184,
 'follows_num': 220,
 'gender': '女',
 'id': '1848028791',
 'name': 'Cathy_A',
 'province': '北京',
 'tweets_num': 536,
 'vip_level': '未开通'}
2020-01-22 16:32:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6279622426> (referer: https://weibo.cn/6279622426/info)
2020-01-22 16:32:11	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6279622426>
{'birthday': '2018-02-07',
 'brief_introduction': '那一天 那一刻 那个场景 你出现在我生命',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:32:11',
 'fans_num': 130,
 'follows_num': 134,
 'gender': '男',
 'id': '6279622426',
 'name': '0臭臭真臭0',
 'province': '湖北',
 'tweets_num': 353,
 'vip_level': '4级'}
2020-01-22 16:32:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5228035069> (referer: https://weibo.cn/5228035069/info)
2020-01-22 16:32:12	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5228035069>
{'birthday': '1996-10-04',
 'brief_introduction': '有些话你不经意的说出了口，我却认真的难过了好久，只是因为我在乎你。',
 'city': '广州',
 'crawled_at': '2020-01-22 16:32:12',
 'fans_num': 347,
 'follows_num': 140,
 'gender': '男',
 'id': '5228035069',
 'name': 'M安夏如沫',
 'province': '广东',
 'tweets_num': 919,
 'vip_level': '未开通'}
2020-01-22 16:32:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6878548032> (referer: https://weibo.cn/6878548032/info)
2020-01-22 16:32:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6878548032>
{'birthday': '1994-06-30',
 'brief_introduction': '量子力学量力学',
 'crawled_at': '2020-01-22 16:32:13',
 'fans_num': 143,
 'follows_num': 289,
 'gender': '女',
 'id': '6878548032',
 'name': '乱拳打死小青蛙',
 'province': '广西',
 'sentiment': '单身',
 'tweets_num': 1054,
 'vip_level': '5级'}
2020-01-22 16:32:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1713465100> (referer: https://weibo.cn/1713465100/info)
2020-01-22 16:32:15	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1713465100>
{'brief_introduction': '南辕北辙 殊途同归',
 'city': '其他',
 'crawled_at': '2020-01-22 16:32:15',
 'fans_num': 1400,
 'follows_num': 502,
 'gender': '女',
 'id': '1713465100',
 'labels': '不打比方會死',
 'name': '范如也',
 'province': '香港',
 'tweets_num': 5764,
 'vip_level': '未开通'}
2020-01-22 16:32:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2168732153> (referer: https://weibo.cn/2168732153/info)
2020-01-22 16:32:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2168732153>
{'birthday': '1900-01-01',
 'brief_introduction': '做个好人',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:32:16',
 'fans_num': 337,
 'follows_num': 213,
 'gender': '女',
 'id': '2168732153',
 'labels': '时尚',
 'name': '大菲姐-',
 'province': '湖北',
 'tweets_num': 271,
 'vip_level': '2级'}
2020-01-22 16:32:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1662638292/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1412248752/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5261436051/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1892327960/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5783199737/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3616451957/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2208285211/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:24	scrapy.extensions.logstats	INFO	Crawled 187 pages (at 49 pages/min), scraped 182 items (at 40 items/min)
2020-01-22 16:32:25	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6512797703/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1708119357/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=10)
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 14,
 'id_str': '1787567623_IqzhD2jgi',
 'image_url': 'http://wx2.sinaimg.cn/wap180/6a8c1e07ly1frd8i0m13wj20w92ol4o1.jpg',
 'origin_weibo': 'https://weibo.cn/comment/GgVdpjP2I?rl=1#cmtfrm',
 'reply_count': 3,
 'retweet_count': 16,
 'source': '微博 weibo.com',
 'text': '199IT大数据导航【HAO.199IT.COM】目前上线3000多款数据工具，近日新增【客户服务工具】【人口普查数据库】【知名智库机构】栏目，本站是您工作好帮手，欢迎大家收藏并分享更多的人。199IT大数据导航',
 'user': '1787567623',
 'username': '199IT-互联网数据资讯网',
 'weibo_url': 'https://weibo.com/1787567623/IqzhD2jgi'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 7,
 'id_str': '5347795977_IqzhD0YxP',
 'reply_count': 0,
 'retweet_count': 3,
 'source': '专业版微博',
 'text': '#北京新增5例新型肺炎病例#【快讯！北京今日新增5例新型肺炎病例！患者均于近期前往武汉】1月21日，据北京市卫健委通报，本市新增5例新型冠状病毒感染的肺炎病例。5名新确诊患者已在定点医院接受隔离治疗，现已对21名密切接触者开展医学观察。截至1月21日18时，北京市共确诊10例新型肺炎病例。http://t.cn/A6vdQRf6',
 'user': '5347795977',
 'username': '青蜂侠Bee',
 'weibo_url': 'https://weibo.com/5347795977/IqzhD0YxP'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '3495630685_IqzhCrzez',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '够快才畅快vivo X6S',
 'text': '【转发了解！#新型冠状病毒肺炎潜伏期#】国家卫健委专家组成员高占成表示，新型冠状病毒肺炎的潜伏期平均在7天左右，短的在2-3天，长的10-12天。如出现发热、干咳、呼吸衰竭、休克等症状，请及时就医！（央视）央视新闻的微博视频',
 'user': '3495630685',
 'username': '文明安顺开发区',
 'weibo_url': 'https://weibo.com/3495630685/IqzhCrzez'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 9,
 'id_str': '6272693374_IqzhCphuL',
 'place': '白银·甘肃白银会宁',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'OPPO Reno',
 'text': '希望明天起来看到的消息是已得到控制🙏🙏🙏#武汉新型肺炎患者救治由政府买单#',
 'user': '6272693374',
 'username': 'CL木偶人',
 'weibo_url': 'https://weibo.com/6272693374/IqzhCphuL'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1691934393_IqzhBxdkt',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '黑鲨游戏手机 2',
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '1691934393',
 'username': '木马鱼雷',
 'weibo_url': 'https://weibo.com/1691934393/IqzhBxdkt'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 3,
 'id_str': '1905391435_IqzhADUzz',
 'image_url': 'http://wx1.sinaimg.cn/wap180/7191f74bgy1gb4mifj6adj20rs11r76l.jpg',
 'reply_count': 0,
 'retweet_count': 2,
 'text': '#晚安心语#【今天，转发#武汉新型肺炎防治倡议#！】让我们一起努力，早日打赢这场看不见硝烟的战争！武汉加油！晚安',
 'user': '1905391435',
 'username': '北京旅游网官方微博',
 'weibo_url': 'https://weibo.com/1905391435/IqzhADUzz'}
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 7,
 'id_str': '6544635970_IqzhADFfN',
 'reply_count': 0,
 'retweet_count': 1,
 'source': 'Android',
 'text': '#武汉新型肺炎患者救治由政府买单#新型肺炎什么时候才能结束好多地方都有新增病例过年了希望大家都能平安健康我们的医护人员辛苦了咖啡遇见冰糖的微博视频',
 'user': '6544635970',
 'username': '咖啡遇见冰糖',
 'weibo_url': 'https://weibo.com/6544635970/IqzhADFfN'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 6,
 'id_str': '1199680454_IqzhADELr',
 'place': '三亚·三亚·山水国际',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone XR',
 'text': '#武汉新型肺炎患者救治由政府买单#点个大大的赞！抵抗病毒，全民有责！挺住！武汉！',
 'user': '1199680454',
 'username': '三亚游艇小哥',
 'weibo_url': 'https://weibo.com/1199680454/IqzhADELr'}
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 1,
 'id_str': '1564876465_IqzhAm0CM',
 'place': True,
 'reply_count': 0,
 'retweet_count': 0,
 'source': '小米9',
 'text': '#武汉新型肺炎患者救治均由政府买单#今天，国家卫健委发布通报：2020年1月20日0-24时，我委收到国内3省（区、市）报告新增新型冠状病毒感染的肺炎确诊病例77例（湖北省72例，上海市2例，北京市3例）；9省（区、市）报告新增疑似病例27例（广东省4例，四川省1例，云南省1例，上海市7例，浙江省10例，安徽省1例，海南省1例，贵州省1例，宁夏回族自治区1例）。截至20日24时，我委收到国内4省（区、市）累计报告新型冠状病毒感染的肺炎确诊病例291例（湖北省270例，北京市5例，广东省14例，上海市2例）；14省（区、市）累计报告疑似病例54例（湖北省11例，广东省7例，四川省3例，云南省1例，上海市7例，广西壮族自治区1例，山东省1例，吉林省1例，安徽省1例，浙江省16例，江西省2例，海南省1例，贵州省1例，宁夏回族自治区1例）。收到日本通报确诊病例1例，泰国通报确诊病例2例，韩国通报确诊病例1例。目前追踪到密切接触者1739人，已解除医学观察817人，尚有922人正在接受医学观察。',
 'user': '1564876465',
 'username': '导演潇扬',
 'weibo_url': 'https://weibo.com/1564876465/IqzhAm0CM'}
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11>
{'crawled_at': '2020-01-22 16:32:26',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 2,
 'id_str': '1406419784_IqzhA5Gux',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 1,
 'retweet_count': 0,
 'source': '微博 weibo.com',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '1406419784',
 'username': 'xiongyongqiang',
 'weibo_url': 'https://weibo.com/1406419784/IqzhA5Gux'}
2020-01-22 16:32:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1662638292> (referer: https://weibo.cn/1662638292/info)
2020-01-22 16:32:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:28	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1662638292>
{'birthday': '0001-00-00',
 'brief_introduction': '站在最广大 老百姓 根本利益 一边。少谈主义，多研究问题，别忽悠也别折腾老百姓；',
 'city': '东城区',
 'crawled_at': '2020-01-22 16:32:28',
 'fans_num': 748,
 'follows_num': 231,
 'gender': '男',
 'id': '1662638292',
 'name': '悲天人',
 'province': '北京',
 'tweets_num': 55350,
 'vip_level': '未开通'}
2020-01-22 16:32:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1412248752> (referer: https://weibo.cn/1412248752/info)
2020-01-22 16:32:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:28	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1412248752>
{'birthday': '巨蟹座',
 'brief_introduction': '默藏其用，息之深深。白云高卧，世无知音。',
 'city': '通州区',
 'crawled_at': '2020-01-22 16:32:28',
 'fans_num': 71,
 'follows_num': 190,
 'gender': '女',
 'id': '1412248752',
 'labels': '绘画,书,教育',
 'name': '舒墨自然',
 'province': '北京',
 'sentiment': '已婚',
 'tweets_num': 2888,
 'vip_level': '2级'}
2020-01-22 16:32:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5261436051> (referer: https://weibo.cn/5261436051/info)
2020-01-22 16:32:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:30	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5261436051>
{'brief_introduction': '冷圈爱好者|真的不是僵尸|天雷信白|云亮|雷安雷',
 'city': '杭州',
 'crawled_at': '2020-01-22 16:32:30',
 'fans_num': 52,
 'follows_num': 191,
 'gender': '男',
 'id': '5261436051',
 'name': '北南之境',
 'province': '浙江',
 'tweets_num': 32,
 'vip_level': '未开通'}
2020-01-22 16:32:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1892327960> (referer: https://weibo.cn/1892327960/info)
2020-01-22 16:32:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:31	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1892327960>
{'authentication': '成都全搜索新闻网官方微博',
 'brief_introduction': '成都全搜索新闻网是成都市新闻门户网站，由成都市政府新闻办公室主管，成都传媒集团主办，人民群众简称“全叔”。新闻爆料邮箱：100406616@qq.com。',
 'crawled_at': '2020-01-22 16:32:31',
 'fans_num': 1020886,
 'follows_num': 1688,
 'gender': '男',
 'id': '1892327960',
 'labels': '娛樂,写作,购物',
 'name': '成都全搜索新闻网',
 'province': '四川',
 'tweets_num': 72328,
 'vip_level': '6级'}
2020-01-22 16:32:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5783199737> (referer: https://weibo.cn/5783199737/info)
2020-01-22 16:32:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:31	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5783199737>
{'birthday': '2003-02-23',
 'city': '广州',
 'crawled_at': '2020-01-22 16:32:31',
 'fans_num': 136,
 'follows_num': 64,
 'gender': '女',
 'id': '5783199737',
 'labels': '文艺,工作,钢琴',
 'name': '夏曦越Koalas',
 'province': '广东',
 'sentiment': '单身',
 'tweets_num': 3,
 'vip_level': '1级'}
2020-01-22 16:32:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3616451957> (referer: https://weibo.cn/3616451957/info)
2020-01-22 16:32:32	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3616451957>
{'birthday': '1996-10-22',
 'brief_introduction': 'JUST DONT PUSH SO HARD',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:32:32',
 'fans_num': 701,
 'follows_num': 219,
 'gender': '男',
 'id': '3616451957',
 'labels': '情感生活',
 'name': 'Dehaan_',
 'province': '湖北',
 'tweets_num': 805,
 'vip_level': '4级'}
2020-01-22 16:32:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2208285211> (referer: https://weibo.cn/2208285211/info)
2020-01-22 16:32:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2208285211>
{'authentication': '娱乐博主',
 'birthday': '1994-11-19',
 'brief_introduction': '🙊🙊🙊',
 'city': '金华',
 'crawled_at': '2020-01-22 16:32:34',
 'fans_num': 3425,
 'follows_num': 489,
 'gender': '男',
 'id': '2208285211',
 'labels': '初级话务,90后但我不脑残,单身',
 'name': 'T-eemo',
 'province': '浙江',
 'sentiment': '单身',
 'sex_orientation': '异性恋',
 'tweets_num': 230,
 'vip_level': '3级'}
2020-01-22 16:32:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6512797703> (referer: https://weibo.cn/6512797703/info)
2020-01-22 16:32:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6512797703>
{'birthday': '处女座',
 'brief_introduction': '快看，那个人好像一条狗诶',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:32:34',
 'fans_num': 86,
 'follows_num': 106,
 'gender': '男',
 'id': '6512797703',
 'name': '勿语同蒙',
 'province': '湖北',
 'tweets_num': 151,
 'vip_level': '1级'}
2020-01-22 16:32:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1691934393/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:32:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6272693374/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:32:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3495630685/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:32:39	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5347795977/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:32:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1787567623/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:32:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:32:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1564876465/IqzhAm0CM> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:09	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/1564876465/IqzhAm0CM>
{'crawled_at': '2020-01-22 16:33:09',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 1,
 'id_str': '1564876465_IqzhAm0CM',
 'place': '北京',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '小米9',
 'text': '#武汉新型肺炎患者救治均由政府买单#今天，国家卫健委发布通报：2020年1月20日0-24时，我委收到国内3省（区、市）报告新增新型冠状病毒感染的肺炎确诊病例77例（湖北省72例，上海市2例，北京市3例）；9省（区、市）报告新增疑似病例27例（广东省4例，四川省1例，云南省1例，上海市7例，浙江省10例，安徽省1例，海南省1例，贵州省1例，宁夏回族自治区1例）。截至20日24时，我委收到国内4省（区、市）累计报告新型冠状病毒感染的肺炎确诊病例291例（湖北省270例，北京市5例，广东省14例，上海市2例）；14省（区、市）累计报告疑似病例54例（湖北省11例，广东省7例，四川省3例，云南省1例，上海市7例，广西壮族自治区1例，山东省1例，吉林省1例，安徽省1例，浙江省16例，江西省2例，海南省1例，贵州省1例，宁夏回族自治区1例）。收到日本通报确诊病例1例，泰国通报确诊病例2例，韩国通报确诊病例1例。目前追踪到密切接触者1739人，已解除医学观察817人，尚有922人正在接受医学观察。',
 'user': '1564876465',
 'username': '导演潇扬',
 'weibo_url': 'https://weibo.com/1564876465/IqzhAm0CM'}
2020-01-22 16:33:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1564876465/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1199680454/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:12	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1406419784/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6544635970/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:14	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1905391435/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1708119357> (referer: https://weibo.cn/1708119357/info)
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1708119357>
{'birthday': '处女座',
 'brief_introduction': '本人信奉中庸之道，既不保守、也不跃进，深感生活就是一本书，大家都在演戏而已。',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:33:16',
 'fans_num': 787,
 'follows_num': 972,
 'gender': '男',
 'id': '1708119357',
 'labels': '处女座,搞笑,睡觉',
 'name': '新闻不是新闻',
 'province': '湖北',
 'tweets_num': 8663,
 'vip_level': '未开通'}
2020-01-22 16:33:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=11)
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 7,
 'id_str': '6121908845_IqzhztXII',
 'image_url': 'http://wx1.sinaimg.cn/wap180/006GiU9fly1gb4micjq41j30u016wwjb.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'vivo智能手机',
 'text': '#武汉新型肺炎患者救治由政府买单#武汉加油中国加油',
 'user': '6121908845',
 'username': '你爸爸还是你爸爸07',
 'weibo_url': 'https://weibo.com/6121908845/IqzhztXII'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 1,
 'id_str': '1761842125_IqzhzsF28',
 'image_url': 'http://wx2.sinaimg.cn/wap180/690393cdgy1gb4mihs9fbj20u0140jxz.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '华为P8',
 'text': '1/21最近被从武汉传往各地的肺炎弄得人心惶惶，不过也是千万千万不要不把它当回事儿，因为这个病毒目前能损害你的消化系统，让你日渐消瘦！寝食难安！年会过后做好公交车，回到住处快22点，走进亮灯的药店问问口罩多少钱一包？答曰:30元，心想，你怎么不去抢呐！左翻右找，终于找到了一个之前的库存！不管怎样用上再说！宁可信其有，不可信其无！再说说今年的年会，前年抽中了没在，连续两年人在没抽中！概率太小了！送温暖，送温暖！想想老板花了多少钱？一等奖一名3000元，二等奖两名2000元，三等奖5名华为手机一部，四等奖20名500元沃尔玛购物卡合计2200元，另外郭总两个2000元红包，杜总两个2000元红包，赵总3000元红包一个，赵董事长3000元红包一个，合计14000元，这就是今晚所有的奖项，可惜没有我，晚安吧',
 'user': '1761842125',
 'username': '宁静如流苏',
 'weibo_url': 'https://weibo.com/1761842125/IqzhzsF28'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '2247568230_IqzhxpDXp',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 5,
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '2247568230',
 'username': '用户没有输入昵称',
 'weibo_url': 'https://weibo.com/2247568230/IqzhxpDXp'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '3487672427_IqzhusJnP',
 'origin_weibo': 'https://weibo.cn/comment/Iqxzog6F3?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '努比亚小牛8前后双摄',
 'text': '这个采访很有价值：一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话',
 'user': '3487672427',
 'username': '初见狐狸',
 'weibo_url': 'https://weibo.com/3487672427/IqzhusJnP'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 16,
 'id_str': '5979261191_IqzhurUeE',
 'place': '日照',
 'reply_count': 0,
 'retweet_count': 1,
 'source': 'OPPO超视野全面屏R15',
 'text': '#黄冈新增12例新型肺炎#武汉人民一定要挺住啊大家与你同在',
 'user': '5979261191',
 'username': '野土元气女汉子',
 'weibo_url': 'https://weibo.com/5979261191/IqzhurUeE'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 20,
 'id_str': '5449602816_IqzhuafQn',
 'reply_count': 28,
 'retweet_count': 1,
 'text': '#国内确诊291例新型冠状病毒肺炎病例#为什么只是去过武汉就被感染，可是武汉那么多人口确诊数才几百，这个病的传播途径到底是什么。',
 'user': '5449602816',
 'username': '你亲爱的羊肉串吖',
 'weibo_url': 'https://weibo.com/5449602816/IqzhuafQn'}
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 1,
 'id_str': '1110432760_IqzhtgVAM',
 'image_url': 'http://wx4.sinaimg.cn/wap180/422fdbf8ly1gb4mhfnwezj20rs2g8n3x.jpg',
 'reply_count': 1,
 'retweet_count': 0,
 'text': '#新型冠状病毒肺炎最新情况#：#全国已确诊新型肺炎病例319例#截止1月21日23时，全国已确诊新型肺炎病例319例。没事别出门，出门戴口罩。安全第一条！！！#晚安##武汉新型肺炎患者救治均由政府买单#',
 'user': '1110432760',
 'username': '语涵视听',
 'weibo_url': 'https://weibo.com/1110432760/IqzhtgVAM'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 2,
 'id_str': '5718219547_Iqzht1pFE',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P30',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#医生真的不容易，希望每一位冲在一线的医护人员都能够平安，希望疫情能够得到控制，希望武汉能够传来好的消息！也希望大家都能够引起重视！#武汉新型肺炎患者救治由政府买单#',
 'user': '5718219547',
 'username': '请叫我小郝同学IMO',
 'weibo_url': 'https://weibo.com/5718219547/Iqzht1pFE'}
2020-01-22 16:33:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12>
{'crawled_at': '2020-01-22 16:33:16',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '3872472373_IqzhsF4o3',
 'origin_weibo': 'https://weibo.cn/comment/IqxzGeyWT?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone 7 Plus',
 'text': '什么样的人会成为超级“毒弹”？病毒在他体内经历了什么过程才让他变成“毒弹”的？还挺想了解下的。',
 'user': '3872472373',
 'username': '博看博听',
 'weibo_url': 'https://weibo.com/3872472373/IqzhsF4o3'}
2020-01-22 16:33:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1691934393> (referer: https://weibo.cn/1691934393/info)
2020-01-22 16:33:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1691934393>
{'city': '黔东南',
 'crawled_at': '2020-01-22 16:33:18',
 'fans_num': 75,
 'follows_num': 546,
 'gender': '男',
 'id': '1691934393',
 'name': '木马鱼雷',
 'province': '贵州',
 'tweets_num': 1443,
 'vip_level': '未开通'}
2020-01-22 16:33:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6272693374> (referer: https://weibo.cn/6272693374/info)
2020-01-22 16:33:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:19	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6272693374>
{'birthday': '2000-05-24',
 'brief_introduction': '生活，简单点就好',
 'city': '西安',
 'crawled_at': '2020-01-22 16:33:19',
 'fans_num': 183,
 'follows_num': 421,
 'gender': '女',
 'id': '6272693374',
 'labels': '搞笑,生活',
 'name': 'CL木偶人',
 'province': '陕西',
 'tweets_num': 271,
 'vip_level': '未开通'}
2020-01-22 16:33:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3495630685> (referer: https://weibo.cn/3495630685/info)
2020-01-22 16:33:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3495630685>
{'authentication': '贵州省安顺经济技术开发区宣传部官方微博',
 'birthday': '1998-11-20',
 'city': '安顺',
 'crawled_at': '2020-01-22 16:33:20',
 'fans_num': 3471,
 'follows_num': 323,
 'gender': '男',
 'id': '3495630685',
 'labels': '贵州生活',
 'name': '文明安顺开发区',
 'province': '贵州',
 'tweets_num': 33652,
 'vip_level': '1级'}
2020-01-22 16:33:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5347795977> (referer: https://weibo.cn/5347795977/info)
2020-01-22 16:33:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:22	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5347795977>
{'authentication': '中国青年网短视频官方微博',
 'birthday': '2013-05-04',
 'brief_introduction': '中青网品牌短视频栏目。严肃打捞各类有趣、有品的新闻边角料。',
 'crawled_at': '2020-01-22 16:33:22',
 'fans_num': 1570355,
 'follows_num': 485,
 'gender': '男',
 'id': '5347795977',
 'labels': '活泼开朗,努力,思考',
 'name': '青蜂侠Bee',
 'province': '北京',
 'tweets_num': 9745,
 'vip_level': '未开通'}
2020-01-22 16:33:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1787567623> (referer: https://weibo.cn/1787567623/info)
2020-01-22 16:33:23	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1787567623>
{'authentication': '199it.com官方网站微博',
 'birthday': '2009-09-01',
 'brief_introduction': '找数据，上199IT--数据创造价值！ 投搞：T@199it.com 微信：i199it',
 'crawled_at': '2020-01-22 16:33:23',
 'fans_num': 358276,
 'follows_num': 1888,
 'gender': '男',
 'id': '1787567623',
 'labels': '大数据资讯,大数据研究,大数据工具',
 'name': '199IT-互联网数据资讯网',
 'province': '北京',
 'tweets_num': 76781,
 'vip_level': '7级'}
2020-01-22 16:33:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1564876465> (referer: https://weibo.cn/1564876465/info)
2020-01-22 16:33:24	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1564876465>
{'authentication': '电影博主',
 'birthday': '1986-02-07',
 'brief_introduction': '电影《恋爱大师》电影《功夫达人》电影《邂逅危机》诚招有意者合作！',
 'city': '西城区',
 'crawled_at': '2020-01-22 16:33:24',
 'fans_num': 128915,
 'follows_num': 2024,
 'gender': '男',
 'id': '1564876465',
 'labels': '潇扬传媒,80后电影人,潇扬',
 'name': '导演潇扬',
 'province': '北京',
 'tweets_num': 2688,
 'vip_level': '7级'}
2020-01-22 16:33:24	scrapy.extensions.logstats	INFO	Crawled 217 pages (at 30 pages/min), scraped 217 items (at 35 items/min)
2020-01-22 16:33:25	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1199680454> (referer: https://weibo.cn/1199680454/info)
2020-01-22 16:33:25	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1199680454>
{'authentication': '知名旅游博主 头条文章作者 微博签约自媒体',
 'birthday': '01-01',
 'brief_introduction': '旅游资讯、旅游攻略、旅游实拍',
 'crawled_at': '2020-01-22 16:33:25',
 'fans_num': 249823,
 'follows_num': 494,
 'gender': '男',
 'id': '1199680454',
 'labels': '网络,NBA,爱情',
 'name': '三亚游艇小哥',
 'province': '海南',
 'tweets_num': 6200,
 'vip_level': '7级'}
2020-01-22 16:33:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1406419784> (referer: https://weibo.cn/1406419784/info)
2020-01-22 16:33:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1406419784>
{'birthday': '01-01',
 'brief_introduction': '季文子三思而后行。子闻之曰：“再，斯可矣。”',
 'city': '海淀区',
 'crawled_at': '2020-01-22 16:33:26',
 'fans_num': 248493,
 'follows_num': 456,
 'gender': '男',
 'id': '1406419784',
 'name': 'xiongyongqiang',
 'province': '北京',
 'tweets_num': 46600,
 'vip_level': '4级'}
2020-01-22 16:33:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6544635970> (referer: https://weibo.cn/6544635970/info)
2020-01-22 16:33:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6544635970>
{'birthday': '狮子座',
 'brief_introduction': '🇨🇳',
 'crawled_at': '2020-01-22 16:33:27',
 'fans_num': 352,
 'follows_num': 85,
 'gender': '女',
 'id': '6544635970',
 'name': '咖啡遇见冰糖',
 'province': '其他',
 'tweets_num': 210,
 'vip_level': '5级'}
2020-01-22 16:33:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1905391435> (referer: https://weibo.cn/1905391435/info)
2020-01-22 16:33:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1905391435>
{'authentication': '北京旅游网官方微博',
 'birthday': '0001-00-00',
 'brief_introduction': '北京旅游网是北京市文化和旅游局监管的非营利性网站。www.visitbeijing.com.cn',
 'crawled_at': '2020-01-22 16:33:29',
 'fans_num': 694339,
 'follows_num': 741,
 'gender': '男',
 'id': '1905391435',
 'labels': '吃喝玩乐,旅游,特色酒店',
 'name': '北京旅游网官方微博',
 'province': '北京',
 'tweets_num': 15239,
 'vip_level': '6级'}
2020-01-22 16:33:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5979261191/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3487672427/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2247568230/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1761842125/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6121908845/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3872472373/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5718219547/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1110432760/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5449602816/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:39	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=12)
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 197,
 'id_str': '3514732862_Iqzhrcqty',
 'image_url': 'http://wx3.sinaimg.cn/wap180/d17e913egy1gb4mi13phaj20hr09ragb.jpg',
 'reply_count': 75,
 'retweet_count': 43,
 'source': '微博 weibo.com',
 'text': '#梧州新闻#【广西新增1例新型冠状病毒感染的肺炎疑似病例】1月21日晚，自治区卫生健康委通报，梧州市报告1例新型冠状病毒感染的肺炎疑似病例，患者为男性，梧州市居民，发病前接触过来自武汉的人员，过后出现发热症状。患者已在定点医院隔离治疗，病情稳定。目前，患者实验室检验结果正在按国家病例确认程序复核中，一旦确认，将及时向社会公布。http://t.cn/A6vdQj0W',
 'user': '3514732862',
 'username': '广西日报',
 'weibo_url': 'https://weibo.com/3514732862/Iqzhrcqty'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 1,
 'id_str': '2604143035_Iqzhq2GaR',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone 11',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#2020年第一个愿望就是家人平安武汉平安全世界平安[拳頭]',
 'user': '2604143035',
 'username': '王如花不是花',
 'weibo_url': 'https://weibo.com/2604143035/Iqzhq2GaR'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 8933,
 'id_str': '1618051664_Iqzhp83K0',
 'image_url': 'http://wx1.sinaimg.cn/wap180/60718250ly1gb4mhx2vkej20fa073taz.jpg',
 'reply_count': 1057,
 'retweet_count': 319,
 'source': '微博 weibo.com',
 'text': '【黑龙江#牡丹江发现1例疑似新型肺炎患者#】牡丹江市第二医院呼吸科收治一位去武汉探亲返回的69岁男性危重肺炎患者，1月21日，初步判定新型冠状病毒感染可疑病人，按诊断程序，需要国家、省专家进一步确诊。(牡丹江市政府官网)',
 'user': '1618051664',
 'username': '头条新闻',
 'weibo_url': 'https://weibo.com/1618051664/Iqzhp83K0'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '6025374986_Iqzhpbr7S',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀10 AI变色更潮美',
 'text': '#肺炎#要不先查查源头？可以不要笼统的说是武汉可以不如果是全武汉都有的话，那就当我没说',
 'user': '6025374986',
 'username': '脑阔疼昂',
 'weibo_url': 'https://weibo.com/6025374986/Iqzhpbr7S'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 0,
 'id_str': '1750338185_IqzhnoGWU',
 'reply_count': 3,
 'retweet_count': 0,
 'source': 'iPhone XS Max',
 'text': '武汉肺炎让我好怕可是还要上班按规定体制内人员要大年三十才放假呢我们家已经决定要买多点菜过年哪里也不去了你们都要保护好自己呀我那些在武汉的朋友们你们最好也和我一样哪也不去呆在家里大家都要健健康康的。',
 'user': '1750338185',
 'username': '余余余余余余余余璇儿',
 'weibo_url': 'https://weibo.com/1750338185/IqzhnoGWU'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 7,
 'id_str': '1402324311_IqzhmvkrC',
 'image_url': 'http://wx1.sinaimg.cn/wap180/5395c557gy1gb4mhp05vgj20fg08pq3e.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'UC浏览器Android',
 'text': '【纵相】东方网·纵相新闻记者贾天荣据楚天都市报20日报道，武汉原定于20日起派送20万张惠民旅游券钟南山发预警，武汉紧急叫停20万人惠民出游活动【评论才是亮点】#四川省首例输入性新型冠状病毒感染肺炎病例##老兽医频道##武汉发现不明原因肺炎##韩国现不明原因肺炎病例##日本确认首例新型冠状病毒病例##泰国发现第二例新型冠状病毒肺炎患者##广东确诊1例新型冠状病毒感染肺炎病例##北京确诊2例新型冠状病毒感染肺炎病例##浙江发现5例武汉来浙发热呼吸道症状患者##台湾确诊首例新型冠状病毒肺炎患者##大连发现1例来自武汉发热患者##河南确诊首例新型冠状病毒肺炎##重庆市确诊5例输入性新型冠状病毒感染肺炎病例##天津确诊2名武汉肺炎#http://t.cn/A6vdQWtD',
 'user': '1402324311',
 'username': '沈阳sz1961sy',
 'weibo_url': 'https://weibo.com/1402324311/IqzhmvkrC'}
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:57',
 'favorite_count': 4,
 'id_str': '7181133529_IqzhmtfS5',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#希望疫情尽快得到控制大家一定要戴好口罩注意安全武汉加油[加油]',
 'user': '7181133529',
 'username': '挽卿开颜',
 'weibo_url': 'https://weibo.com/7181133529/IqzhmtfS5'}
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:40	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13>
{'crawled_at': '2020-01-22 16:33:40',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 15,
 'id_str': '1831150900_Iqzhlh2bk',
 'reply_count': 2,
 'retweet_count': 3,
 'source': 'HUAWEI Mate 20 Pro',
 'text': '钟南山院士在电视里说“这次冠状病毒肺炎发源地，来自武汉的那处海鲜市场，我们在现场看，相当多（卖）的并不是海鲜，而是野味。”我们还记得，2003年的SARS病毒，来自于野味果子狸，果子狸之所以携带SARS病毒，是因为它们会捕食菊头蝠，菊头蝠身体中有非典病毒的基因，是SARS病毒的来源者。普通中国人一说起野味，通常会有自然形成两种观点，一是味道好，二是大补，总觉得食物原生态的就是最好的，在这种观念的推行下，才会有人不断地尝试野味。这种错误的观念现在必须要进行纠正了。野生动物味道并不好吃，也不适合食用。多年前，身边的一个朋友曾经描述过吃野猪肉的情景，那个时候她还是个孩子，家住山区，野猪很多，老吃地里的庄稼，于是有人出主意给野猪下套，吓唬它几次就不敢偷吃庄稼了。她家里人抱着试试的想法用了这个招。果然，不久后，一个野猪上套了，家人把这个捕获回来的猎物宰了，经过处理后的野猪肉给邻居分了一些，剩下的留给自己家吃。但是这次吃野猪肉的经历并不愉快，首先，野猪肉非常难煮，骚臭味儿特别大，煮过肉的锅具洗了好多遍还有味儿。其次，烹饪好的肉，肉质干柴，还嚼不动，根本不是享用，是浪费食材，找罪受。生物进化过程中，我们现在能吃的常规食材都是老祖宗几千年以来不断摸索，培育出来的，那些本不属于餐桌上的东西，又难吃又有毒。',
 'user': '1831150900',
 'username': '骑士loves雪茄',
 'weibo_url': 'https://weibo.com/1831150900/Iqzhlh2bk'}
2020-01-22 16:33:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5979261191> (referer: https://weibo.cn/5979261191/info)
2020-01-22 16:33:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5979261191>
{'birthday': '金牛座',
 'brief_introduction': '哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈',
 'crawled_at': '2020-01-22 16:33:41',
 'fans_num': 53,
 'follows_num': 97,
 'gender': '女',
 'id': '5979261191',
 'name': '野土元气女汉子',
 'province': '内蒙古',
 'tweets_num': 165,
 'vip_level': '未开通'}
2020-01-22 16:33:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3487672427> (referer: https://weibo.cn/3487672427/info)
2020-01-22 16:33:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:43	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3487672427>
{'birthday': '1991-11-21',
 'city': '安庆',
 'crawled_at': '2020-01-22 16:33:43',
 'fans_num': 158,
 'follows_num': 286,
 'gender': '女',
 'id': '3487672427',
 'labels': '微博奇葩,旅游,新闻趣事',
 'name': '初见狐狸',
 'province': '安徽',
 'tweets_num': 3329,
 'vip_level': '5级'}
2020-01-22 16:33:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2247568230> (referer: https://weibo.cn/2247568230/info)
2020-01-22 16:33:43	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2247568230>
{'birthday': '天秤座',
 'brief_introduction': '[魏控.奉孝本命.] [仙剑. 漫威. POI. 来打和奥【我永远喜欢桐生战兔】. 岛崎信长/绿川光. '
                       '刀剑. FGO. 舟. SRRX. 鬼灭【大哥！】] 坑超杂，墙头无数。',
 'crawled_at': '2020-01-22 16:33:43',
 'fans_num': 519,
 'follows_num': 1687,
 'gender': '女',
 'id': '2247568230',
 'labels': '铁拳,黑蝠王,黑豹',
 'name': '用户没有输入昵称',
 'province': '重庆',
 'tweets_num': 9076,
 'vip_level': '4级'}
2020-01-22 16:33:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1761842125> (referer: https://weibo.cn/1761842125/info)
2020-01-22 16:33:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1761842125>
{'birthday': '0001-00-00',
 'brief_introduction': '爱如水墨青花，何惧霎那芳华！',
 'city': '深圳',
 'crawled_at': '2020-01-22 16:33:45',
 'fans_num': 630,
 'follows_num': 753,
 'gender': '女',
 'id': '1761842125',
 'labels': '微笑,看书,财经',
 'name': '宁静如流苏',
 'province': '广东',
 'tweets_num': 3759,
 'vip_level': '未开通'}
2020-01-22 16:33:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3872472373> (referer: https://weibo.cn/3872472373/info)
2020-01-22 16:33:48	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3872472373>
{'brief_introduction': '眼观四路，耳闻八方',
 'crawled_at': '2020-01-22 16:33:48',
 'fans_num': 790,
 'follows_num': 4909,
 'gender': '男',
 'id': '3872472373',
 'name': '博看博听',
 'province': '其他',
 'tweets_num': 14391,
 'vip_level': '6级'}
2020-01-22 16:33:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6121908845> (referer: https://weibo.cn/6121908845/info)
2020-01-22 16:33:48	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6121908845>
{'birthday': '2003-08-26',
 'brief_introduction': '热爱可抵岁月漫长',
 'crawled_at': '2020-01-22 16:33:48',
 'fans_num': 132,
 'follows_num': 497,
 'gender': '女',
 'id': '6121908845',
 'name': '你爸爸还是你爸爸07',
 'province': '天津',
 'tweets_num': 2978,
 'vip_level': '2级'}
2020-01-22 16:33:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5718219547> (referer: https://weibo.cn/5718219547/info)
2020-01-22 16:33:49	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5718219547>
{'birthday': '双子座',
 'brief_introduction': '我不希望，因为太懂事而失去了自己',
 'city': '吉林',
 'crawled_at': '2020-01-22 16:33:49',
 'fans_num': 35,
 'follows_num': 108,
 'gender': '女',
 'id': '5718219547',
 'labels': '读书分享,旅游,花样美男',
 'name': '请叫我小郝同学IMO',
 'province': '吉林',
 'tweets_num': 84,
 'vip_level': '1级'}
2020-01-22 16:33:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1110432760> (referer: https://weibo.cn/1110432760/info)
2020-01-22 16:33:50	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1110432760>
{'authentication': '知名音乐博主 音乐视频自媒体',
 'birthday': '01-01',
 'brief_introduction': '笛子＋二胡 双金奖🎶🏆🏆',
 'crawled_at': '2020-01-22 16:33:50',
 'fans_num': 117918,
 'follows_num': 296,
 'gender': '女',
 'id': '1110432760',
 'labels': '葫芦丝,小提琴,时事新闻',
 'name': '语涵视听',
 'province': '北京',
 'tweets_num': 10493,
 'vip_level': '5级'}
2020-01-22 16:33:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5449602816> (referer: https://weibo.cn/5449602816/info)
2020-01-22 16:33:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5449602816>
{'birthday': '1995-11-11',
 'brief_introduction': '💕 人间有味是清欢💕',
 'city': '伊犁',
 'crawled_at': '2020-01-22 16:33:51',
 'fans_num': 2773,
 'follows_num': 633,
 'gender': '女',
 'id': '5449602816',
 'name': '你亲爱的羊肉串吖',
 'province': '新疆',
 'tweets_num': 1123,
 'vip_level': '6级'}
2020-01-22 16:33:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1402324311/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1750338185/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6025374986/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1618051664/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2604143035/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3514732862/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:33:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1831150900/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:33:59	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/7181133529/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:34:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=13)
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 9,
 'id_str': '5526558498_IqzhknGF6',
 'image_url': 'http://wx2.sinaimg.cn/wap180/00620Skily1gb4mhvmskrj30m80s8mxw.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P30 Pro',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#喂，你在武汉吗',
 'user': '5526558498',
 'username': '苏安哟',
 'weibo_url': 'https://weibo.com/5526558498/IqzhknGF6'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 13,
 'id_str': '1735020111_Iqzhk8YCj',
 'reply_count': 2,
 'retweet_count': 0,
 'source': '荣耀V10 我AI的快',
 'text': '#黄冈新增12例新型肺炎#武汉是新型冠状病毒的源头，而现在临近春节，大量的返乡务工人员经过武汉，或者有大量的人员涌入武汉，一个把病毒带出去了，一个来“收集病毒”最后也给带出去了…这样一来，新型冠状病毒可能会呈“爆发趋势”最终变异成“超级病毒”随之而来的将是全国性的爆发！请不自觉的人自觉起来，请自觉的人要更加注意防范！做好个人防护！不要拿生命开玩笑。',
 'user': '1735020111',
 'username': '徽州李哥哥',
 'weibo_url': 'https://weibo.com/1735020111/Iqzhk8YCj'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '6772432602_IqzhjfEdn',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Android',
 'text': '#武汉新型肺炎患者救治由政府买单#🙏',
 'user': '6772432602',
 'username': '静止运动兼熬夜达人',
 'weibo_url': 'https://weibo.com/6772432602/IqzhjfEdn'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 1,
 'id_str': '1544256452_IqzhiFmVK',
 'place': '深圳',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI P30',
 'text': '#武汉新型肺炎患者救治由政府买单#顶一个！#期待，大同世界#',
 'user': '1544256452',
 'username': '拥抱大同世界的潇雨老师',
 'weibo_url': 'https://weibo.com/1544256452/IqzhiFmVK'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '6384056512_IqzhiDiYY',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI nova 3',
 'text': '『正滚动播报“武汉新型肺炎”全国疫情实时动态_新浪直播间』正滚动播报“武汉新型肺炎”全国疫情实时动态',
 'user': '6384056512',
 'username': '第三三三只眼',
 'weibo_url': 'https://weibo.com/6384056512/IqzhiDiYY'}
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '2665683875_IqzhilFn2',
 'reply_count': 2,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '我怎么不在武汉呢让我感染上新型肺炎然后在混沌中死掉这样世界上就少一个矫情、矛盾的人还多一个用于医学研究的标本',
 'user': '2665683875',
 'username': '兔子不吃萝卜yy',
 'weibo_url': 'https://weibo.com/2665683875/IqzhilFn2'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 53,
 'id_str': '1642088277_Iqzhi2LAv',
 'image_url': 'http://wx3.sinaimg.cn/wap180/61e04755ly1gb4mhq3xzoj20ku0urk8x.jpg',
 'reply_count': 20,
 'retweet_count': 51,
 'source': 'iPhone 8',
 'text': '【#山东确诊1例新型肺炎病例#】患者为37岁男性，武汉人，在日照市工作。因发热等症状，于1月17日在日照市就诊，当晚自行至青岛市就诊。经预检分诊了解到其发病前两周内有武汉居住史，立即被收治入院隔离治疗。该病例为新型冠状病毒感染的肺炎确诊病例。目前，患者生命体征平稳。青岛市8名、日照市45名密切接触者正接受医学观察。@人民日报',
 'user': '1642088277',
 'username': '财经网',
 'weibo_url': 'https://weibo.com/1642088277/Iqzhi2LAv'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 45,
 'id_str': '5497006622_IqzhhukJh',
 'image_url': 'http://wx2.sinaimg.cn/wap180/00600Sx8gy1gb4md22aryj30ku0z3k2f.jpg',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#最近在关注这件事情，总能看到一些键盘侠在说武汉人怎么样，南方人怎么样。都是一个国家的人，不要躲在网络上指责，不要当只敢在网络上当重拳出击的人。祝大家都平平安安，健健康康的',
 'user': '5497006622',
 'username': '不吃糖vbb',
 'weibo_url': 'https://weibo.com/5497006622/IqzhhukJh'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '1681448593_Iqzhh9suM',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '1681448593',
 'username': '小岛上De一只嘟',
 'weibo_url': 'https://weibo.com/1681448593/Iqzhh9suM'}
2020-01-22 16:34:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14>
{'crawled_at': '2020-01-22 16:34:02',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 284,
 'id_str': '6073802030_Iqzhh9qBc',
 'reply_count': 11,
 'retweet_count': 17,
 'source': '中国超话',
 'text': '#国内确诊291例新型冠状病毒肺炎病例##黄冈新增12例新型肺炎#钟老您叫我们不要去武汉，您却自己带队去了武汉，希望您也要保护好自己中国医疗太需要您了，高尚的医德医风！防病您功不可没风期限在凌晨的微博视频',
 'user': '6073802030',
 'username': '风期限在凌晨',
 'weibo_url': 'https://weibo.com/6073802030/Iqzhh9qBc'}
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1402324311> (referer: https://weibo.cn/1402324311/info)
2020-01-22 16:34:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:03	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1402324311>
{'authentication': '知名科学科普博主 手机随拍超话小主持人 头条文章作者',
 'brief_introduction': '沈阳 2001年起在网络媒体工作（编辑）、《中国域名经济》主编。生于揭阳的广东中山人。',
 'crawled_at': '2020-01-22 16:34:03',
 'fans_num': 32946,
 'follows_num': 3470,
 'gender': '男',
 'id': '1402324311',
 'labels': '人道公益,医药,宠物',
 'name': '沈阳sz1961sy',
 'province': '北京',
 'tweets_num': 79183,
 'vip_level': '7级'}
2020-01-22 16:34:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1750338185> (referer: https://weibo.cn/1750338185/info)
2020-01-22 16:34:05	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:05	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1750338185>
{'birthday': '1996-02-24',
 'brief_introduction': '微信975295961 and yuyu2haodian',
 'crawled_at': '2020-01-22 16:34:05',
 'fans_num': 395,
 'follows_num': 782,
 'gender': '女',
 'id': '1750338185',
 'name': '余余余余余余余余璇儿',
 'province': '福建',
 'tweets_num': 437,
 'vip_level': '6级'}
2020-01-22 16:34:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6025374986> (referer: https://weibo.cn/6025374986/info)
2020-01-22 16:34:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:06	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6025374986>
{'birthday': '1998-09-29',
 'brief_introduction': '攒够了失望就离开了呦',
 'city': '南京',
 'crawled_at': '2020-01-22 16:34:06',
 'fans_num': 74,
 'follows_num': 175,
 'gender': '男',
 'id': '6025374986',
 'name': '脑阔疼昂',
 'province': '江苏',
 'tweets_num': 98,
 'vip_level': '未开通'}
2020-01-22 16:34:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1618051664> (referer: https://weibo.cn/1618051664/info)
2020-01-22 16:34:08	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1618051664>
{'authentication': '新浪新闻中心24小时播报全球重大新闻',
 'birthday': '0001-00-00',
 'brief_introduction': '每日播报全球各类重要资讯、突发新闻，全天24小时即时发布。欢迎报料、投稿，请发私信或者邮件：xlttnews@vip.sina.com。',
 'crawled_at': '2020-01-22 16:34:08',
 'fans_num': 74173128,
 'follows_num': 1460,
 'gender': '女',
 'id': '1618051664',
 'labels': '新浪,互联网,新闻',
 'name': '头条新闻',
 'province': '北京',
 'tweets_num': 173160,
 'vip_level': '6级'}
2020-01-22 16:34:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3514732862> (referer: https://weibo.cn/3514732862/info)
2020-01-22 16:34:09	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3514732862>
{'authentication': '广西日报官方微博',
 'birthday': '1984-11-27',
 'brief_introduction': '权威领主流，沟通凝力量！《广西日报》，成熟稳重的大叔一枚，生日是1949年12月3日，射手座，充满活力，风趣幽默。爱好广泛，在时政、经济、社会、文化体育领域有独到见解，常常发布重大权威解读。他写得了好文章，玩得了新花样，微博微信聊得了新闻，耍得了帅。你还不认识他的话，生活会缺少很多乐趣哦！',
 'city': '南宁',
 'crawled_at': '2020-01-22 16:34:09',
 'fans_num': 6856412,
 'follows_num': 1284,
 'gender': '男',
 'id': '3514732862',
 'labels': '广西,新闻',
 'name': '广西日报',
 'province': '广西',
 'tweets_num': 117692,
 'vip_level': '3级'}
2020-01-22 16:34:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2604143035> (referer: https://weibo.cn/2604143035/info)
2020-01-22 16:34:10	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2604143035>
{'birthday': '天秤座',
 'brief_introduction': '除了吃还是吃',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:34:10',
 'fans_num': 787,
 'follows_num': 522,
 'gender': '女',
 'id': '2604143035',
 'name': '王如花不是花',
 'province': '湖北',
 'tweets_num': 38,
 'vip_level': '4级'}
2020-01-22 16:34:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1831150900> (referer: https://weibo.cn/1831150900/info)
2020-01-22 16:34:11	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1831150900>
{'birthday': '0001-00-00',
 'brief_introduction': '发现生活乐趣！',
 'city': '成都',
 'crawled_at': '2020-01-22 16:34:11',
 'fans_num': 246,
 'follows_num': 37,
 'gender': '男',
 'id': '1831150900',
 'labels': '做最好的自己,科技,真实力',
 'name': '骑士loves雪茄',
 'province': '四川',
 'tweets_num': 736,
 'vip_level': '未开通'}
2020-01-22 16:34:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/7181133529> (referer: https://weibo.cn/7181133529/info)
2020-01-22 16:34:12	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/7181133529>
{'birthday': '1999-11-13',
 'brief_introduction': '喜欢喜欢超级喜欢翟潇闻',
 'crawled_at': '2020-01-22 16:34:12',
 'fans_num': 288,
 'follows_num': 353,
 'gender': '女',
 'id': '7181133529',
 'name': '挽卿开颜',
 'province': '湖北',
 'tweets_num': 471,
 'vip_level': '未开通'}
2020-01-22 16:34:14	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6384056512/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:14	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1544256452/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6772432602/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1735020111/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5526558498/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6073802030/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1681448593/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5497006622/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:24	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:24	scrapy.extensions.logstats	INFO	Crawled 265 pages (at 48 pages/min), scraped 256 items (at 39 items/min)
2020-01-22 16:34:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1642088277/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2665683875/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=14)
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 9,
 'id_str': '3235579924_Iqzhgzy7U',
 'image_url': 'http://wx4.sinaimg.cn/wap180/c0db0814ly1gb4m9fpuh6j20o317uwj4.jpg',
 'reply_count': 5,
 'retweet_count': 0,
 'source': 'Samsung Galaxy S8',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#好奇地图了一下我们学校离华南海鲜市场的距离……应该是武汉的大学里距离最近的一所了吧……回家半个多月了前几天还感冒了还好我没咳嗽',
 'user': '3235579924',
 'username': '极目送飞鸟',
 'weibo_url': 'https://weibo.com/3235579924/Iqzhgzy7U'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 1,
 'id_str': '2622003940_Iqzhgjiy8',
 'image_url': 'http://wx3.sinaimg.cn/wap180/9c489ae4ly1gb4lfbxe1aj20u00u0wj7.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '小米6 拍人更美',
 'text': '30岁前最后一个生日，再过3天就真的满30岁了。前几天去纹了个眉，染了个头，买了套衣……最近朋友圈不是医闹就是武汉病毒肺炎……今天的我挺开心，中午难得一大家子和谐的坐在一起吃了个饭，晚上还有水果蛋糕🎂吃……。虽然过去的一年人生貌似跌入了谷底，我相信新的一年新气象，一切从新开始。',
 'user': '2622003940',
 'username': '郭小zhuo加油',
 'weibo_url': 'https://weibo.com/2622003940/Iqzhgjiy8'}
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 26,
 'id_str': '6297332728_IqzhfovUZ',
 'image_url': 'http://wx2.sinaimg.cn/wap180/006SaXUIly1gb4mg5k3vdj30k0140gos.jpg',
 'reply_count': 3,
 'retweet_count': 0,
 'source': '荣耀7A 全屏 人脸识别',
 'text': '骨科医生都出动了希望大家都好好的白衣天使们挺住武汉加油！江苏也加油啊现在江苏瑟瑟发抖#国内确诊291例新型冠状病毒肺炎病例##武汉15名医务人员感染新型冠状病毒##钟南山#',
 'user': '6297332728',
 'username': '爱吃烊喔',
 'weibo_url': 'https://weibo.com/6297332728/IqzhfovUZ'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '5340053863_Iqzhf6kuL',
 'origin_weibo': 'https://weibo.cn/comment/Iqz7UfshD?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 30 Pro',
 'text': '【#武汉新型肺炎死亡增至6例#】湖北省武汉市市长周先旺表示，截至2020年1月20日24时，武汉市累计报告新型冠状病毒感染的肺炎病例258例，已治愈出院25例，死亡6例。目前仍在院治疗227例，其中重症51例、危重症12例，均在武汉市定点医疗机构接受隔离治疗。愿平安！#武汉制定诊疗方案#http://t.cn/A6vrbvDa',
 'user': '5340053863',
 'username': '好吃的苦巧克力',
 'weibo_url': 'https://weibo.com/5340053863/Iqzhf6kuL'}
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '5150661033_IqzheuBZe',
 'origin_weibo': 'https://weibo.cn/comment/IqxGL4CFN?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'vivo X20全面屏手机',
 'text': '【武汉#首例重症新型肺炎出院者发声#：护士姐姐特别好，总给我加油】武汉首例重症新型肺炎出院患者李先生向梨视频详细讲述了被隔离治疗的经过。他说，姐姐冲进隔离室照顾他直到痊愈，“护士姐姐们特别好，总是给我加油打气。”其间，朋友和邻居都来看他。23岁的他，终于治愈出院。#国内确诊291例新型冠状病毒肺炎病例##武汉新型肺炎患者救治由政府买单#http://t.cn/A6vrC5ME',
 'user': '5150661033',
 'username': 'xzh谢紫寒',
 'weibo_url': 'https://weibo.com/5150661033/IqzheuBZe'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 29,
 'id_str': '3244555592_Iqzhc8BzM',
 'image_url': 'http://wx4.sinaimg.cn/wap180/c163fd48gy1gb4mh36rbgj20rs11rwfn.jpg',
 'reply_count': 2,
 'retweet_count': 5,
 'source': 'HUAWEI P20 Pro',
 'text': '#晚安遂宁#【支持请转！关于武汉新型肺炎，我们倡议！】同时，向所有前线医务人员致敬！请你们千万也要为自己做好防护！万众一心、众志成城，一定能够打赢这场疫情防控战！武汉加油！#国内确诊291例新型冠状病毒肺炎病例#（人民日报）',
 'user': '3244555592',
 'username': '遂宁发布',
 'weibo_url': 'https://weibo.com/3244555592/Iqzhc8BzM'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 3,
 'id_str': '1887741263_IqzhbwO2h',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone XS Max',
 'text': '#黄冈新增12例新型肺炎#武汉市长周先旺呼吁：外面的人不要到武汉，武汉市民没有特殊情况也不要出武汉。http://t.cn/A6vdQ9Fi',
 'user': '1887741263',
 'username': '番茄小火枪',
 'weibo_url': 'https://weibo.com/1887741263/IqzhbwO2h'}
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 1,
 'id_str': '6284481280_Iqzha5OMH',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '一月三号准备和爸妈一起去武汉的，后来因为有几例肺炎病例就没去了。现在想想这个选择太正确了，当时挑的民宿和海鲜市场就在一条街上。',
 'user': '6284481280',
 'username': '直布罗陀海峡-',
 'weibo_url': 'https://weibo.com/6284481280/Iqzha5OMH'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 1,
 'id_str': '2315385454_Iqzh9aPOO',
 'reply_count': 2,
 'retweet_count': 1,
 'source': '微博 weibo.com',
 'text': '#热爱大武汉##一条武汉医生的朋友圈#据通报，有15名医务人员确诊感染新型冠状病毒肺炎；对武汉的其他医护人员而言，他们正打着一场硬仗。一名医生写道，“接到通知（24h随叫随到）前就有了心理准备，内心比较平静，知道这是责任。”请千万为自己做好防护；3家定点医院设置床位800张用于收治病人',
 'user': '2315385454',
 'username': '土木蔡东锋',
 'weibo_url': 'https://weibo.com/2315385454/Iqzh9aPOO'}
2020-01-22 16:34:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15>
{'crawled_at': '2020-01-22 16:34:27',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '5887283037_Iqzh7FKL6',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '5887283037',
 'username': 'rlirli',
 'weibo_url': 'https://weibo.com/5887283037/Iqzh7FKL6'}
2020-01-22 16:34:28	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6384056512> (referer: https://weibo.cn/6384056512/info)
2020-01-22 16:34:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:28	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6384056512>
{'birthday': '2000-11-28',
 'brief_introduction': '知命不惧 日日自新',
 'city': '石家庄',
 'crawled_at': '2020-01-22 16:34:28',
 'fans_num': 196,
 'follows_num': 410,
 'gender': '女',
 'id': '6384056512',
 'name': '第三三三只眼',
 'province': '河北',
 'tweets_num': 3821,
 'vip_level': '2级'}
2020-01-22 16:34:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1544256452> (referer: https://weibo.cn/1544256452/info)
2020-01-22 16:34:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1544256452>
{'birthday': '1976-06-08',
 'brief_introduction': '行为经济学家，致力于行业国际化和大同世界！',
 'city': '广州',
 'crawled_at': '2020-01-22 16:34:29',
 'fans_num': 121095,
 'follows_num': 1395,
 'gender': '男',
 'id': '1544256452',
 'labels': '美食,新闻资讯',
 'name': '拥抱大同世界的潇雨老师',
 'province': '广东',
 'tweets_num': 2272,
 'vip_level': '5级'}
2020-01-22 16:34:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6772432602> (referer: https://weibo.cn/6772432602/info)
2020-01-22 16:34:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:30	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6772432602>
{'birthday': '1991-08-30',
 'brief_introduction': '转发好运与抽奖爱好者～请保佑我们都顺顺利利～希望老天保佑这个笨小孩～希望我们每一天都开开心心～ '
                       '好人一生平安。2020继续solo冲浪。',
 'crawled_at': '2020-01-22 16:34:30',
 'fans_num': 1,
 'follows_num': 370,
 'gender': '男',
 'id': '6772432602',
 'name': '静止运动兼熬夜达人',
 'province': '广东',
 'tweets_num': 2334,
 'vip_level': '未开通'}
2020-01-22 16:34:32	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1735020111> (referer: https://weibo.cn/1735020111/info)
2020-01-22 16:34:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:32	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1735020111>
{'authentication': '互联网资讯博主 微博签约自媒体',
 'birthday': '1991-10-17',
 'crawled_at': '2020-01-22 16:34:32',
 'fans_num': 94452,
 'follows_num': 1771,
 'gender': '男',
 'id': '1735020111',
 'labels': '梦想,爱旅行,奋斗',
 'name': '徽州李哥哥',
 'province': '安徽',
 'tweets_num': 8757,
 'vip_level': '6级'}
2020-01-22 16:34:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5526558498> (referer: https://weibo.cn/5526558498/info)
2020-01-22 16:34:33	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:33	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5526558498>
{'authentication': '问答答主',
 'birthday': '摩羯座',
 'brief_introduction': '朕的秀儿在哪？ 网易云：苏安',
 'crawled_at': '2020-01-22 16:34:33',
 'fans_num': 11243,
 'follows_num': 177,
 'gender': '男',
 'id': '5526558498',
 'name': '苏安哟',
 'province': '北京',
 'tweets_num': 111,
 'vip_level': '2级'}
2020-01-22 16:34:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6073802030> (referer: https://weibo.cn/6073802030/info)
2020-01-22 16:34:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6073802030>
{'authentication': '游戏博主 王者荣耀超话小主持人 游戏视频自媒体 游戏答主',
 'birthday': '白羊座',
 'brief_introduction': '江湖还是那个江湖 我再也不是那个传说',
 'city': '咸宁',
 'crawled_at': '2020-01-22 16:34:34',
 'fans_num': 1089255,
 'follows_num': 907,
 'gender': '男',
 'id': '6073802030',
 'name': '风期限在凌晨',
 'province': '湖北',
 'tweets_num': 2245,
 'vip_level': '7级'}
2020-01-22 16:34:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1681448593> (referer: https://weibo.cn/1681448593/info)
2020-01-22 16:34:36	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1681448593>
{'birthday': '1989-01-26',
 'brief_introduction': '小岛上の一只嘟……终极宅。。。',
 'crawled_at': '2020-01-22 16:34:36',
 'fans_num': 725,
 'follows_num': 233,
 'gender': '女',
 'id': '1681448593',
 'name': '小岛上De一只嘟',
 'province': '其他',
 'tweets_num': 32379,
 'vip_level': '未开通'}
2020-01-22 16:34:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5497006622> (referer: https://weibo.cn/5497006622/info)
2020-01-22 16:34:36	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5497006622>
{'birthday': '1995-10-17',
 'city': '广州',
 'crawled_at': '2020-01-22 16:34:36',
 'fans_num': 62,
 'follows_num': 69,
 'gender': '女',
 'id': '5497006622',
 'name': '不吃糖vbb',
 'province': '广东',
 'tweets_num': 40,
 'vip_level': '未开通'}
2020-01-22 16:34:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1642088277> (referer: https://weibo.cn/1642088277/info)
2020-01-22 16:34:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1642088277>
{'authentication': '财经网官方微博',
 'birthday': '2009-01-01',
 'brief_introduction': '商务合作： 廖先生 QQ ：3196598336 邮箱：kailiao@caijing.com.cn',
 'city': '朝阳区',
 'crawled_at': '2020-01-22 16:34:38',
 'fans_num': 35973402,
 'follows_num': 898,
 'gender': '男',
 'id': '1642088277',
 'labels': '财经网,融资,基金',
 'name': '财经网',
 'province': '北京',
 'tweets_num': 165909,
 'vip_level': '6级'}
2020-01-22 16:34:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2665683875> (referer: https://weibo.cn/2665683875/info)
2020-01-22 16:34:39	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2665683875>
{'brief_introduction': '极品憨憨🙈',
 'city': '杨浦区',
 'crawled_at': '2020-01-22 16:34:39',
 'fans_num': 117,
 'follows_num': 188,
 'gender': '女',
 'id': '2665683875',
 'name': '兔子不吃萝卜yy',
 'province': '上海',
 'tweets_num': 84,
 'vip_level': '1级'}
2020-01-22 16:34:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3235579924/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6297332728/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2622003940/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3244555592/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:44	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5150661033/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5340053863/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:47	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5887283037/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:47	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2315385454/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6284481280/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:50	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1887741263/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=15)
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '2244720992_Iqzh4bnTQ',
 'image_url': 'http://wx4.sinaimg.cn/wap180/53df2517ly1gb3wclue44j20qy16nn71.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqtngh5Yf?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀9 美得有声有色',
 'text': '#武汉15名医务人员感染新型冠状病毒#大家看看这次疫情的源头华南海鲜市场，图2是什么？行走的病毒库旱獭！所以说病从口入，放着好好的正常餐食不吃，非要吃什么野味，还动辄说什么饮食文化……2020年了，都长点心吧……',
 'user': '2244720992',
 'username': '呵呵这个昵称已经被占用',
 'weibo_url': 'https://weibo.com/2244720992/Iqzh4bnTQ'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 2,
 'id_str': '6561124564_Iqzh4bm5a',
 'reply_count': 1,
 'retweet_count': 3,
 'source': 'OPPO R9 Plus',
 'text': '#武汉新型肺炎全国疫情实时动态#『全国新型肺炎疫情实时动态-丁香园·丁香医生』http://t.cn/A6vdQqWg',
 'user': '6561124564',
 'username': '琴剑竹心',
 'weibo_url': 'https://weibo.com/6561124564/Iqzh4bm5a'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 3,
 'id_str': '1358804463_Iqzh2naNA',
 'image_url': 'http://wx1.sinaimg.cn/wap180/50fdb5efly1gb4mgd7dmyj20m80m848c.jpg',
 'reply_count': 0,
 'retweet_count': 1,
 'source': '佛系青年',
 'text': '#武汉新型肺炎患者救治均由政府买单##黄冈新增12例新型肺炎#有啥别有病，目前新型肺炎流行，又赶上春节假期，请客吃饭、出行旅游、聚会……人员密集场所安全隐患大，建议大家好好在家待着，看看电视，玩玩游戏，陪陪家人，挺好！九张图走进如何预防新型肺炎！',
 'user': '1358804463',
 'username': '东土大唐圣僧',
 'weibo_url': 'https://weibo.com/1358804463/Iqzh2naNA'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '2802615534_Iqzh26Fds',
 'image_url': 'http://wx3.sinaimg.cn/wap180/a70c84eely1gb4mh2qnozj20j60fjgmr.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '养生经济超话',
 'text': '#养生经济[超话]#【钟南山这张图疯传：17年前他领军战非典；这次，84岁的他再赴武汉】#养生经济#这位当年敢讲真话、敢涉险滩、敢啃硬骨的抗击“非典”英雄，再次站出来了。2020年1月21日,“武汉肺炎”又霸占了微博热搜！全国范围内，共确诊219例，多个地区出现病毒感染者。武汉、北京、上海、广州……更令人心惊的事实是：经过确认，这种新型冠状病毒，人与人之间会互相传染。当传染病遇上春运，灾难指数瞬间翻倍。几乎是一夜之间，口罩成为了被抢购的稀缺品。即使价格翻了两倍，也依然供不应求。很多人想起了曾经被“非典”支配的恐惧。即使是平时高喊着“很丧、不想活了”的年轻人们，也都纷纷取消了出行计划和观影计划，成为抢购口罩的主力军。所有人都在害怕。在恐慌情绪不断蔓延的时候，有个84岁的老人抵达了武汉。他的出现，使所有人都松了一口气。这位年迈的老人，是2003年抗击“非典”的第一功臣。他敢于直言，向世界披露了“非典”的真实情况；他研究的治疗方法，使中国人摆脱了死亡阴影。17年后，当病毒再次来袭，84岁的他重新披甲上阵。他是无双国士，更是定海神针。他，就是钟南山。',
 'user': '2802615534',
 'username': '养生经济',
 'weibo_url': 'https://weibo.com/2802615534/Iqzh26Fds'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 5,
 'id_str': '5949716310_Iqzh1tPFJ',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#黄冈新增12例新型肺炎#😭离武汉这么近家住黄冈的我就知道逃不过，希望所有人都平平安安，一定要做好预防啊啊啊啊啊，现在真的瑟瑟发抖了',
 'user': '5949716310',
 'username': '优秀热心网友',
 'weibo_url': 'https://weibo.com/5949716310/Iqzh1tPFJ'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 2,
 'id_str': '3586158887_Iqzh1ccCb',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '荣耀7X 全面屏手机',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#武汉挺住，武汉加油，致敬钟院士及全体一线医护人员，保护好自己',
 'user': '3586158887',
 'username': '阿伽想走路带风',
 'weibo_url': 'https://weibo.com/3586158887/Iqzh1ccCb'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '5586933121_Iqzh1djwo',
 'image_url': 'http://wx2.sinaimg.cn/wap180/00666cwxgy1gb4mh35cz2j30dc0acadg.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Android客户端',
 'text': '【国家卫生健康委确认成都市首例输入性新型冠状病毒感染的肺炎确诊病例】1月21日经国家卫健委疫情防控领导小组诊断专家组评估确认，成都市首例新型冠状病毒感染的肺炎疑似病例诊断为确诊病例，为武汉来蓉的输入病例。目前病人已隔离治疗，病情稳定，各项防控措施均已落实。@健康成都官微',
 'user': '5586933121',
 'username': '从宇宙黑洞飞出火凤凰',
 'weibo_url': 'https://weibo.com/5586933121/Iqzh1djwo'}
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '1797518042_Iqzh0Atbj',
 'image_url': 'http://wx4.sinaimg.cn/wap180/6b23f2daly1gb4md8mv8lj20u00n2di2.jpg',
 'reply_count': 1,
 'retweet_count': 2,
 'source': 'iPhone',
 'text': '趁着武汉肺炎事，现代医学在加紧分析、跟踪、研制，中医已经开始刷热度了。这北中医和南中医开的药方有区别的，这同一家医院的开出的药方也不一样。说明啥呢，中医无定论？咋弄都有理？',
 'user': '1797518042',
 'username': '北京韦少父家',
 'weibo_url': 'https://weibo.com/1797518042/Iqzh0Atbj'}
2020-01-22 16:34:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16>
{'crawled_at': '2020-01-22 16:34:53',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 9,
 'id_str': '5316741806_Iqzh048gP',
 'image_url': 'http://wx3.sinaimg.cn/wap180/005NOvq6ly1gb4mg6c3s1j30u01o0jvu.jpg',
 'place': '黄冈',
 'reply_count': 22,
 'retweet_count': 0,
 'source': '宫水三叶的Android',
 'text': '#黄冈新增12例新型肺炎#这病潜伏期多久，我就问问求个心安上上周刚从武汉回来',
 'user': '5316741806',
 'username': '吹灰不费艳与天齐',
 'weibo_url': 'https://weibo.com/5316741806/Iqzh048gP'}
2020-01-22 16:34:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3235579924> (referer: https://weibo.cn/3235579924/info)
2020-01-22 16:34:54	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:54	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3235579924>
{'brief_introduction': '日安',
 'crawled_at': '2020-01-22 16:34:54',
 'fans_num': 209,
 'follows_num': 981,
 'gender': '女',
 'id': '3235579924',
 'labels': '名人明星,微博奇葩,萌宠',
 'name': '极目送飞鸟',
 'province': '海外',
 'tweets_num': 247,
 'vip_level': '未开通'}
2020-01-22 16:34:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6297332728> (referer: https://weibo.cn/6297332728/info)
2020-01-22 16:34:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:55	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6297332728>
{'birthday': '2001-08-17',
 'brief_introduction': '呀哈',
 'crawled_at': '2020-01-22 16:34:55',
 'fans_num': 48,
 'follows_num': 96,
 'gender': '女',
 'id': '6297332728',
 'name': '爱吃烊喔',
 'province': '江苏',
 'tweets_num': 269,
 'vip_level': '未开通'}
2020-01-22 16:34:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2622003940> (referer: https://weibo.cn/2622003940/info)
2020-01-22 16:34:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2622003940>
{'birthday': '1991-02-11',
 'brief_introduction': '事情的终局强如事情的起头；存心忍耐的，胜过居心骄傲的。 (传道书7:8 和合本)',
 'city': '武汉',
 'crawled_at': '2020-01-22 16:34:57',
 'fans_num': 131,
 'follows_num': 11,
 'gender': '女',
 'id': '2622003940',
 'labels': '旅游',
 'name': '郭小zhuo加油',
 'province': '湖北',
 'tweets_num': 826,
 'vip_level': '未开通'}
2020-01-22 16:34:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3244555592> (referer: https://weibo.cn/3244555592/info)
2020-01-22 16:34:58	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:34:58	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3244555592>
{'authentication': '四川省遂宁市人民政府官方微博',
 'birthday': '0001-00-00',
 'brief_introduction': '遂宁，中国著名的观音文化之乡，位于四川盆地中部腹心，涪江中游。四川第二大交通枢纽城市。',
 'crawled_at': '2020-01-22 16:34:58',
 'fans_num': 408705,
 'follows_num': 469,
 'gender': '男',
 'id': '3244555592',
 'labels': '静静的遂宁,遂宁,遂宁市',
 'name': '遂宁发布',
 'province': '四川',
 'tweets_num': 23334,
 'vip_level': '未开通'}
2020-01-22 16:34:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5150661033> (referer: https://weibo.cn/5150661033/info)
2020-01-22 16:34:59	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5150661033>
{'birthday': '1999-01-21',
 'brief_introduction': '一个幸福的普通人',
 'city': '东城区',
 'crawled_at': '2020-01-22 16:34:59',
 'fans_num': 112,
 'follows_num': 591,
 'gender': '女',
 'id': '5150661033',
 'labels': '名人明星',
 'name': 'xzh谢紫寒',
 'province': '北京',
 'tweets_num': 75,
 'vip_level': '未开通'}
2020-01-22 16:35:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5340053863> (referer: https://weibo.cn/5340053863/info)
2020-01-22 16:35:01	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5340053863>
{'birthday': '1995-10-14',
 'brief_introduction': '（见头像）',
 'city': '济南',
 'crawled_at': '2020-01-22 16:35:01',
 'fans_num': 113,
 'follows_num': 125,
 'gender': '女',
 'id': '5340053863',
 'labels': '视频音乐',
 'name': '好吃的苦巧克力',
 'province': '山东',
 'tweets_num': 670,
 'vip_level': '1级'}
2020-01-22 16:35:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5887283037> (referer: https://weibo.cn/5887283037/info)
2020-01-22 16:35:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5887283037>
{'birthday': '2016-03-27',
 'brief_introduction': '道家做人 儒家做事 佛家修心   秉承童真 广结善缘',
 'crawled_at': '2020-01-22 16:35:02',
 'fans_num': 5634,
 'follows_num': 441,
 'gender': '男',
 'id': '5887283037',
 'labels': '武汉生活',
 'name': 'rlirli',
 'province': '其他',
 'sentiment': '已婚',
 'tweets_num': 120205,
 'vip_level': '3级'}
2020-01-22 16:35:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2315385454> (referer: https://weibo.cn/2315385454/info)
2020-01-22 16:35:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2315385454>
{'authentication': '知名教育博主',
 'birthday': '天秤座',
 'brief_introduction': '愿历尽千帆，归来仍少年；QQ2742996；vx-cdfengzd',
 'crawled_at': '2020-01-22 16:35:04',
 'fans_num': 500688,
 'follows_num': 6259,
 'gender': '男',
 'id': '2315385454',
 'labels': '华中科技大学,路桥,湖北',
 'name': '土木蔡东锋',
 'province': '湖北',
 'sex_orientation': '异性恋',
 'tweets_num': 5361,
 'vip_level': '7级'}
2020-01-22 16:35:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6284481280> (referer: https://weibo.cn/6284481280/info)
2020-01-22 16:35:05	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6284481280>
{'birthday': '2018-10-08',
 'brief_introduction': '可能需要半段感情',
 'city': '广州',
 'crawled_at': '2020-01-22 16:35:05',
 'fans_num': 151,
 'follows_num': 480,
 'gender': '女',
 'id': '6284481280',
 'name': '直布罗陀海峡-',
 'province': '广东',
 'tweets_num': 2242,
 'vip_level': '2级'}
2020-01-22 16:35:05	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1887741263> (referer: https://weibo.cn/1887741263/info)
2020-01-22 16:35:05	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1887741263>
{'authentication': '财经博主',
 'brief_introduction': '比特币早期投资者。区块链才是未来！',
 'crawled_at': '2020-01-22 16:35:05',
 'fans_num': 35090,
 'follows_num': 728,
 'gender': '男',
 'id': '1887741263',
 'labels': '区块链,比特币,证券',
 'name': '番茄小火枪',
 'province': '北京',
 'tweets_num': 11013,
 'vip_level': '6级'}
2020-01-22 16:35:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/3586158887/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5949716310/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:08	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:09	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2802615534/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1358804463/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:12	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6561124564/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:12	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2244720992/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:14	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5316741806/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:14	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1797518042/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5586933121/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=16)
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 7,
 'id_str': '5254912337_IqzgZsoZa',
 'image_url': 'http://wx3.sinaimg.cn/wap180/005JD4KBly1gb4mgyx23oj30u017lqav.jpg',
 'place': '许昌·健发御园',
 'reply_count': 5,
 'retweet_count': 0,
 'source': 'OPPO Reno 10倍变焦版',
 'text': '#武汉新型肺炎患者救治由政府买单#科学家院士才应该是给予高薪的人他们才是有功的人！而不是什么明星#河南娱乐资讯#',
 'user': '5254912337',
 'username': '八组兔区会火',
 'weibo_url': 'https://weibo.com/5254912337/IqzgZsoZa'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '2427316301_IqzgZpsDy',
 'origin_weibo': 'https://weibo.cn/comment/Iqz6Qjftm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '千纸鹤花开Android',
 'text': '#胡侃#武汉市今早宣布的15名被感染的医务人员中，有14人是被同一名患者感染的。星期二晚上湖北黄冈宣布新增12个确诊病例，其中5例是医生和护士。今天湖北的医生护士们都是英勇的战士，而武汉已经成了抗击新型冠状病毒的最前线。打赢“武汉保卫战”才会有全国的胜利。胡锡进的微博视频',
 'user': '2427316301',
 'username': 'goodluck琳琳',
 'weibo_url': 'https://weibo.com/2427316301/IqzgZpsDy'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '5966686758_IqzgZaLEK',
 'origin_weibo': 'https://weibo.cn/comment/Iqxz47NfX?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Weibo.intl',
 'text': '来看看武汉市中心医院（原二医院）是怎么做隔离的呢躺在床上的都是患者，家属说今天光是她看到听到已经离世了的就有2个了，怎么现在通报还不更新死亡例数呢？真的不多说大家都懂吧，我托朋友要到了报社的电话号码，打了电话有什么用呢，已经有消息说了各大报社不准播这些信息。http://t.cn/A6vrlUdW',
 'user': '5966686758',
 'username': '来吃大西瓜v',
 'weibo_url': 'https://weibo.com/5966686758/IqzgZaLEK'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 11,
 'id_str': '6900094636_IqzgZ8ZvC',
 'reply_count': 3,
 'retweet_count': 2,
 'source': 'iPhone 6s',
 'text': '#武汉新型肺炎患者救治由政府买单#这是一个美国小女孩与一个中国小女孩不同的人生目标，看完让人心痛！我相信这绝不是个例。http://t.cn/AiFf1uoz',
 'user': '6900094636',
 'username': '华贵紫英',
 'weibo_url': 'https://weibo.com/6900094636/IqzgZ8ZvC'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:56',
 'favorite_count': 0,
 'id_str': '1725542714_IqzgXFi1H',
 'image_url': 'http://wx2.sinaimg.cn/wap180/7a904c3dly1gb3mk5tcs6j20yh16ugwi.jpg',
 'origin_weibo': 'https://weibo.cn/comment/Iqr9ghulm?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Share微博客户端',
 'text': '哔哩哔哩真被中国福彩发函了？@哔哩哔哩弹幕网',
 'user': '1725542714',
 'username': '从丽而终',
 'weibo_url': 'https://weibo.com/1725542714/IqzgXFi1H'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 0,
 'id_str': '6112244597_IqzgVhVZd',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'Nokia X6 越级体验',
 'text': '『一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话』一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话',
 'user': '6112244597',
 'username': '忆然XYY',
 'weibo_url': 'https://weibo.com/6112244597/IqzgVhVZd'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 6,
 'id_str': '5958373189_IqzgVgMXF',
 'reply_count': 1,
 'retweet_count': 1,
 'text': '已经出院的患者采访：一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话',
 'user': '5958373189',
 'username': 'Orange指南',
 'weibo_url': 'https://weibo.com/5958373189/IqzgVgMXF'}
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 1,
 'id_str': '6043418644_IqzgUoBEZ',
 'reply_count': 1,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#赶上春运，赶上春节，有点紧张，邻居3个在武汉服务行业，过年回家咋面对',
 'user': '6043418644',
 'username': 'MD_lu8023',
 'weibo_url': 'https://weibo.com/6043418644/IqzgUoBEZ'}
2020-01-22 16:35:18	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17>
{'crawled_at': '2020-01-22 16:35:18',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 1,
 'id_str': '6581584158_IqzgU8dn1',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'vivo X23全息幻彩',
 'text': '#武汉新型肺炎患者救治由政府买单#大家都会好好的[加油]🙏🙏🙏',
 'user': '6581584158',
 'username': 'HMH·这里只有他',
 'weibo_url': 'https://weibo.com/6581584158/IqzgU8dn1'}
2020-01-22 16:35:18	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:19	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/3586158887> (referer: https://weibo.cn/3586158887/info)
2020-01-22 16:35:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/3586158887>
{'birthday': '摩羯座',
 'brief_introduction': '独立有灵气',
 'city': '太原',
 'crawled_at': '2020-01-22 16:35:20',
 'fans_num': 266,
 'follows_num': 290,
 'gender': '女',
 'id': '3586158887',
 'labels': 'Music,随性,爱旅游',
 'name': '阿伽想走路带风',
 'province': '山西',
 'tweets_num': 254,
 'vip_level': '1级'}
2020-01-22 16:35:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5949716310> (referer: https://weibo.cn/5949716310/info)
2020-01-22 16:35:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5949716310>
{'birthday': '天蝎座',
 'brief_introduction': '头可断，血可流，老子可遇不可求| ᐕ)୨',
 'crawled_at': '2020-01-22 16:35:20',
 'fans_num': 813,
 'follows_num': 268,
 'gender': '女',
 'id': '5949716310',
 'name': '优秀热心网友',
 'province': '重庆',
 'tweets_num': 244,
 'vip_level': '未开通'}
2020-01-22 16:35:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2802615534> (referer: https://weibo.cn/2802615534/info)
2020-01-22 16:35:21	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:21	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2802615534>
{'authentication': '养生经济超话主持人 互联网资讯博主 头条文章作者',
 'birthday': '1978-07-14',
 'brief_introduction': '养生与经济',
 'city': '东城区',
 'crawled_at': '2020-01-22 16:35:21',
 'fans_num': 356664,
 'follows_num': 3187,
 'gender': '男',
 'id': '2802615534',
 'labels': '健康',
 'name': '养生经济',
 'province': '北京',
 'tweets_num': 21509,
 'vip_level': '6级'}
2020-01-22 16:35:22	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1358804463> (referer: https://weibo.cn/1358804463/info)
2020-01-22 16:35:22	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1358804463>
{'authentication': '知名职场博主 新鲜事作者 微博故事原创作者 职场超话小主持人 搞笑视频自媒体',
 'birthday': '1900-01-01',
 'brief_introduction': '贫僧从东土大唐而来，前往西天拜佛求经',
 'city': '秦皇岛',
 'crawled_at': '2020-01-22 16:35:22',
 'fans_num': 434987,
 'follows_num': 805,
 'gender': '男',
 'id': '1358804463',
 'labels': '网络,教育就业,情感',
 'name': '东土大唐圣僧',
 'province': '河北',
 'sex_orientation': '异性恋',
 'tweets_num': 15707,
 'vip_level': '6级'}
2020-01-22 16:35:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6561124564> (referer: https://weibo.cn/6561124564/info)
2020-01-22 16:35:24	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6561124564>
{'birthday': '双子座',
 'brief_introduction': '华夏汉文化传承者',
 'crawled_at': '2020-01-22 16:35:24',
 'fans_num': 729,
 'follows_num': 1265,
 'gender': '男',
 'id': '6561124564',
 'name': '琴剑竹心',
 'province': '广东',
 'tweets_num': 2443,
 'vip_level': '未开通'}
2020-01-22 16:35:24	scrapy.extensions.logstats	INFO	Crawled 314 pages (at 49 pages/min), scraped 309 items (at 53 items/min)
2020-01-22 16:35:25	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2244720992> (referer: https://weibo.cn/2244720992/info)
2020-01-22 16:35:25	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2244720992>
{'brief_introduction': '嘿嘿嘿嘿⊙▽⊙',
 'city': '成都',
 'crawled_at': '2020-01-22 16:35:25',
 'fans_num': 285,
 'follows_num': 725,
 'gender': '男',
 'id': '2244720992',
 'labels': '美食',
 'name': '呵呵这个昵称已经被占用',
 'province': '四川',
 'tweets_num': 4387,
 'vip_level': '未开通'}
2020-01-22 16:35:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5316741806> (referer: https://weibo.cn/5316741806/info)
2020-01-22 16:35:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5316741806>
{'birthday': '2000-02-10',
 'brief_introduction': '愿以寸心寄华夏，且将岁月赠山河。',
 'crawled_at': '2020-01-22 16:35:26',
 'fans_num': 255,
 'follows_num': 230,
 'gender': '女',
 'id': '5316741806',
 'labels': '大学,驴友,学生一枚',
 'name': '吹灰不费艳与天齐',
 'province': '湖北',
 'tweets_num': 693,
 'vip_level': '4级'}
2020-01-22 16:35:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1797518042> (referer: https://weibo.cn/1797518042/info)
2020-01-22 16:35:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1797518042>
{'birthday': '1987-10-17',
 'city': '朝阳区',
 'crawled_at': '2020-01-22 16:35:27',
 'fans_num': 1198,
 'follows_num': 2051,
 'gender': '男',
 'id': '1797518042',
 'name': '北京韦少父家',
 'province': '北京',
 'tweets_num': 6868,
 'vip_level': '1级'}
2020-01-22 16:35:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/5586933121> (referer: https://weibo.cn/5586933121/info)
2020-01-22 16:35:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/5586933121>
{'city': '成都',
 'crawled_at': '2020-01-22 16:35:29',
 'fans_num': 13483,
 'follows_num': 270,
 'gender': '男',
 'id': '5586933121',
 'name': '从宇宙黑洞飞出火凤凰',
 'province': '四川',
 'tweets_num': 167034,
 'vip_level': '未开通'}
2020-01-22 16:35:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6112244597/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/1725542714/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6900094636/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:33	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5966686758/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2427316301/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:35:35	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:35:35	scrapy.core.engine	INFO	Closing spider (shutdown)
2020-01-22 16:35:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5254912337/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6581584158/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/6043418644/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/5958373189/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:41	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=17)
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 3,
 'id_str': '3126738955_IqzgTvbZG',
 'image_url': 'http://wx4.sinaimg.cn/wap180/ba5e400bgy1gb4mg20e74j20b408bt9t.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '武汉肺炎冠状病毒事件比较会将一些人钉在历史的耻辱柱上！如果不是请出了钟南山院士，这个盖子还要捂到什么时候！民众的安全大？还是官帽子大？是病毒疫情重要还是政治前途重要？捂盖子的人耽误了最佳的控制疫情的时机，必将成为中华民族的罪人！',
 'user': '3126738955',
 'username': '唐门浪子',
 'weibo_url': 'https://weibo.com/3126738955/IqzgTvbZG'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 1,
 'id_str': '5772585983_IqzgSmBC9',
 'image_url': 'http://wx3.sinaimg.cn/wap180/006iFbjxgy1gb4m7lk0tbj30iu0ivdog.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '微博 weibo.com',
 'text': '1月21日，武汉官方就新型冠状病毒感染的肺炎防控表示，武汉天河机场、火车站等地1月14日开始安装红外线测温仪，加强旅客体温检测工作。需要指出的，早在1月5日，泰国副总理兼卫生部长阿努廷前往曼谷素万那普机场视察机场疫情防控情况，当时曼谷机场就已经加装了4台红外线测温仪，泰国其他主要机场也是一样',
 'user': '5772585983',
 'username': '航空圈365',
 'weibo_url': 'https://weibo.com/5772585983/IqzgSmBC9'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 6,
 'id_str': '5852418896_IqzgQxuKa',
 'reply_count': 4,
 'retweet_count': 2,
 'source': '要饭买的iPhone 11',
 'text': '病源都是武汉引起的！建议武汉人别出来了！大家都想好好过年#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '5852418896',
 'username': '郭德纲喷水',
 'weibo_url': 'https://weibo.com/5852418896/IqzgQxuKa'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 0,
 'id_str': '3991868897_IqzgPnCXs',
 'origin_weibo': 'https://weibo.cn/comment/IqykRlt8w?rl=1#cmtfrm',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 30',
 'text': '【抗击病毒肺炎一线，#武汉市民为一线医生送水果#】21日下午，武昌沙湖果批市场内的店主黄毅为战斗在抗击病毒肺炎一线的医生们，免费送去了几箱维生素C含量高的水果和一封“致敬信”，以表达武汉市民对辛苦在一线的医护工作者的敬意！长江日报的微博视频',
 'user': '3991868897',
 'username': '梦醒小半strawberry',
 'weibo_url': 'https://weibo.com/3991868897/IqzgPnCXs'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 9,
 'id_str': '7187312474_IqzgP7bPV',
 'reply_count': 11,
 'retweet_count': 0,
 'text': '如果有一天你心爱的城市在别人口中成了瘟疫的代名词你会怎么样？听网友的话本武汉人呆在家里大门不出二门不迈也不想给其他城市带去所谓人祸那些地域黑的人考虑过武汉人的感受吗你们隔千里都那么恐慌我们难道还真像有人评论的事不关己？相信国家如果真有必要封城必然没意见我也希望所有人平安地域黑真的放过武汉吧谁想感染了？希望在一线的医护人员平安天佑武汉🙏🙏🙏#国内确诊291例新型冠状病毒肺炎病例#',
 'user': '7187312474',
 'username': '汤不圆o',
 'weibo_url': 'https://weibo.com/7187312474/IqzgP7bPV'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 2,
 'id_str': '5522461484_IqzgNAUOG',
 'image_url': 'http://wx3.sinaimg.cn/wap180/0061JGvqly1gb4mgg5hjnj30ol1nrk3a.jpg',
 'reply_count': 0,
 'retweet_count': 0,
 'source': '北京超话',
 'text': '【#北京新增5例新型肺炎#病例：均曾到过武汉】据北京市卫健委消息：今天，5名患者确诊为新型冠状病毒感染的肺炎病例。5名患者病情平稳，在定点医院接受隔离治疗。现已对21名密切接触者开展医学观察，目前无发热等异常情况。截至21日18时，#北京确诊10例新型肺炎#病例，其中西城区1例、海淀区2例、丰台区1例、通州区1例、大兴区2例、昌平区2例，武汉来京人员1例。',
 'user': '5522461484',
 'username': '北京生活导航',
 'weibo_url': 'https://weibo.com/5522461484/IqzgNAUOG'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 25868,
 'id_str': '2656274875_IqzgM8eoK',
 'image_url': 'http://wx2.sinaimg.cn/wap180/9e5389bbly1gb4mg93uwij20go0gogvn.jpg',
 'reply_count': 2639,
 'retweet_count': 1405,
 'source': '微博 weibo.com',
 'text': '【云南#昆明确诊首例新型肺炎#病例】今天，国家卫健委确认昆明市首例输入性新型冠状病毒感染的肺炎确诊病例。患者为51岁男性，湖北省武汉市户籍。15日自武汉来昆。因发热、乏力等症状，16日到云南省第三人民医院就诊，17日转诊到云南省传染病医院隔离治疗。今天，经国家卫生健康委疫情应对处置领导小组的专家评估确认，该病例为新型冠状病毒感染的肺炎确诊病例。经医院治疗，患者病情稳定好转。与患者密切接触者均追踪到位，经医学观察未见异常。（央视记者王溪）',
 'user': '2656274875',
 'username': '央视新闻',
 'weibo_url': 'https://weibo.com/2656274875/IqzgM8eoK'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 1,
 'id_str': '1967140992_IqzgJdjGM',
 'image_url': 'http://wx3.sinaimg.cn/wap180/b10c1bc2ly1gb37ffxhmtg206o06o0v0.gif',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '今年过年那都不能去，第一是我刚生完老二在家做月子，第二就是武汉现在全世界都知道，肺炎流感有事没事不要来武汉请出门的人带口罩😷回家勤洗手，有消毒的都用上而且有孩子更加注意',
 'user': '1967140992',
 'username': 'Yomi_酱',
 'weibo_url': 'https://weibo.com/1967140992/IqzgJdjGM'}
2020-01-22 16:35:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89+%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time&page=18>
{'crawled_at': '2020-01-22 16:35:41',
 'created_at': '2020-01-21 23:55',
 'favorite_count': 0,
 'id_str': '2047092063_IqzgJayNL',
 'reply_count': 0,
 'retweet_count': 0,
 'source': 'HUAWEI Mate 9',
 'text': '『一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话』一个武汉肺炎康复患者的样本观察：我与新型冠状病毒搏斗的22天|深度对话',
 'user': '2047092063',
 'username': '悠悠啊悠',
 'weibo_url': 'https://weibo.com/2047092063/IqzgJayNL'}
2020-01-22 16:35:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6112244597> (referer: https://weibo.cn/6112244597/info)
2020-01-22 16:35:42	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6112244597>
{'brief_introduction': '愿琴瑟在御 岁月静好',
 'crawled_at': '2020-01-22 16:35:42',
 'fans_num': 79,
 'follows_num': 610,
 'gender': '女',
 'id': '6112244597',
 'name': '忆然XYY',
 'province': '河南',
 'tweets_num': 642,
 'vip_level': '1级'}
2020-01-22 16:35:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/1725542714> (referer: https://weibo.cn/1725542714/info)
2020-01-22 16:35:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/6900094636> (referer: https://weibo.cn/6900094636/info)
2020-01-22 16:35:44	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/1725542714>
{'birthday': '1993-08-07',
 'brief_introduction': '天意已成全！',
 'city': '盐城',
 'crawled_at': '2020-01-22 16:35:44',
 'fans_num': 36,
 'follows_num': 148,
 'gender': '男',
 'id': '1725542714',
 'labels': 'IT数码,游戏动漫',
 'name': '从丽而终',
 'province': '江苏',
 'tweets_num': 380,
 'vip_level': '未开通'}
2020-01-22 16:35:44	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/6900094636>
{'authentication': '鹏讯传媒 短视频制作人 视频博主',
 'birthday': '2000-08-26',
 'brief_introduction': '嘻嘻哈哈过一天！',
 'city': '资阳',
 'crawled_at': '2020-01-22 16:35:44',
 'fans_num': 25440,
 'follows_num': 880,
 'gender': '女',
 'id': '6900094636',
 'labels': '我们的侣行,鹏讯传媒,爱情保卫战',
 'name': '华贵紫英',
 'province': '四川',
 'sentiment': '单身',
 'sex_orientation': '异性恋',
 'tweets_num': 1398,
 'vip_level': '3级'}
2020-01-22 16:36:32	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:36:32	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:36:32	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:36:32	scrapy.extensions.telnet	INFO	Telnet Password: e9663ec9226bfe9c
2020-01-22 16:36:32	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:36:32	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:36:32	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:36:32	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:36:32	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:36:32	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:36:32	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:36:32	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:36:34	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:36:34	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:36:34',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:36:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:36:34	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:36:35	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 16:37:38	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 16:37:51	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 16:37:51	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 16:37:51	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 16:37:51	scrapy.extensions.telnet	INFO	Telnet Password: c54f3197282c269e
2020-01-22 16:37:51	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 16:37:51	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 16:37:51	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 16:37:51	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 16:37:51	scrapy.core.engine	INFO	Spider opened
2020-01-22 16:37:51	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 16:37:51	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 16:37:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:37:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 16:37:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 16:37:53',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 16:37:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:37:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 16:37:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:09:59	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:11:18	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:11:18	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:11:18	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:11:18	scrapy.extensions.telnet	INFO	Telnet Password: 2a0e9457c510c9f3
2020-01-22 17:11:18	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:11:19	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:11:19	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:11:19	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:11:19	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:11:19	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:11:19	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:11:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:11:20	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:11:20',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:11:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:20	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:21	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:11:27	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 171, in parse_all_content
    text = text.xpath('string(.)').extract()
AttributeError: 'str' object has no attribute 'xpath'
2020-01-22 17:11:30	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:11:55	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:11:55	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:11:55	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:11:55	scrapy.extensions.telnet	INFO	Telnet Password: 8b96a33ed7d7089d
2020-01-22 17:11:55	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:11:56	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:11:56	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:11:56	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:11:56	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:11:56	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:11:56	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:11:56	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:57	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:11:57	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:11:57',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:11:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:57	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:11:58	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:13:03	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:13:14	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:13:14	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:13:14	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:13:14	scrapy.extensions.telnet	INFO	Telnet Password: 59419b88695b6c1b
2020-01-22 17:13:14	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:13:15	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:13:15	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:13:15	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:13:15	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:13:15	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:13:15	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:13:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:13:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:13:16	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:13:16',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:13:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:13:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:13:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:13:45	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    response.text = re.sub(r"(<img alt=[\'|\"]\[)(.*?)(\][\'|\"].*?>)", ":\\2:", response.text, 0, re.IGNORECASE | re.MULTILINE)
AttributeError: can't set attribute
2020-01-22 17:13:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:13:49	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:13:51	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2541074492> (referer: https://weibo.cn/2541074492/info)
2020-01-22 17:13:51	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2541074492>
{'birthday': '1990-02-12',
 'brief_introduction': '愿你所有的泪水皆因喜极而泣',
 'city': '长沙',
 'crawled_at': '2020-01-22 17:13:51',
 'fans_num': 1058,
 'follows_num': 1458,
 'gender': '女',
 'id': '2541074492',
 'name': '罗小清清清',
 'province': '湖南',
 'tweets_num': 2029,
 'vip_level': '4级'}
2020-01-22 17:13:51	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 17:13:51	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 2695,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18043,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 36.233028,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 8, 13, 51, 292617),
 'item_scraped_count': 2,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 108838912,
 'memusage/startup': 108838912,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 1, 22, 8, 13, 15, 59589)}
2020-01-22 17:13:51	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 17:15:15	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:15:15	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:15:15	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:15:15	scrapy.extensions.telnet	INFO	Telnet Password: a692e7f0b8e24579
2020-01-22 17:15:15	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:15:16	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:15:16	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:15:16	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:15:16	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:15:16	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:15:16	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:15:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:15:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:15:17	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:15:17',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:15:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:15:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:15:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:15:46	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:19:06	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:19:06	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:19:06	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:19:06	scrapy.extensions.telnet	INFO	Telnet Password: 10e8bb93015225c7
2020-01-22 17:19:06	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:19:06	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:19:06	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:19:06	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:19:06	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:19:06	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:19:06	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:19:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:19:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:19:07	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:19:07',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:19:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:19:07	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:19:08	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:32:16	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:37:24	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:37:24	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:37:24	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:37:24	scrapy.extensions.telnet	INFO	Telnet Password: 35c9a29dcfb19752
2020-01-22 17:37:24	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:37:25	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:37:25	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:37:25	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:37:25	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:37:25	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:37:25	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:37:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:37:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:37:26	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:37:26',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:37:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:37:26	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:37:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:37:51	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:39:03	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:39:03	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:39:03	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:39:03	scrapy.extensions.telnet	INFO	Telnet Password: f889de00f674a1d2
2020-01-22 17:39:03	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:39:03	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:39:03	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:39:03	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:39:03	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:39:03	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:39:03	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:39:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:39:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:39:04',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:39:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:39:28	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:39:41	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:39:41	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:39:41	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:39:41	scrapy.extensions.telnet	INFO	Telnet Password: ee0608ae11f36ad1
2020-01-22 17:39:41	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:39:42	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:39:42	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:39:42	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:39:42	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:39:42	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:39:42	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:39:42	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:43	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:39:43	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:39:43',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:39:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:43	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:39:44	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:40:20	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 169, in parse_all_content
    test = re.sub(r"(<img alt=[\'|\"]\[)(.*?)(\][\'|\"].*?>)", ":\\2:", test, 0, re.IGNORECASE | re.MULTILINE)
  File "/Users/gao/opt/anaconda3/lib/python3.7/re.py", line 192, in sub
    return _compile(pattern, flags).sub(repl, string, count)
TypeError: expected string or bytes-like object
2020-01-22 17:40:21	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:44:05	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:44:05	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:44:05	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:44:05	scrapy.extensions.telnet	INFO	Telnet Password: a5e18f53bd9d7bda
2020-01-22 17:44:05	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:44:05	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:44:05	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:44:05	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:44:05	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:44:05	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:44:05	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:44:05	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:44:06	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:44:06	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:44:06',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:44:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:44:06	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:44:07	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:44:12	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(.//)')
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(.//)
2020-01-22 17:44:16	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:48:28	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:48:28	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:48:28	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:48:28	scrapy.extensions.telnet	INFO	Telnet Password: e4442550de58f387
2020-01-22 17:48:28	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:48:28	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:48:28	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:48:28	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:48:28	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:48:28	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:48:28	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:48:28	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:48:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:48:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:48:29',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:48:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:48:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:48:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:48:41	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:49:39	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:49:39	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:49:39	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:49:39	scrapy.extensions.telnet	INFO	Telnet Password: f90e4631c3d36a91
2020-01-22 17:49:39	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:49:40	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:49:40	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:49:40	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:49:40	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:49:40	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:49:40	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:49:40	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:49:40	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:49:41	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:49:41',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:49:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:49:41	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:49:42	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:49:44	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(./[name(..)!="img"]])').extract()
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(./[name(..)!="img"]])
2020-01-22 17:49:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:49:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:49:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2541074492> (referer: https://weibo.cn/2541074492/info)
2020-01-22 17:49:47	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2541074492>
{'birthday': '1990-02-12',
 'brief_introduction': '愿你所有的泪水皆因喜极而泣',
 'city': '长沙',
 'crawled_at': '2020-01-22 17:49:47',
 'fans_num': 1058,
 'follows_num': 1458,
 'gender': '女',
 'id': '2541074492',
 'name': '罗小清清清',
 'province': '湖南',
 'tweets_num': 2029,
 'vip_level': '4级'}
2020-01-22 17:49:47	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 17:49:47	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 2695,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18176,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.392713,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 8, 49, 47, 603187),
 'item_scraped_count': 2,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 108859392,
 'memusage/startup': 108855296,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 1, 22, 8, 49, 40, 210474)}
2020-01-22 17:49:47	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 17:51:21	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:51:21	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:51:21	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:51:21	scrapy.extensions.telnet	INFO	Telnet Password: 95461182c83533f7
2020-01-22 17:51:21	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:51:22	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:51:22	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:51:22	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:51:22	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:51:22	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:51:22	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:51:22	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:23	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:51:23	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:51:23',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:51:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:23	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:24	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:51:27	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(.img').extract()
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(.img
2020-01-22 17:51:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:51:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2541074492> (referer: https://weibo.cn/2541074492/info)
2020-01-22 17:51:31	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2541074492>
{'birthday': '1990-02-12',
 'brief_introduction': '愿你所有的泪水皆因喜极而泣',
 'city': '长沙',
 'crawled_at': '2020-01-22 17:51:31',
 'fans_num': 1058,
 'follows_num': 1458,
 'gender': '女',
 'id': '2541074492',
 'name': '罗小清清清',
 'province': '湖南',
 'tweets_num': 2029,
 'vip_level': '4级'}
2020-01-22 17:51:31	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 17:51:31	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 2695,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18134,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 9.146527,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 8, 51, 31, 265373),
 'item_scraped_count': 2,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 108830720,
 'memusage/startup': 108830720,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 1, 22, 8, 51, 22, 118846)}
2020-01-22 17:51:31	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 17:51:43	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:51:43	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:51:43	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:51:43	scrapy.extensions.telnet	INFO	Telnet Password: 810c1b48d5bb5d22
2020-01-22 17:51:43	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:51:44	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:51:44	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:51:44	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:51:44	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:51:44	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:51:44	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:51:44	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:45	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:51:45	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:51:45',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:51:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:51:48	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(.img)').extract()
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(.img)
2020-01-22 17:51:50	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:51:50	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:51:52	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2541074492> (referer: https://weibo.cn/2541074492/info)
2020-01-22 17:51:52	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2541074492>
{'birthday': '1990-02-12',
 'brief_introduction': '愿你所有的泪水皆因喜极而泣',
 'city': '长沙',
 'crawled_at': '2020-01-22 17:51:52',
 'fans_num': 1058,
 'follows_num': 1458,
 'gender': '女',
 'id': '2541074492',
 'name': '罗小清清清',
 'province': '湖南',
 'tweets_num': 2029,
 'vip_level': '4级'}
2020-01-22 17:51:52	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 17:51:52	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 2695,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18070,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.643282,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 8, 51, 52, 232339),
 'item_scraped_count': 2,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 108879872,
 'memusage/startup': 108879872,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 1, 22, 8, 51, 44, 589057)}
2020-01-22 17:51:52	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 17:52:51	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:52:51	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:52:51	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:52:51	scrapy.extensions.telnet	INFO	Telnet Password: ff0bf49f0dc76311
2020-01-22 17:52:51	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:52:52	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:52:52	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:52:52	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:52:52	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:52:52	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:52:52	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:52:52	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:52:53	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:52:53	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:52:53',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:52:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:52:53	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:52:54	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:52:56	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(./[not(name="img")])').extract()
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(./[not(name="img")])
2020-01-22 17:52:59	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/info> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:53:00	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:01	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/u/2541074492> (referer: https://weibo.cn/2541074492/info)
2020-01-22 17:53:01	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/u/2541074492>
{'birthday': '1990-02-12',
 'brief_introduction': '愿你所有的泪水皆因喜极而泣',
 'city': '长沙',
 'crawled_at': '2020-01-22 17:53:01',
 'fans_num': 1058,
 'follows_num': 1458,
 'gender': '女',
 'id': '2541074492',
 'name': '罗小清清清',
 'province': '湖南',
 'tweets_num': 2029,
 'vip_level': '4级'}
2020-01-22 17:53:01	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 17:53:01	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 2695,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18094,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 9.498055,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 8, 53, 1, 863160),
 'item_scraped_count': 2,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 108855296,
 'memusage/startup': 108855296,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 1, 22, 8, 52, 52, 365105)}
2020-01-22 17:53:01	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 17:53:12	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:53:12	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:53:12	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:53:12	scrapy.extensions.telnet	INFO	Telnet Password: 9293c93ca965f24d
2020-01-22 17:53:12	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:53:12	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:53:12	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:53:12	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:53:12	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:53:12	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:53:12	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:53:12	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:13	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:53:13	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:53:13',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:53:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:13	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:15	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:53:35	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:53:54	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:53:54	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:53:54	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:53:54	scrapy.extensions.telnet	INFO	Telnet Password: 0551734f70cae47e
2020-01-22 17:53:54	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:53:54	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:53:54	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:53:54	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:53:54	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:53:54	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:53:54	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:53:54	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:55	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:53:55	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:53:55',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:53:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:55	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:53:56	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:54:04	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:54:47	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:54:47	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:54:47	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:54:47	scrapy.extensions.telnet	INFO	Telnet Password: 30c8bbca37c9168e
2020-01-22 17:54:47	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:54:47	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:54:47	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:54:48	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:54:48	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:54:48	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:54:48	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:54:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:54:48	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:54:48	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:54:48',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:54:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:54:48	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:54:49	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:54:55	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:55:09	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:55:09	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:55:09	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:55:09	scrapy.extensions.telnet	INFO	Telnet Password: e3dcefc9b8522ea2
2020-01-22 17:55:09	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:55:09	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:55:09	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:55:09	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:55:09	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:55:09	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:55:09	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:55:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:55:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:55:10	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:55:10',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:55:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:55:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:55:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:55:13	scrapy.core.scraper	ERROR	Spider error processing <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/gao/PycharmProjects/WeiboCrawler/WeiboSearch/spiders/weibo_spider.py", line 168, in parse_all_content
    test = response.xpath('//*[@id="M_"]/div[1]').xpath('string(.//)').extract()
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/six.py", line 695, in reraise
    raise value.with_traceback(tb)
  File "/Users/gao/opt/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1583, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in string(.//)
2020-01-22 17:55:15	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:56:08	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:56:08	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:56:08	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:56:08	scrapy.extensions.telnet	INFO	Telnet Password: 423412b006ad022b
2020-01-22 17:56:08	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:56:09	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:56:09	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:56:09	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:56:09	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:56:09	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:56:09	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:56:09	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:56:10	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:56:10	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:56:10',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:56:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:56:10	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:56:11	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:56:47	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:57:29	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:57:29	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:57:29	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:57:29	scrapy.extensions.telnet	INFO	Telnet Password: 88088c2674b7a1d2
2020-01-22 17:57:29	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:57:30	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:57:30	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:57:30	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:57:30	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:57:30	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:57:30	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:57:30	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:57:30	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:57:30	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:57:30',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:57:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:57:31	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:57:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:57:47	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 17:58:00	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 17:58:00	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 17:58:00	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 17:58:00	scrapy.extensions.telnet	INFO	Telnet Password: eb2c7c68ba67e2d2
2020-01-22 17:58:01	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 17:58:01	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 17:58:01	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 17:58:01	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 17:58:01	scrapy.core.engine	INFO	Spider opened
2020-01-22 17:58:01	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 17:58:01	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 17:58:01	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:58:02	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 17:58:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:58:02	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 17:58:02',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 17:58:02	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 17:58:03	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 17:58:21	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:00:36	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:00:36	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:00:36	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:00:36	scrapy.extensions.telnet	INFO	Telnet Password: 3a4e7594d9fb130a
2020-01-22 18:00:36	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:00:37	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:00:37	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:00:37	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:00:37	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:00:37	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:00:37	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:00:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:00:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:00:38	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:00:38',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:00:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:00:38	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:00:39	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:00:48	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:01:15	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:01:15	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:01:15	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:01:15	scrapy.extensions.telnet	INFO	Telnet Password: bdbddb5ba9934c3b
2020-01-22 18:01:15	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:01:16	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:01:16	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:01:16	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:01:16	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:01:16	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:01:16	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:01:16	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:01:17	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:01:17	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:01:17',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:01:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:01:17	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:01:18	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:01:53	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:02:35	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:02:35	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:02:35	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:02:36	scrapy.extensions.telnet	INFO	Telnet Password: 1f79aeb39c727bc0
2020-01-22 18:02:36	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:02:36	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:02:36	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:02:36	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:02:36	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:02:36	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:02:36	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:02:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:02:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:02:37	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:02:37',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:02:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:02:37	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:02:38	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:05:32	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:06:02	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:06:02	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:06:02	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:06:02	scrapy.extensions.telnet	INFO	Telnet Password: 4d7232fc4d8e0638
2020-01-22 18:06:02	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:06:03	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:06:03	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:06:03	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:06:03	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:06:03	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:06:03	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:06:03	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:06:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:06:04	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:06:04',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:06:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:06:04	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:06:04	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:06:39	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:07:35	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:07:35	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:07:35	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:07:35	scrapy.extensions.telnet	INFO	Telnet Password: 5a0249c58030c41b
2020-01-22 18:07:35	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:07:35	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:07:35	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:07:35	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:07:35	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:07:35	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:07:35	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:07:35	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:07:36	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:07:36	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:07:36',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:07:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:07:36	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:07:37	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:08:10	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:14:18	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:14:18	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:14:18	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:14:18	scrapy.extensions.telnet	INFO	Telnet Password: 46a92dad597caf50
2020-01-22 18:14:18	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:14:19	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:14:19	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:14:19	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:14:19	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:14:19	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:14:19	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:14:19	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:14:20	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%E7%A6%BB%E6%AD%A6%E6%B1%89%E8%BF%99%E4%B9%88%E8%BF%91%E3%80%82%E3%80%82%E3%80%82%E4%BF%A1%E9%98%B3%E4%BA%BA%E7%91%9F%E7%91%9F%E5%8F%91%E6%8A%96&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:14:20	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 18:14:20	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 709,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3870,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.089681,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 9, 14, 20, 169969),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 107851776,
 'memusage/startup': 107851776,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 1, 22, 9, 14, 19, 80288)}
2020-01-22 18:14:20	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 18:14:28	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:14:28	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:14:28	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:14:28	scrapy.extensions.telnet	INFO	Telnet Password: 5be7575130bbedd6
2020-01-22 18:14:28	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:14:29	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:14:29	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:14:29	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:14:29	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:14:29	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:14:29	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:14:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:14:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%E7%A6%BB%E6%AD%A6%E6%B1%89%E8%BF%99%E4%B9%88%E8%BF%91%E3%80%82%E3%80%82%E3%80%82%E4%BF%A1%E9%98%B3%E4%BA%BA%E7%91%9F%E7%91%9F%E5%8F%91%E6%8A%96&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:14:29	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 18:14:29	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 709,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3873,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.765615,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 9, 14, 29, 991329),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 108822528,
 'memusage/startup': 108822528,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 1, 22, 9, 14, 29, 225714)}
2020-01-22 18:14:29	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 18:15:14	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:15:14	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:15:14	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:15:14	scrapy.extensions.telnet	INFO	Telnet Password: 4f52806dc2e96a1e
2020-01-22 18:15:14	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:15:15	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:15:15	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:15:15	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:15:15	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:15:15	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:15:15	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:15:15	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:15:16	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E4%BF%A1%E9%98%B3%E7%A6%BB%E6%AD%A6%E6%B1%89%E8%BF%99%E4%B9%88%E8%BF%91%E3%80%82%E3%80%82%E3%80%82%E4%BF%A1%E9%98%B3%E4%BA%BA%E7%91%9F%E7%91%9F%E5%8F%91%E6%8A%96&advancedfilter=1&starttime=20200121&endtime=20200122&sort=time> (referer: None)
2020-01-22 18:15:16	scrapy.core.engine	INFO	Closing spider (finished)
2020-01-22 18:15:16	scrapy.statscollectors	INFO	Dumping Scrapy stats:
{'downloader/request_bytes': 709,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 3872,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.726513,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 22, 9, 15, 16, 386095),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 108318720,
 'memusage/startup': 108314624,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 1, 22, 9, 15, 15, 659582)}
2020-01-22 18:15:16	scrapy.core.engine	INFO	Spider closed (finished)
2020-01-22 18:18:28	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:18:28	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:18:28	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:18:28	scrapy.extensions.telnet	INFO	Telnet Password: fa081e3359074c45
2020-01-22 18:18:28	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:18:28	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:18:29	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:18:29	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:18:29	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:18:29	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:18:29	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:18:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:18:29	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:18:29	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:18:29',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:18:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:18:29	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:18:31	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:20:50	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:22:24	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:22:24	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:22:24	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:22:24	scrapy.extensions.telnet	INFO	Telnet Password: 8c30e4a3ca8e3bf8
2020-01-22 18:22:24	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:22:25	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:22:25	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:22:25	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:22:25	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:22:25	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:22:25	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:22:25	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:22:26	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:22:27	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:22:27',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:22:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:22:27	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:22:27	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:23:08	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
2020-01-22 18:27:44	scrapy.utils.log	INFO	Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-22 18:27:44	scrapy.utils.log	INFO	Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.5 (default, Oct 25 2019, 10:52:18) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-22 18:27:44	scrapy.crawler	INFO	Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': '0', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders']}
2020-01-22 18:27:44	scrapy.extensions.telnet	INFO	Telnet Password: 3b022685bf868b71
2020-01-22 18:27:44	scrapy.middleware	INFO	Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-22 18:27:45	scrapy.middleware	INFO	Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-22 18:27:45	scrapy.middleware	INFO	Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-22 18:27:45	scrapy.middleware	INFO	Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-22 18:27:45	scrapy.core.engine	INFO	Spider opened
2020-01-22 18:27:45	scrapy.extensions.logstats	INFO	Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-22 18:27:45	scrapy.extensions.telnet	INFO	Telnet console listening on 127.0.0.1:6023
2020-01-22 18:27:45	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:27:46	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time> (referer: None)
2020-01-22 18:27:46	scrapy.core.scraper	DEBUG	Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time>
{'crawled_at': '2020-01-22 18:27:46',
 'created_at': '2020-01-21 19:55',
 'favorite_count': 39,
 'id_str': '2541074492_IqxHeATcq',
 'place': True,
 'reply_count': 21,
 'retweet_count': 0,
 'source': 'iPhone客户端',
 'text': '#国内确诊291例新型冠状病毒肺炎病例#我在长沙，离武汉只有高铁1小时的城市，今天出门全家都带上了口罩，可是商场，超市，人流量较大的地方，都没有人戴口罩，最重要的是商场超市工作人员乃至收银员，她们一天是接触人最多的，她们都没有戴口罩，不是小题大做，真的对生命没有一点敬畏之心。',
 'user': '2541074492',
 'username': '罗小清清清',
 'weibo_url': 'https://weibo.com/2541074492/IqxHeATcq'}
2020-01-22 18:27:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:27:46	urllib3.connectionpool	DEBUG	Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-22 18:27:47	scrapy.core.engine	DEBUG	Crawled (200) <GET https://weibo.cn/2541074492/IqxHeATcq> (referer: https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%88%91%E5%9C%A8%E9%95%BF%E6%B2%99%EF%BC%8C%E7%A6%BB%E6%AD%A6%E6%B1%89%E5%8F%AA%E6%9C%89%E9%AB%98%E9%93%811%E5%B0%8F%E6%97%B6%E7%9A%84%E5%9F%8E%E5%B8%82&advancedfilter=1&starttime=20200120&endtime=20200121&sort=time)
2020-01-22 18:33:39	scrapy.crawler	INFO	Received SIGINT, shutting down gracefully. Send again to force 
